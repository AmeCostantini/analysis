---
title: "Untitled"
author: "Americo"
date: "29 aprile 2016"
output: html_document
---

#Introduzione

Questo capitolo tratta lo svolgimento di una analisi dati relativa al **direct marketing** bancario, utilizzando un dataset disponibile sul web a questo indirizzo: http://archive.ics.uci.edu/ml/datasets/Bank+Marketing. Questo dataset contiene le informazioni raccolte da una banca portoghese che dal 2008 al 2013 ha effettuato chiamate in outbound a un campione del suo portafoglio per proporre la sottoscrizione di un ulteriore prodotto, un deposito a termine. Avendo a disposizione alcune informazioni sui clienti e sapendo quali hanno sottoscritto e quali no, l'obiettivo dell'analisi sarà quello di costruire un modello di regressione logistica che sia in grado di discriminare i clienti, tra quelli mai chiamati, che sottoscriveranno il prodotto se contattati da quelli che non lo soottoscriveranno. Una tale analisi predittiva avrebbe enormi benefici in termini di efficacia dell'attività di vendita: senza il supporto di modelli infatti ogni n clienti contattati si avrà una penetrazione del prodotto identica, che sarà molto prossimo a quello del campione analizzato (11,7% circa); con un modello a disposizione invece si potrà individuare un segmento di clienti entro la quale la **penetrazione** sarà maggiore, e si potranno collocare più prodotti a parità di chiamate.

#Metodologia

##Strumenti

Questa analisi viene svolta utilizzando il linguaggio di analisi statistica R, tramite il modulo di literate statical programming **R markdown**, che permette il rispetto dei principi della ricerca riproducibile. Per ogni risultato dell'analisi viene riportato il codice che lo ha generato. Di seguito i package utilizzati per l'analisi:

```{r setup, include=FALSE}
knitr::opts_chunk$set(cache=TRUE)
```

```{r packages, message=FALSE, warning=FALSE}
require(gains)
require(PRROC)
require(broom)
require(ResourceSelection)
require(MKmisc)
require(perturb)
require(caret)
require(DAAG)
library(pROC)
library(ROCR)
require(MASS)
library(devtools)
require(GGally)
library(woe)
require(ggplot2)
require(dplyr)
require(tidyr)
require(knitr)
require(e1071)
select <- dplyr::select
```

##Approccio statistico

I modelli che verranno testati rientrano tutti nella famiglia della regressione logistica, di cui si è trattato nel capitolo primo. L'approccio si concretizzerà in una prima fase di **exploratory data analysis**, soprattutto in formato grafico, seguita da un confronto tra diverse ipotesi di modello guidate dalla prima fase. Per ogni variabile verrà eseguita una analisi univariata e una della sua relazione con la variabile target `y`, inoltre in alcuni casi verrà approfondita la relazione trivariata tra `y`e due variabili indipendenti.

#Analisi esplorativa

##Caricamento del dataset

```{r directory e dataset, results='hide'}
getwd()
setwd("/Users/Americo/Documents/Education/Unitelma/tesi/data_analysis/dataset")
bank0_df <- read.csv(file = "bank_full.csv", sep = ";")
bank0 <- tbl_df(read.csv(file = "bank_full.csv", sep = ";"))
bank0_sm <- read.csv(file = "bank.csv", sep = ";")
```

`bank0` è il nome dato al dataset che utilizzeremo.

##Informazioni sul dataset

```{r dim dataset}
dim(bank0)
```

Il dataset è composto da circa 45000 osservazioni e da 17 variabili. Vediamo meglio quali sono le variabili:

```{r str dataset}
str(bank0)
```

Al link sopra riportato vi è la descrizione delle 17 variabili presenti nel dataset, che noi approfondiremo singolarmente nella nostra analisi. Per ora basti la seguente sintesi:

**Variabili legate al profilo del cliente**

* age: età del cliente
* job: professione svolta dal cliente
* marital : stato coniugale del cliente
* education: titolo di studio del cliente
* default: presenza di crediti in default
* balance: saldo medio annuale del conto
* housing: presenza di mutuo per la casa
* loan: presenza di prestiti

**Variabili legate all'ultimo contatto dell'attuale campagna di marketing**

* contact: modalità di comunicazione per l'ultimo contatto avvenuto
* day: giorno del mese dell'ultimo contatto avvenuto
* month: mese dell'ultimo contatto avvenuto
* duration: durata (in secondi) dell'ultimo contatto avvenuto

**Variabili legate all'attuale o a precedente campagna di marketing**

* campaign: totale di contatti avvenuti durante l'attuale campagna di marketing per ogni cliente
* pdays: numero di giorni trascorsi prima che il cliente fosse contattato per questa campagna dopo la fine della campagna precedente
* previous: numerodi contatti avvenuti prima di questa campagna
* poutcome: esito della precedente campagna di marketing

**Variabile target: sottoscrizione o meno del deposito**

Verifichiamo che non ci siano valori mancanti

```{r missing vaue detect}
bank0[!complete.cases(bank0),]
```

Nessuna riga contiene valori mancanti.

##Esplorazione variabili univariata e in rapporto alla sottoscrizione

###age

Da indicazioni del dizionario dati, `age` è una variabile numerica che misura l'età del cliente, anche se non sappiamo in quale momento (assumiamo quello attuale di processamento del modello).

```{r age 5 quantities}
class(bank0$age)
summary(bank0$age)
```

Il range è dai 18 ai 95, vediamo in forma tabellare e grafica la distribuzione delle varie età.

```{r age table and graph, fig.width=16, fig.height=7}
t_age <- bank0 %>%
        group_by(age) %>%
        summarise(frequenza = n()) %>% 
        mutate(frequenza_relativa = frequenza / sum(frequenza))
kable(t_age, digits = 4, format = "markdown")

g_age <- ggplot(bank0, aes(x = factor(age))) + geom_bar(col = "white") +
        ggtitle("distribuzione per età") +
        xlab("età") +
        ylab("frequenza")    
g_age
```

Una distribuzione quasi normale, con maggioritaria presenza di clienti dai 30 ai 60 anni, pochissimi diciotenni e ultra-ottantenni.

Ora vediamo come la penetrazione del prodotto si distribuisce all'interno delle varie età (in questo e in tutti gli altri grafici la linea orizzontale trattegiata rappresenta la percentuale di sottoscrizioni complessiva del campione, `r mean(bank0$y =="yes")`.

```{r age_y table and graph, fig.width=16, fig.height=7}
g_age_y <- ggplot(bank0, aes(x = factor(age), fill = y)) + 
        geom_bar(col = "white", position = "fill") + 
        geom_hline(yintercept = mean(bank0$y!="yes"), col = "black", linetype = 2) +
        ggtitle("penetrazione per età") +
        xlab("età") +
        ylab("tasso sottoscrizioni") +
        scale_y_continuous(breaks = seq(0, 1, 0.1)) +
        scale_fill_discrete(name="Sottoscrizione", labels=c("no", "sì"))
g_age_y

t_age_y <- bank0 %>%
        group_by (age) %>%
        summarise (frequenza = n(), tasso_sottoscrizioni = mean(y == "yes")) %>%
        mutate(frequenza_relativa = frequenza / sum(frequenza)) %>%
        select(age, frequenza, frequenza_relativa, tasso_sottoscrizioni)
kable(t_age_y, digits = 4, format = "markdown")
```

Vediamo che dai 30 ai 59 anni l'incidenza di sottoscrizioni è prossima a quella complessiva, e rappresenta la parte più numerosa del campione. La penetrazione del prodotto comincia a essere superiore a quella complessiva, di portafoglio diciamo, per fasce di età molto giovani o ultra-sessantenni, dove però la numerosità (e quindi la significatività) è inferiore. 

Potrebbe essere interessante raggruppare le età per fasce dal comportamento simile: [18, 30], [31, 59], [60, 95]

```{r age_class_y table and graph}
bank0$age <- as.numeric(bank0$age)
bank0$age_class <- cut(bank0$age, breaks = c(min(bank0$age)-1, 30, 59, max(bank0$age)), labels = c("[18, 30]", "[31, 59]", "[60, 95]"))
summary(bank0$age_class)

t_age_class <- bank0 %>%
        select(age_class, y) %>%
        group_by(age_class) %>%
        summarise(frequenza = n(), tasso_sottoscrizioni = mean(y =="yes")) %>%
        mutate(frequenza_relativa = frequenza / sum(frequenza)) %>%
        select(age_class, frequenza, frequenza_relativa, tasso_sottoscrizioni)
kable(t_age_class, digits = 4, format = "markdown")

g_age_class_y <- ggplot(bank0, aes(x = age_class, fill = y)) + 
        geom_bar(col = "white", position = "fill") + 
        geom_hline(yintercept = mean(bank0$y!="yes"), col = "black", linetype = 2) +
        ggtitle("penetrazione per età") +
        xlab("fasce di età") +
        ylab("tasso sottoscrizioni") +
        scale_x_discrete(labels = c("[18, 30]", "[31, 59]", "[60, 95]")) +
        scale_y_continuous(breaks = seq(0, 1, 0.1)) +
        scale_fill_discrete(name="Sottoscrizione", labels=c("no", "sì"))
g_age_class_y
```

è evidente che giovani e anziani sottoscrivono più del campione nel complesso, che nel comportamento è guidato dalla fascia media, gli adulti. Inoltre l'alta penetrazione della fascia anziana va pesato per la scarsa rilevanza numerica nel campione, il 4% circa, ma comunque di dimensione significativa.

Ha senso questa distribuzione? Beh, ci si può aspettare che un deposito a lungo termine venga sottoscritto di più da giovani che vogliono investire i loro risparmi (magari regali dei loro cari), mentre la fascia adulta avendo già molte spese (mantenimento della famiglia, mutui, presiti - in questi ultimi due casi potremo verificare l'ipotesi di una qualche interazione) abbia meno possibilità di farlo. Quanto agli anziani, per saperlo dovremmo conoscere meglio le caratteristiche del prodotto, magari lo hanno sottoscritto ma per farne beneficiare gli eredi.

Come per ogni variabile che analizzeremo, l'analisi termina con il calcolo dell'**information value**, una misura del potere predittivo della variabile per la cui trattazione teorica rimandiamo al capitolo secondo.

```{r age class IV}
age_class_woe <- bank0 %>%
        select(age_class, y) %>%
        group_by(age_class) %>%
        summarise(n_no = sum(y == "no"), n_y = sum(y == "yes")) %>%
        mutate (perc_no = n_no / sum(n_no), perc_y = n_y / sum(n_y)) %>%
        select (starts_with("perc"))
age_class_woe$woe <- log(age_class_woe$perc_no / age_class_woe$perc_y)
age_class_IV <- sum((age_class_woe$perc_no - age_class_woe$perc_y) * age_class_woe$woe)
age_class_IV
```

`r age_class_IV` , confrontato con la griglia del capitolo secondo, ci fa dire che l'età, raggruppata in tre classi, è una variabile mediamente predittiva della sottoscrizione. 

###Job

La professione svolta dal cliente. Iniziamo con tabella e grafico della distribuzione:

```{r job table and graph }
t_job <- bank0 %>%
        group_by (job) %>%
        summarise (frequenza = n()) %>%
        mutate (frequenza_relativa = frequenza / sum(frequenza)) %>%
        arrange(desc(frequenza_relativa))
kable(t_job, digits = 4, format = "markdown")

g_job  <- ggplot(bank0, aes(x = job)) +
        geom_bar() +
        ggtitle("distribuzione per job") +
        ylab("frequenza") +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_job
```

Vediamo adesso come, all'interno dei vari livelli della professione, si distribuiscono i sottoscrittori:

```{r job_y table and graph}
t_job_y <- bank0 %>%
        group_by (job) %>%
        summarise (frequenza = n(), tasso_sottoscrizioni = mean(y=="yes")) %>%
        mutate(frequenza_relativa = frequenza / sum(frequenza)) %>%
        select(job, frequenza, frequenza_relativa, tasso_sottoscrizioni) %>%
        arrange(desc(tasso_sottoscrizioni))
kable(t_job_y, digits = 4, format = "markdown")

g_job_y  <- ggplot(bank0, aes(x = job, fill = y)) +
        geom_bar(position = "fill") +
        geom_hline(yintercept = mean(bank0$y!="yes"), width = 2, col = "black", linetype = 2) +
        ggtitle("penetrazione per job") +
        ylab("tasso sottoscrizioni") +
        scale_y_continuous(breaks = seq(0, 1, 0.1)) +
        scale_fill_discrete(name="Sottoscrizione", labels=c("no", "sì")) +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_job_y
```

Le professioni con il maggior tasso di sottoscrittori sono le meno frequenti, studenti e pensionati. Sarà interessante vedere - e lo faremo nella sezione delle analisi trivariate - se c'è un legame da età e professione tale per cui una delle due variabili può spiegare parzialmente la relazione con la sottoscrizione. 

Non facile da interpretare invece il dato sui disoccupati: perché mai chi non ha reddito dovrebbe tendere più della media a sottoscrivere depositi a lungo termine? Forse vi rientrano giovani non categorizzati come studenti il cui deposito viene finanziato dai genitori. Anche qui l'analisi trivariata ci potrà svelare se c'è un legame.

Da Ultimo calcoliamo l'information value della variabile `job`:

```{r job IV}
job_woe <- bank0 %>%
        select(job, y) %>%
        group_by(job) %>%
        summarise(n_no = sum(y == "no"), n_y = sum(y == "yes")) %>%
        mutate (perc_no = n_no / sum(n_no), perc_y = n_y / sum(n_y)) %>%
        select (starts_with("perc"))
job_woe$woe <- log(job_woe$perc_no / job_woe$perc_y)
job_IV <- sum((job_woe$perc_no - job_woe$perc_y) * job_woe$woe)
job_IV
```

Anche `job` ha un potere predittivo di media entità.

###Marital

La variabile descrive lo stato coniugale. Dal dizionario dati sappiamo che il valore "divorced" include anche i vedovi.

```{r marital table and graph}
t_marital <- bank0 %>%
        group_by(marital) %>%
        summarise(frequenza = n()) %>%
        mutate(frequenza_relativa = frequenza / sum(frequenza)) %>%
        arrange(desc(frequenza))
kable(t_marital, digits = 4, format = "markdown")

g_marital  <- ggplot(bank0, aes(x = marital)) +
        geom_bar() +
        ggtitle("distribuzione per marital") +
        ylab("frequenza") +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_marital
```


```{r marital_y table and graph}
t_marital_y <- bank0 %>%
        group_by (marital) %>%
        summarise (frequenza = n(), tasso_sottoscrizioni = mean(y=="yes")) %>%
        mutate(frequenza_relativa = frequenza / sum(frequenza)) %>%
        select(marital, frequenza, frequenza_relativa, tasso_sottoscrizioni) %>%
        arrange(desc(tasso_sottoscrizioni))
kable(t_marital_y, digits = 4, format = "markdown")

g_marital_y  <- ggplot(bank0, aes(x = marital, fill = y)) +
        geom_bar(position = "fill") +
        geom_hline(yintercept = mean(bank0$y!="yes"), width = 2, col = "black", linetype = 2) +
        ggtitle("penetrazione per marital") +
        ylab("tasso sottoscrizioni") +
        scale_y_continuous(breaks = seq(0, 1, 0.1)) +
        scale_fill_discrete(name="Sottoscrizione", labels=c("no", "sì")) +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_marital_y
```

I single tendono a sottoscrivere un po' di più. Anche qui andrà indagata la relazione con l'età (la maggior parte dei single sono giovani e quindi per questo i single sottoscrivono di più?) e la professione (specialmente studentesca).

L'information value di `marital`:

```{r marital IV}
marital_woe <- bank0 %>%
        select(marital, y) %>%
        group_by(marital) %>%
        summarise(n_no = sum(y == "no"), n_y = sum(y == "yes")) %>%
        mutate (perc_no = n_no / sum(n_no), perc_y = n_y / sum(n_y)) %>%
        select (starts_with("perc"))
marital_woe$woe <- log(marital_woe$perc_no / marital_woe$perc_y)
marital_IV <- sum((marital_woe$perc_no - marital_woe$perc_y) * marital_woe$woe)
marital_IV
```

Ha una predittività molto debole.

###Education

```{r education graph and table}
t_education  <- bank0 %>%
        group_by(education) %>%
        summarise(frequenza = n()) %>%
        mutate(frequenza_relativa = frequenza / sum(frequenza)) %>%
        arrange(desc(frequenza))
kable(t_education, digits = 4, format = "markdown")

g_education  <- ggplot(bank0, aes(x = education)) +
        geom_bar() +
        ggtitle("distribuzione per education") +
        ylab("frequenza") +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_education
```

Analizziamo come la penetrazione si distribuisce tra i titoli di studio:

```{r education_y graph and table}
t_education_y <- bank0 %>%
        group_by (education) %>%
        summarise (frequenza = n(), tasso_sottoscrizioni = mean(y=="yes")) %>%
        mutate(frequenza_relativa = frequenza / sum(frequenza)) %>%
        select(education, frequenza, frequenza_relativa, tasso_sottoscrizioni) %>%
        arrange(desc(tasso_sottoscrizioni))
kable(t_education_y, digits = 4, format = "markdown")

g_education_y  <- ggplot(bank0, aes(x = education, fill = y)) +
        geom_bar(position = "fill") +
        geom_hline(yintercept = mean(bank0$y!="yes"), width = 2, col = "black", linetype = 2) +
        ggtitle("penetrazione per education") +
        ylab("tasso sottoscrizioni") +
        scale_y_continuous(breaks = seq(0, 1, 0.1)) +
        scale_fill_discrete(name="Sottoscrizione", labels=c("no", "sì")) +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_education_y
```

Sembra che (ignorando il livello "unknown") a maggior livello culturale segua maggiore propensione a sottoscrivere depositi, e questa appare come una informazione aggiuntiva rispetto a quanto abbiamo scoperto sinora. Anche qui dovremo capire se l'educazione terziaria è maggiormente presente negli under 30, che per condizioni socio-economiche mutevoli hanno studiato in proporzione di più degli adulti.

L'information value di `èducation`:

```{r education IV}
education_woe <- bank0 %>%
        select(education, y) %>%
        group_by(education) %>%
        summarise(n_no = sum(y == "no"), n_y = sum(y == "yes")) %>%
        mutate (perc_no = n_no / sum(n_no), perc_y = n_y / sum(n_y)) %>%
        select (starts_with("perc"))
education_woe$woe <- log(education_woe$perc_no / education_woe$perc_y)
education_IV <- sum((education_woe$perc_no - education_woe$perc_y) * education_woe$woe)
education_IV
```

Predittività debole ma non assente.

##Default

Variabile dicotomica che quando assume valore `r 1` indica la presenza di crediti in defualt.

```{r default table and graph}
t_default  <- bank0 %>%
        group_by(default) %>%
        summarise(frequenza = n()) %>%
        mutate(frequenza_relativa = frequenza / sum(frequenza)) %>%
        arrange(desc(frequenza))
kable(t_default, digits = 4, format = "markdown")

g_default  <- ggplot(bank0, aes(x = default)) +
        geom_bar() +
        ggtitle("distribuzione per default") +
        ylab("frequenza") +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_default
```

Pochissimi in default, forse troppo pochi per trovare significatività in questa variabile.

```{r default_y graph and  table}
t_default_y <- bank0 %>%
        group_by (default) %>%
        summarise (frequenza = n(), tasso_sottoscrizioni = mean(y=="yes")) %>%
        mutate(frequenza_relativa = frequenza / sum(frequenza)) %>%
        select(default, frequenza, frequenza_relativa, tasso_sottoscrizioni) %>%
        arrange(desc(tasso_sottoscrizioni))
kable(t_default_y, digits = 4, format = "markdown")

g_default_y  <- ggplot(bank0, aes(x = default, fill = y)) +
        geom_bar(position = "fill") +
        geom_hline(yintercept = mean(bank0$y!="yes"), width = 2, col = "black", linetype = 2) +
        ggtitle("penetrazione per default") +
        ylab("tasso sottoscrizioni") +
        scale_y_continuous(breaks = seq(0, 1, 0.1)) +
        scale_fill_discrete(name="Sottoscrizione", labels=c("no", "sì")) +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_default_y
```

I clienti non in default si comportano, in termini di sottoscrizioni, assolutamente nella media, ma d'altronde rappresentano pressoché tutto il campione. Il `r t_default[2,3]` che è in default sottoscrive (prevedibilmente) molto meno.

Passiamo all'information value

```{r default IV}
default_woe <- bank0 %>%
        select(default, y) %>%
        group_by(default) %>%
        summarise(n_no = sum(y == "no"), n_y = sum(y == "yes")) %>%
        mutate (perc_no = n_no / sum(n_no), perc_y = n_y / sum(n_y)) %>%
        select (starts_with("perc"))
default_woe$woe <- log(default_woe$perc_no / default_woe$perc_y)
default_IV <- sum((default_woe$perc_no - default_woe$perc_y) * default_woe$woe)
default_IV
```

Predittività assente.

###Balance

Il saldo medio sul conto corrente del cliente; in questo caso adottiamo un istogramma, data la natura quantitativa della variabile: 

```{r balance quant graph and table}
balance_quantile <- quantile(bank0$balance, c(seq(0.1, 1, 0.05)))
balance_quantile

g_balance <- ggplot(bank0, aes(x = balance)) + 
        geom_histogram(binwidth = 500) +
        ggtitle("distribuzione di balance") +
        ylab("frequenza")
g_balance
```

Come sia il grafico che la distribuzione dei percentili ci mostrano, `balance` presenta dei valori anomali che rendono l'intervallo dei valori incredibilmente ampio; per così dire, i pochi ricchi clienti della banca, mentre il 79% è tra 0 e 1000.

Vediamo che tipo di distribuzione prende forma se escludiamo il 2% dei valori più alti.

```{r balance quant graph p98}
balance_p_98 <- quantile(bank0$balance, 0.98)
bank0_p98 <- bank0 %>%
        filter(balance <= balance_p_98)
g_balance_p98 <- ggplot(bank0_p98, aes(x = 1, y = balance)) + 
        geom_boxplot() +
        ggtitle("distribuzione di balance - 98-esimo percentile") +
        xlab("") +
        scale_x_continuous(labels = c("", "", "", "", "")) +
        scale_y_continuous(breaks = seq(min(bank0$balance), balance_p_98, 1000))
g_balance_p98
```

Il 50% dei valori è tra 0 e 1000 euro, ora la distribuzione di `balance` è più chiara. Vediamo cosa succede condizionando la distribuzione alla sottoscrizione o meno

```{r balance_y quant graph}
g_balance_y_p98 <- ggplot(bank0_p98, aes(x = y, y = balance)) + 
        geom_boxplot(aes(col = y)) +
        ggtitle("distribuzione di balance - 98-esimo percentile secondo la sottoscrizione") +
        xlab("sottoscrizione") + 
        scale_x_discrete(labels = c("no", "sì")) +
        scale_color_discrete(name="Sottoscrizione", labels=c("no", "sì")) +
        scale_y_continuous(breaks = seq(min(bank0$balance), balance_p_98, 1000))
g_balance_y_p98
```

Ora comincia a essere evidente che chi sottoscrive depositi tende a avere un saldo medio del conto più alto; vale per la mediana del gruppo dei sottoscrittori, ma anche per il terzo quartile. Quindi per saldi che crescono si tende a sottoscrivere più depositi, il che ha senso. Più soldi hai, più ne puoi depositare.

Ora, anche ai fini del calcolo dell'information value, raggruppiamo `balance` in classi e analizziamo la distribuzione dei sottoscrittori all'interno dei vari livelli.

```{r balance_class_y table and graph}
bank0$balance <- as.numeric(bank0$balance)
balance_decile <- quantile(bank0$balance, probs = seq(0.1,1,0.1))
bank0$balance_class <- cut(bank0$balance, breaks = c(min(bank0$balance)-1, -1, balance_decile), right = TRUE, labels = c("negative", "0", "(0, 22]", "(22,131]", "(131,272]", "(272,448]", "(448,701]", "(701,1126]", "(1126,1859]", "(1859,3574]", "(3574,102127]"))
summary(bank0$balance_class)

t_balance_class_y <- bank0 %>%
        group_by (balance_class) %>%
        summarise (frequenza = n(), tasso_sottoscrizioni = mean(y=="yes")) %>%
        mutate(frequenza_relativa = frequenza / sum(frequenza)) %>%
        select(balance_class, frequenza, frequenza_relativa, tasso_sottoscrizioni)
kable(t_balance_class_y, digits = 4, format = "markdown")

g_balance_class_y  <- ggplot(bank0, aes(x = balance_class, fill = y)) +
        geom_bar(position = "fill") +
        geom_hline(yintercept = mean(bank0$y!="yes"), width = 2, col = "black", linetype = 2) +
        ggtitle("penetrazione per balance_class") +
        ylab("tasso sottoscrizioni") +
        scale_y_continuous(breaks = seq(0, 1, 0.1)) +
        scale_fill_discrete(name="Sottoscrizione", labels=c("no", "sì")) +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_balance_class_y
```

Evidente come spostandosi verso gruppi di saldo maggiore (gruppi di numerosità simile, ricordiamolo) cresce la probabilità di sottoscrivere un deposito a medio termine. E l'information value?

```{r balance IV}
balance_class_woe <- bank0 %>%
        select(balance_class, y) %>%
        group_by(balance_class) %>%
        summarise(n_no = sum(y == "no"), n_y = sum(y == "yes")) %>%
        mutate (perc_no = n_no / sum(n_no), perc_y = n_y / sum(n_y)) %>%
        select (starts_with("perc"))
balance_class_woe$woe <- log(balance_class_woe$perc_no / balance_class_woe$perc_y)
balance_class_IV <- sum((balance_class_woe$perc_no - balance_class_woe$perc_y) * balance_class_woe$woe)
balance_class_IV
```

Il valore di `r balance_class_IV` rientra tra i predittori di media rilevanza. 

###Housing

La variabile di dice se il cliente ha o meno sottoscritto un mutuo ipotecario per l'acquisto di un immobile

```{r housing graph and table}
t_housing  <- bank0 %>%
        group_by(housing) %>%
        summarise(frequenza = n()) %>%
        mutate(frequenza_relativa = frequenza / sum(frequenza)) %>%
        arrange(desc(frequenza))
kable(t_housing, digits = 4, format = "markdown")

g_housing  <- ggplot(bank0, aes(x = housing)) +
        geom_bar() +
        ggtitle("distribuzione per housing") +
        ylab("frequenza") +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_housing
```

Vediamo ora il comportamento dei sottoscrittori.

Poco più della metà dei clienti ha il mutuo, l'altra no. Entrambe le classi sono estremanente significative, quindi.

```{r housing_y table and graph}
t_housing_y <- bank0 %>%
        group_by (housing) %>%
        summarise (frequenza = n(), tasso_sottoscrizioni = mean(y=="yes")) %>%
        mutate(frequenza_relativa = frequenza / sum(frequenza)) %>%
        select(housing, frequenza, frequenza_relativa, tasso_sottoscrizioni) %>%
        arrange(desc(tasso_sottoscrizioni))
kable(t_housing_y, digits = 4, format = "markdown")

g_housing_y  <- ggplot(bank0, aes(x = housing, fill = y)) +
        geom_bar(position = "fill") +
        geom_hline(yintercept = mean(bank0$y!="yes"), width = 2, col = "black", linetype = 2) +
        ggtitle("penetrazione per housing") +
        ylab("tasso sottoscrizioni") +
        scale_y_continuous(breaks = seq(0, 1, 0.1)) +
        scale_fill_discrete(name="Sottoscrizione", labels=c("no", "sì")) +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_housing_y
```

La distinzione tra mutuatari o meno se,bra abbastanza discriminante sulla sottoscrizione; un gruppo sottoscrive al 16,5%, l'altro al 7,5%. Ha una logica il fatto che chi ha dovuto accolarsi un mutuo non abbia risorse finanziarie da investire per rendimento nel lungo periodo, data l'esigenza pressante di liquidità. Alla luce di ciò l'information value dovrebbe presentarci una variabile con potere predittivo medio.

```{r housing IV}
housing_woe <- bank0 %>%
        select(housing, y) %>%
        group_by(housing) %>%
        summarise(n_no = sum(y == "no"), n_y = sum(y == "yes")) %>%
        mutate (perc_no = n_no / sum(n_no), perc_y = n_y / sum(n_y)) %>%
        select (starts_with("perc"))
housing_woe$woe <- log(housing_woe$perc_no / housing_woe$perc_y)
housing_IV <- sum((housing_woe$perc_no - housing_woe$perc_y) * housing_woe$woe)
housing_IV
```

Esatto.

###Loan

Variabile dicotomica che indica che il cliente ha richiesto e sta pagando un prestito.

```{r loan graph and table}
t_loan  <- bank0 %>%
        group_by(loan) %>%
        summarise(frequenza = n()) %>%
        mutate(frequenza_relativa = frequenza / sum(frequenza)) %>%
        arrange(desc(frequenza))
kable(t_loan, digits = 4, format = "markdown")

g_loan  <- ggplot(bank0, aes(x = loan)) +
        geom_bar() +
        ggtitle("distribuzione per loan") +
        ylab("frequenza") +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_loan
```

La quota di persone con prestiti è intorno al 16%. Vediamo come si distribuiscono i sottoscrittori

```{r loan_y table and graph}
t_loan_y <- bank0 %>%
        group_by (loan) %>%
        summarise (frequenza = n(), tasso_sottoscrizioni = mean(y=="yes")) %>%
        mutate(frequenza_relativa = frequenza / sum(frequenza)) %>%
        select(loan, frequenza, frequenza_relativa, tasso_sottoscrizioni) %>%
        arrange(desc(tasso_sottoscrizioni))
kable(t_loan_y, digits = 4, format = "markdown")

g_loan_y  <- ggplot(bank0, aes(x = loan, fill = y)) +
        geom_bar(position = "fill") +
        geom_hline(yintercept = mean(bank0$y!="yes"), width = 2, col = "black", linetype = 2) +
        ggtitle("penetrazione per loan") +
        ylab("tasso sottoscrizioni") +
        scale_y_continuous(breaks = seq(0, 1, 0.1)) +
        scale_fill_discrete(name="Sottoscrizione", labels=c("no", "sì")) +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_loan_y
```

Il 16% dei richiedenti prestito ha un tasso di sottoscrizione pari alla metà del restante 84%, che sottoscrive poco sopra la media di portafoglio. Ci si aspettava in effetti un comportamento simile a quello di `housing`, e sarà interessante vedere l'effetto di interazione in chi sta pagando sia mutuo che prestito.

```{r loan IV}
loan_woe <- bank0 %>%
        select(loan, y) %>%
        group_by(loan) %>%
        summarise(n_no = sum(y == "no"), n_y = sum(y == "yes")) %>%
        mutate (perc_no = n_no / sum(n_no), perc_y = n_y / sum(n_y)) %>%
        select (starts_with("perc"))
loan_woe$woe <- log(loan_woe$perc_no / loan_woe$perc_y)
loan_IV <- sum((loan_woe$perc_no - loan_woe$perc_y) * loan_woe$woe)
loan_IV
```

In realtà l'information value restituisce una predittività debole.

###Contact

Variabile categoricha che indica la modalità di comunicazione col cliente.

```{r contact graph and table}
t_contact  <- bank0 %>%
        group_by(contact) %>%
        summarise(frequenza = n()) %>%
        mutate(frequenza_relativa = frequenza / sum(frequenza)) %>%
        arrange(desc(frequenza))
kable(t_contact, digits = 4, format = "markdown")

g_contact  <- ggplot(bank0, aes(x = contact)) +
        geom_bar() +
        ggtitle("distribuzione per contact") +
        ylab("frequenza") +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_contact
```

In sostanza abbiamo un 6% tramite fisso e il restante tramite cellullare. Purtroppo Un 29% dei clienti è stato contattato tramite modalità non rilevate.

```{r contact_y graph and table}
t_contact_y <- bank0 %>%
        group_by (contact) %>%
        summarise (frequenza = n(), tasso_sottoscrizioni = mean(y=="yes")) %>%
        mutate(frequenza_relativa = frequenza / sum(frequenza)) %>%
        select(contact, frequenza, frequenza_relativa, tasso_sottoscrizioni) %>%
        arrange(desc(tasso_sottoscrizioni))
kable(t_contact_y, digits = 4, format = "markdown")

g_contact_y  <- ggplot(bank0, aes(x = contact, fill = y)) +
        geom_bar(position = "fill") +
        geom_hline(yintercept = mean(bank0$y!="yes"), width = 2, col = "black", linetype = 2) +
        ggtitle("penetrazione per contact") +
        ylab("tasso sottoscrizioni") +
        scale_y_continuous(breaks = seq(0, 1, 0.1)) +
        scale_fill_discrete(name="Sottoscrizione", labels=c("no", "sì")) +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_contact_y
```

Interessantissimo notare che c'è una variabilità sistematica: se la modalità di contatto è sconosciuta la percentuale di sottoscrittori è bassissima. Questo vorrà dire qualcosa, ma è complicato immaginare il motivo. Il restante 70% di portafoglio sottoscrive al 14% circa, contro l'11,7% complessivo. La variabile sembra discriminante, vediamo se l'information value lo conferma.

```{r contact IV}
contact_woe <- bank0 %>%
        select(contact, y) %>%
        group_by(contact) %>%
        summarise(n_no = sum(y == "no"), n_y = sum(y == "yes")) %>%
        mutate (perc_no = n_no / sum(n_no), perc_y = n_y / sum(n_y)) %>%
        select (starts_with("perc"))
contact_woe$woe <- log(contact_woe$perc_no / contact_woe$perc_y)
contact_IV <- sum((contact_woe$perc_no - contact_woe$perc_y) * contact_woe$woe)
contact_IV
```

Confermato, la predittività è di media / forte entità.

###Day

La variabile rileva il giorno del mese dell'ultimo contatto, che laddove `y = "yes` significa la chiamata di vendita.

```{r day graph}
t_day  <- bank0 %>%
        group_by(day) %>%
        summarise(frequenza = n()) %>%
        mutate(frequenza_relativa = frequenza / sum(frequenza)) %>%
        arrange(day)
kable(t_day, digits = 4, format = "markdown")

g_day  <- ggplot(bank0, aes(x = factor(day))) +
        geom_bar() +
        ggtitle("distribuzione per day") +
        xlab("day") +
        ylab("frequenza") +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_day
```

Il 1, 10, 24 e 31 del mese accade poche volte che ci sia l'ultima chiamata della campagna. Chissà perché.

```{r day_y graph and table}
t_day_y <- bank0 %>%
        group_by (day) %>%
        summarise (frequenza = n(), tasso_sottoscrizioni = mean(y=="yes")) %>%
        mutate(frequenza_relativa = frequenza / sum(frequenza)) %>%
        select(day, frequenza, frequenza_relativa, tasso_sottoscrizioni) %>%
        arrange(day)
kable(t_day_y, digits = 4, format = "markdown")

g_day_y  <- ggplot(bank0, aes(x = factor(day), fill = y)) +
        geom_bar(position = "fill") +
        geom_hline(yintercept = mean(bank0$y!="yes"), width = 2, col = "black", linetype = 2) +
        ggtitle("penetrazione per day") +
        xlab("day") +
        ylab("tasso sottoscrizioni") +
        scale_y_continuous(breaks = seq(0, 1, 0.1)) +
        scale_fill_discrete(name="Sottoscrizione", labels=c("no", "sì")) +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_day_y
```

I due giorni di maggior sottoscrizione sono quelli con il minor numero di contatti. Chissà perché. Sarebbe inoltre utile capire se c'è una interazione tra il giorno dell'ultima chiamata e il numero di contatti già effettuati, così da vedere se ci sono giorni dove basta una chiamata sola per vendere il prodotto. In generale c'è parecchia variabilità all'interno del mese sul tasso di sottoscrizioni.


```{r day IV}
day_woe <- bank0 %>%
        select(day, y) %>%
        group_by(day) %>%
        summarise(n_no = sum(y == "no"), n_y = sum(y == "yes")) %>%
        mutate (perc_no = n_no / sum(n_no), perc_y = n_y / sum(n_y)) %>%
        select (starts_with("perc"))
day_woe$woe <- log(day_woe$perc_no / day_woe$perc_y)
day_IV <- sum((day_woe$perc_no - day_woe$perc_y) * day_woe$woe)
day_IV
```

Media predittività.

###Month

La variabile rileva il mese del mese dell'ultimo contatto, che laddove `y = "yes` significa la chiamata di vendita.

```{r month graph and table}
bank0$month <- factor(bank0$month, levels = c("jan","feb","mar", "apr","may","jun", "jul","aug", "sep", "oct", "nov","dec"))
t_month  <- bank0 %>%
        group_by(month) %>%
        summarise(frequenza = n()) %>%
        mutate(frequenza_relativa = frequenza / sum(frequenza))
kable(t_month, digits = 4, format = "markdown")

g_month  <- ggplot(bank0, aes(x = month)) +
        geom_bar() +
        ggtitle("distribuzione per month") +
        ylab("frequenza") +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_month
```

I mesi di ultima chiamata sono prevalentemente quelli estivi. La campagna di marketing è andata avant per due anni, quindi non è chiaro se ci sia stato o meno ogni anno un focus particolare in estate, quando magari l'operatività corrente è inferiore.


```{r month_y graph and table}
t_month_y <- bank0 %>%
        group_by (month) %>%
        summarise (frequenza = n(), tasso_sottoscrizioni = mean(y=="yes")) %>%
        mutate(frequenza_relativa = frequenza / sum(frequenza)) %>%
        select(month, frequenza, frequenza_relativa, tasso_sottoscrizioni)
kable(t_month_y, digits = 4, format = "markdown")

g_month_y  <- ggplot(bank0, aes(x = month, fill = y)) +
        geom_bar(position = "fill") +
        geom_hline(yintercept = mean(bank0$y!="yes"), width = 2, col = "black", linetype = 2) +
        ggtitle("penetrazione per month") +
        ylab("tasso sottoscrizioni") +
        scale_y_continuous(breaks = seq(0, 1, 0.1)) +
        scale_fill_discrete(name="Sottoscrizione", labels=c("no", "sì")) +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_month_y
```

I  mesi di maggior sottoscrizione, in percentuale, sono quelli con il minor numero di contatti. Si sottoscrive pochissimo d'estate, infatti, e questo dovrebbe indurci a pensare che il management non ponga un focus particolare sul fare gli outbound d'estate. Anche qui l'interazione con il numero di contatti precedenti può essere importante, e idem per la durata dell'ultima chiamata: se ci sono ultime chiamate molto lunghe (magari perché si sta vendendo il prodotto) allora ci può stare che se ne facciano di meno in alcuni mesi.

```{r month IV}
month_woe <- bank0 %>%
        select(month, y) %>%
        group_by(month) %>%
        summarise(n_no = sum(y == "no"), n_y = sum(y == "yes")) %>%
        mutate (perc_no = n_no / sum(n_no), perc_y = n_y / sum(n_y)) %>%
        select (starts_with("perc"))
month_woe$woe <- log(month_woe$perc_no / month_woe$perc_y)
month_IV <- sum((month_woe$perc_no - month_woe$perc_y) * month_woe$woe)
month_IV
```

Predittività molto forte.

###Duration

Durata in secondi dell'ultima chiamata effettuata al cliente. Se il valore è pari a zero significa che all'ultima chiamata il cliente non ha risposto. Analizziamo la distribuzione univariata:

```{r duration quant graph and table}
summary(bank0$duration)
duration_quantile <- quantile(bank0$duration, c(seq(0.1, 1, 0.05)))
duration_quantile

g_duration <- ggplot(bank0, aes(x = duration)) + 
        geom_histogram(binwidth = 20) +
        ggtitle("distribuzione di duration") +
        xlab("duration") +
        ylab("frequenza") +
        scale_x_continuous(breaks = seq(0, 5000, 250))+
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_duration
```

Una distribuzione molto concentrata in un piccolo intervallo, il 70% delle chiamate non supera i 280 secondi. Vediamo se il comportamento della variabile cambia considerando chi sottoscrive e chi non sottoscrive.

```{r duration_y quant graph}
g_duration_y <- ggplot(bank0, aes(x = y, y = duration)) + 
        geom_boxplot(aes(col = y)) +
        ggtitle("distribuzione di duration per sottoscrizione") +
        xlab("sottoscrizione") +
        scale_x_discrete(labels = c("no", "sì")) +
        scale_color_discrete(name="Sottoscrizione", labels=c("no", "sì"))
g_duration_y
```


```{r duration_class_y table and graph}
duration_decile <- quantile(bank0$duration[bank0$duration != 0], probs = seq(0.1,1,0.1))
bank0$duration_class <- cut(bank0$duration, breaks = c(-1, 0, duration_decile), right = TRUE, labels = c("no call", "(0,58]",  "(58,89]", "(89,117]", "(117,147]"," (147,180]", "(180,223]", "(223,280]", "(280,368]", "(368,548]", "(548,4918]"))

t_duration_class_y <- bank0 %>%
        group_by (duration_class) %>%
        summarise (frequenza = n(), tasso_sottoscrizioni = mean(y=="yes")) %>%
        mutate(frequenza_relativa = frequenza / sum(frequenza)) %>%
        select(duration_class, frequenza, frequenza_relativa, tasso_sottoscrizioni)
kable(t_duration_class_y, digits = 4, format = "markdown")

g_duration_class_y  <- ggplot(bank0, aes(x = duration_class, fill = y)) +
        geom_bar(position = "fill") +
        geom_hline(yintercept = mean(bank0$y!="yes"), width = 2, col = "black", linetype = 2) +
        ggtitle("penetrazione per duration_class") +
        ylab("tasso sottoscrizioni") +
        scale_y_continuous(breaks = seq(0, 1, 0.1)) +
        scale_fill_discrete(name="Sottoscrizione", labels=c("no", "sì")) +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_duration_class_y
```

Muovendosi all'interno dei 10 gruppi di dimensioni simili il tasso di sottoscrizione aumenta all'aumentare della durata della chiamata. La cosa ha senso, dato che una chiamata in cui si vende richiede tempo lunghi perché il cliente è molto interessato al prodotto e inoltre dovrà assolvere a dei questionari burocratici. Tuttavia la durata della chiamata non è nota in anticipo, quindi non ha senso includere la variabile in un modello predittivo.

```{r duration IV} 
#devo togliere i tre valori nulli di duration altrimenti la formula va in errore
duration_class_woe <- bank0 %>%
        filter(duration_class != "no call") %>%
        select(duration_class, y) %>%
        group_by(duration_class) %>%
        summarise(n_no = sum(y == "no"), n_y = sum(y == "yes")) %>%
        mutate (perc_no = n_no / sum(n_no), perc_y = n_y / sum(n_y)) %>%
        select (starts_with("perc"))
duration_class_woe$woe <- log(duration_class_woe$perc_no / duration_class_woe$perc_y)
duration_class_IV <- sum((duration_class_woe$perc_no - duration_class_woe$perc_y) * duration_class_woe$woe)
duration_class_IV
```

è infatti un valore di 1.6 è davvero sospetto, troppo alto per essere vero.

###Campaign

Numero di contatti complessivi avuto con il cliente durante la campagna promozionale. Include l'ultimo contatto.

```{r campaign quant table and graph}
summary(bank0$campaign)
campaign_quantile <- quantile(bank0$campaign, c(seq(0.1, 1, 0.05)))
campaign_quantile

g_campaign <- ggplot(bank0, aes(x = factor(campaign))) + 
        geom_histogram(binwidth = 1) +
        ggtitle("distribuzione di duration") +
        xlab("campaign") +
        ylab("frequenza") +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_campaign
```

Il 95% dei valori è tra 1 e 8 contatti. Ha senso raggruppare la variabile in classi 

```{r campaign_class table and graph}
bank0$campaign_class <- cut(bank0$campaign, breaks = c(0, 1, 2, 3, 4, 5, max(bank0$campaign)+1), right = TRUE, labels = c("1", "2", "3", "4", "5", "up 5"))

t_campaign_class  <- bank0 %>%
        group_by(campaign_class) %>%
        summarise(frequenza = n()) %>%
        mutate(frequenza_relativa = frequenza / sum(frequenza))
kable(t_campaign_class, digits = 4, format = "markdown")

g_campaign_class  <- ggplot(bank0, aes(x = campaign_class)) +
        geom_bar() +
        ggtitle("distribuzione per campaign_class") +
        ylab("frequenza") +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_campaign_class
```

Vediamo come si comportano i sottoscrittori attraverso i vari livelli di `campaign`.

```{r campaign_class_ table and graph}
t_campaign_class_y <- bank0 %>%
        group_by (campaign_class) %>%
        summarise (frequenza = n(), tasso_sottoscrizioni = mean(y=="yes")) %>%
        mutate(frequenza_relativa = frequenza / sum(frequenza)) %>%
        select(campaign_class, frequenza, frequenza_relativa, tasso_sottoscrizioni)
kable(t_campaign_class_y, digits = 4, format = "markdown")

g_campaign_class_y  <- ggplot(bank0, aes(x = campaign_class, fill = y)) +
        geom_bar(position = "fill") +
        geom_hline(yintercept = mean(bank0$y!="yes"), width = 2, col = "black", linetype = 2) +
        ggtitle("penetrazione per campaign_class") +
        ylab("tasso sottoscrizioni") +
        scale_y_continuous(breaks = seq(0, 1, 0.1)) +
        scale_fill_discrete(name="Sottoscrizione", labels=c("no", "sì")) +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_campaign_class_y
```

Meno chiamate vengono fatte ai clienti, più si vende (in proporzione). Significa che al cliente davvero interessato basta una chiamata. Solo la fascia "1 contatto" ha un tasso di sottoscrizione superiore a quello complessivo, questa è una informazione rilevante. Vediamo l'information value:

```{r campaign IV}
campaign_class_woe <- bank0 %>%
        select(campaign_class, y) %>%
        group_by(campaign_class) %>%
        summarise(n_no = sum(y == "no"), n_y = sum(y == "yes")) %>%
        mutate (perc_no = n_no / sum(n_no), perc_y = n_y / sum(n_y)) %>%
        select (starts_with("perc"))
campaign_class_woe$woe <- log(campaign_class_woe$perc_no / campaign_class_woe$perc_y)
campaign_class_IV <- sum((campaign_class_woe$perc_no - campaign_class_woe$perc_y) * campaign_class_woe$woe)
campaign_class_IV
```

0.08, predittore debole.

###pdays

Variabile che rileva il numero di giorni trascorsi da quando il cliente è stato contattato per una precedente campagna. Se `pdays = -1` allora il cliente non è stato mai contattato per la precedente campagna.

Vediamo come si distribuisce la variabile se il cliente è stato contattato.

```{r pdays quant graph and table}
summary(bank0$pdays[bank0$pdays != -1])
pdays_decile <- quantile(bank0$pdays[bank0$pdays != -1], c(seq(0.1, 1, 0.1)))

g_pdays_quant <- bank0  %>% 
        filter(pdays != -1) %>% 
        ggplot(aes(x = pdays)) + 
        geom_histogram(binwidth = 10) +
        ggtitle("distribuzione di pdays") +
        xlab("pdays") +
        ylab("frequenza") +
        scale_x_continuous(breaks = seq(0, 871, 50))+
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_pdays_quant
````

Una distribuzione quasi trimodale; immagino che nell'attuale campagna ci siano stati dei periodi con maggiore concentrazione di chiamate, che hanno generato quelle tre mode. Anche la variabile `month` conferma che ci sono stati mesi con molta più concentrazione di chiamate. Vediamo come si dsitribuisce `pdays` condizionando per la sottoscrizione:

```{r pdays_y quant graph}
g_pdays_quant_y <- bank0 %>% 
        filter(pdays != -1) %>% 
        ggplot(aes(x = y, y = pdays)) + 
        geom_boxplot(aes(col = y)) +
        ggtitle("distribuzione di pdays per sottoscrizione") +
        xlab("sottoscrizione") +
        scale_x_discrete(labels = c("no", "sì")) +
        scale_color_discrete(name="Sottoscrizione", labels=c("no", "sì"))
g_pdays_quant_y
```

Chi non sottoscrive è un cliente per cui sono trascorsi più giorni dall'ultimo contatto. Questo ha senso. Dobbiamo tuttavia indagare il comportamento dei sottoscrittori anche tra chi non è mai stato contatatto, e per questo raggruppiamo la variabile in classi, una per i non contattati e poi dieci in base ai decili.

```{r pdays_class table}
bank0$pdays_class <- cut(bank0$pdays, breaks = c(-2, 0, pdays_decile), right = TRUE, labels = c("no campaign", "(0,91]",  "(91,108]", "(108,159]", "(159,181]"," (181,194]", "(194,258]", "(258,300]", "(300,343]", "(343,362]", "(362,871]"))
table(bank0$pdays_class)
```

Circa l'80% dei clienti contattati per questa campagna non è mai stato contattato precedentemente. Ora vediamo come il tasso di sottoscrizione si distribuisce all'interno delle 11 classi:

```{r pdays_class_y table and graph}
t_pdays_class_y <- bank0 %>%
        group_by (pdays_class) %>%
        summarise (frequenza = n(), tasso_sottoscrizioni = mean(y=="yes")) %>%
        mutate(frequenza_relativa = frequenza / sum(frequenza)) %>%
        select(pdays_class, frequenza, frequenza_relativa, tasso_sottoscrizioni)
kable(t_pdays_class_y, digits = 4, format = "markdown")

g_pdays_class_y  <- ggplot(bank0, aes(x = pdays_class, fill = y)) +
        geom_bar(position = "fill") +
        geom_hline(yintercept = mean(bank0$y!="yes"), width = 2, col = "black", linetype = 2) +
        ggtitle("penetrazione per pdays_class") +
        ylab("tasso sottoscrizioni") +
        scale_y_continuous(breaks = seq(0, 1, 0.1)) +
        scale_fill_discrete(name="Sottoscrizione", labels=c("no", "sì")) +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_pdays_class_y
```

In generale se in passato si è stati contattati si sottoscrive di più che se non lo si è mai stati; il tasso non decresce in maniera monotona ma la distribuzione sembra comunque abbastanza informativa.

```{r pdays_class IV}
pdays_class_woe <- bank0 %>%
        select(pdays_class, y) %>%
        group_by(pdays_class) %>%
        summarise(n_no = sum(y == "no"), n_y = sum(y == "yes")) %>%
        mutate (perc_no = n_no / sum(n_no), perc_y = n_y / sum(n_y)) %>%
        select (starts_with("perc"))
pdays_class_woe$woe <- log(pdays_class_woe$perc_no / pdays_class_woe$perc_y)
pdays_class_IV <- sum((pdays_class_woe$perc_no - pdays_class_woe$perc_y) * pdays_class_woe$woe)
pdays_class_IV
```

Infatti 0.34 come information value significa predittore potente.

###Previous

Numero di volte in cui il cliente è stato contattato prima di questa campagna.

```{r previous quant table and graph}
previous_decile <- quantile(bank0$previous, c(seq(0.1, 1, 0.1)))
previous_decile

g_previous_quant <- ggplot(bank0, aes(x = previous)) + 
        geom_histogram(binwidth = 5) +
        ggtitle("distribuzione di previous") +
        xlab("pdays") +
        ylab("frequenza") +
        scale_x_continuous(breaks = seq(0, 275, 5))+
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_previous_quant
````

L'80% dei clienti non è mai stato contattato, è una distribuzione molto strana. Vediamo distinguendo tra sottoscrittori e non in un boxplot:

```{r previous_y quant graph}
g_previous_quant_y <- ggplot(bank0, aes(x = y, y = previous)) + 
        geom_boxplot(aes(col = y)) +
        ggtitle("distribuzione di previous per sottoscrizione") +
        xlab("sottoscrizione") +
        scale_x_discrete(labels = c("no", "sì")) +
        scale_y_continuous(breaks = seq(0, 200, 10)) +
        scale_color_discrete(name="Sottoscrizione", labels=c("no", "sì"))
g_previous_quant_y
```

In questo modo individuare una associazione tra `previous` e sottoscrizione è impossibile. Raggruppiamo in classi, anche se mi aspetto una forte correlazione con `pdays`.
 
```{r previous_class table}
previous_nz_quantile <- quantile(bank0$previous[bank0$previous > 0], probs = seq(0.1,1,0.1))
#Considerando i decili, preferisco fare 7 classi di non pari frequenza: da 0 a 6 e maggiore di 6
bank0$previous_class <- cut(bank0$previous, breaks = c(0, 1, 2, 3, 4, 5, 7, max(bank0$previous)+1), right = FALSE, labels = c("0 contact", "1 contact",  "2 contact", "3 contact", "4 contact","5 or 6 contact", "+ 6 contact"))
table(bank0$previous_class)
summary(bank0$previous_class)
```

```{r previous_class_y graph and table}
t_previous_class_y <- bank0 %>%
        group_by (previous_class) %>%
        summarise (frequenza = n(), tasso_sottoscrizioni = mean(y=="yes")) %>%
        mutate(frequenza_relativa = frequenza / sum(frequenza)) %>%
        select(previous_class, frequenza, frequenza_relativa, tasso_sottoscrizioni)
kable(t_previous_class_y, digits = 4, format = "markdown")

g_previous_class_y  <- ggplot(bank0, aes(x = previous_class, fill = y)) +
        geom_bar(position = "fill") +
        geom_hline(yintercept = mean(bank0$y!="yes"), width = 2, col = "black", linetype = 2) +
        ggtitle("penetrazione per previous_class") +
        ylab("tasso sottoscrizioni") +
        scale_y_continuous(breaks = seq(0, 1, 0.1)) +
        scale_fill_discrete(name="Sottoscrizione", labels=c("no", "sì")) +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_previous_class_y
```

Anche qui c'è un comportamento chiaro: se non si è mai stati contattati si sottoscrive meno (in proporzione) della media, altrimenti sensibilmente di più. Mi aspetto forte predittività:

```{r previous_class IV}
previous_class_woe <- bank0 %>%
        select(previous_class, y) %>%
        group_by(previous_class) %>%
        summarise(n_no = sum(y == "no"), n_y = sum(y == "yes")) %>%
        mutate (perc_no = n_no / sum(n_no), perc_y = n_y / sum(n_y)) %>%
        select (starts_with("perc"))
previous_class_woe$woe <- log(previous_class_woe$perc_no / previous_class_woe$perc_y)
previous_class_IV <- sum((previous_class_woe$perc_no - previous_class_woe$perc_y) * previous_class_woe$woe)
previous_class_IV
```

0.22 è vicina ad essere forte predittività.

###Poutcome

Esito della precedente campagna promozionale per il medesimo cliente. Analizziamo subito la distribuzione univariata:

```{r poutcome table and graph }
t_poutcome <- bank0 %>%
        group_by (poutcome) %>%
        summarise (frequenza = n()) %>%
        mutate (frequenza_relativa = frequenza / sum(frequenza)) %>%
        arrange(desc(frequenza_relativa))
kable(t_poutcome, digits = 4, format = "markdown")

g_poutcome  <- ggplot(bank0, aes(x = poutcome)) +
        geom_bar() +
        ggtitle("distribuzione per poutcome") +
        ylab("frequenza") +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_poutcome
```

Gli "unknown" saranno senz'altro quell'80% di clienti mai contattati. Vediamo nelle quattro fascie come si sottoscrive:

```{r poutcome_y table and graph}
t_poutcome_y <- bank0 %>%
        group_by (poutcome) %>%
        summarise (frequenza = n(), tasso_sottoscrizioni = mean(y=="yes")) %>%
        mutate(frequenza_relativa = frequenza / sum(frequenza)) %>%
        select(poutcome, frequenza, frequenza_relativa, tasso_sottoscrizioni) %>%
        arrange(desc(tasso_sottoscrizioni))
kable(t_poutcome_y, digits = 4, format = "markdown")

g_poutcome_y  <- ggplot(bank0, aes(x = poutcome, fill = y)) +
        geom_bar(position = "fill") +
        geom_hline(yintercept = mean(bank0$y!="yes"), width = 2, col = "black", linetype = 2) +
        ggtitle("penetrazione per poutcome") +
        ylab("tasso sottoscrizioni") +
        scale_y_continuous(breaks = seq(0, 1, 0.1)) +
        scale_fill_discrete(name="Sottoscrizione", labels=c("no", "sì")) +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_poutcome_y
```

Se la precedente campagna ha avuto successo si sottoscrive in percentuali altissime. Persino se è stata fallimentare però si sottoscrive di più che se non si è mai stati contatatti; questo è coerente con l'analisi di `previous`, per cui il gruppo dei contattati sottoscriveva comunque di più dei mai contatatti.

```{r poutcome IV}
poutcome_woe <- bank0 %>%
        select(poutcome, y) %>%
        group_by(poutcome) %>%
        summarise(n_no = sum(y == "no"), n_y = sum(y == "yes")) %>%
        mutate (perc_no = n_no / sum(n_no), perc_y = n_y / sum(n_y)) %>%
        select (starts_with("perc"))
poutcome_woe$woe <- log(poutcome_woe$perc_no / poutcome_woe$perc_y)
poutcome_IV <- sum((poutcome_woe$perc_no - poutcome_woe$perc_y) * poutcome_woe$woe)
poutcome_IV
```

0.51, molto predittiva, ai limiti del sospetto.

###Information values

Creiamo il vettore degli information values e lo rappresentiamo tramite grafico:

```{r all IV table}
names(bank0)
IV <- c(age_class_IV, job_IV, marital_IV, education_IV, default_IV, balance_class_IV, housing_IV, loan_IV, contact_IV, day_IV, month_IV, duration_class_IV, campaign_class_IV, pdays_class_IV, previous_class_IV, poutcome_IV)
Variables <- c("age_class", "job", "marital", "education", "default", "balance_class", "housing", "loan", "contact", "day", "month", "duration_class", "campaign_class", "pdays_class", "previous_class", "poutcome")
t_IV_all <- data.frame(Variables, IV)
t_IV_all <- t_IV_all %>%
        arrange(desc(IV))
t_IV_all
```

```{r all IV graph}
g_IV_all <- ggplot(t_IV_all, aes(x= reorder(Variables, IV), y= IV)) +
        geom_bar(stat='identity') +
        coord_flip() +
        ggtitle ("Information values") +
        ylab("Variabili") +
        xlab("Inromation value") +
        geom_hline(yintercept = c(0.02, 0.1, 0.3, 0.5), linewidth = 2, linetype = 2, col = c("yellow", "blue", "green", "red"))
g_IV_all
```

Le 4 rette trattegiate indicano le soglie per: predittività assente (tra asse e retta gialla), debole (tra retta gialla e blue), media (tra retta blu e verde), forte (tra retta verde e rossa), sospetta (oltre retta rossa).

**ricominciare da qui**

##Esplorazione dell'associazione tra coppie di variabili e in relazione alla sottoscrizione

###Matrice dei grafici bivariati

```{r ggpairs, fig.width=20, fig.height=20}
#bank0_prof_ggpairs <- ggpairs(bank0_sm[])
#bank0_contact_ggpairs <- ggpairs(bank0_sm[])
#bank0_campaign_ggpairs <- ggpairs(bank0_sm[])


```

#Tre tipologie di relazione tra tre variabili
Forniamo un breve commento ai tre esempi che seguono. 

Al punto 1 presentiamo la situazione detta *spiegazione*. La tab. 3 mostra la tabella a doppia entrata originale che mette in relazione il numero delle pompe antincendio presenti sul luogo di un incendio e l’entità dei danni dello stesso. Come si vede tra le due variabili vi è relazione: solo il 30% degli incidenti è caratterizzato da danni superiori a 10.000$ se le autopompe non sono più di 2, sale al 59% se le autopompe sono più di 2. Naturalmente il numero di autopompe che vengono inviate sul luogo dell’incendio sarà legato alle dimensioni dell’incendio stesso e quindi al presumibile danno prodotto. Quindi occorre *controllare la relazione originale* introducendo la variabile “dimensione dell’incendio”. Si vede così in tab 1 che a parità di dimensioni dell’incendio, non vi è alcuna relazione tra numero di autopompe e ammontare del danno: se le dimensioni sono ridotte solo il 5% degli incendi produce un danno superiore a 10.000$, indipendentemente dal numero di autopompe presenti; questa percentuale sale all’80% quando l’incendio è di ampie dimensioni, anche qui indipendentemente dal numero di autopompe coinvolte. E’ ovvio che il numero di autopompe non può determinare le dimensioni dell’incendio, ma ne è una sua conseguenza. Il numero di autopompe non determina neppure l’ammontare dei danni. In realtà le dimensioni causano sia il numero di autopompe che l’ammontare del danno, così che la relazione tra autopompe e danno è fittizia, dovuta esclusivamente alla terza variabile, perciò *spuria*. => Non so se il confondimento implica che la relazione sia spuria.

Al punto 2 presentiamo la situazione detta *interpretazione*. La tab. 6 mostra la tabella a doppia entrata originale che mette in relazione sesso e coinvolgimento in incidenti. Come si vede le donne hanno meno incidenti dei maschi: 32% e 44% rispettivamente. Bisogna però considerare che, al di là della prudenza e delle capacità di guida, il semplice fatto di percorrere mediamente più chilometri espone ad una probabilità maggiore di incorrere in incidenti. Se introduciamo come terza variabile la percorrenza chilometrica annua (tab. 4) vediamo che la relazione tra sesso e incidenti sparisce: se la percorrenza è bassa il 25% dei conducenti è coinvolto in incidenti qualunque sia il suo sesso; se la percorrenza è alta questa percentuale sale al 52% sia tra i maschi che tra le femmine. *A prima vista, la relazione tra sesso e incidenti potrebbe apparire spuria come nell’esempio precedente. Qui però vi è una differenza fondamentale: la terza variabile non è la causa delle due variabili originali (la percorrenza non causa il sesso del conducente)*. *Siamo invece in presenza di una catena causale: il sesso causa la percorrenza che a sua volta causa il coinvolgimento in incidenti. Insomma la relazione tra sesso e incidenti non è fittizia*, appare a prima vista incomprensibile perché è *mediata* da una variabile intermedia, la percorrenza. E’ in questo senso che si dice che la relazione originale è interpretata. Anche qui forniamo la tab. 5, forma compatta della tab. 4.=> l'interpretazione è quando tra la relazione causale tra2 variabili se ne include una terza intermedia che cambia l'interpretazione della relazione, che comunque ha senso, non è spuria come nobel e cioccolato.

Al punto 3 presentiamo la situazione detta *specificazione*. La tab. 9 mostra la tabella a doppia entrata originale che mette in relazione orientamento politico e interesse per la politica. La tab. 7 mostra cosa accade *quando introduciamo come variabile di controllo*, il titolo di studio. In origine tra coloro che si collocano a sinistra il 28% ha un interesse alto, che scende al 15% tra i soggetti di destra. Questa differenza resta anche quando si introduce la terza variabile. Bisogna però notare che tra coloro che hanno un basso grado di istruzione i valori sono pari a 19% e 7%, cioè valori più bassi di quelli della relazione bivariata e con una differenza tra sinistra e destra equivalente. Tra coloro invece che hanno un elevato titolo di studio l’interesse per la politica aumenta: coloro che sono molto interessati crescono rispettivamente al 36% e al 18%, rispettivamente per sinistra e destra, con una differenza tra i due pari a 18 punti percentuali, contro i 13 della relazione originaria. Qui entrambe le variabili “orientamento” e “titolo” influenzano la dipendente ed è per questo che si parla di “specificazione” della relazione originale.=> a me questo sembra effetto di interazione: l'introduzione di una terza variabile porta a un effetto congiunto delle due indipendenti che è piu (perché cambiano le differenze tra i valori) della loro moltiplicazione.

#Link utili

* [epidemiologia1](http://www.quadernodiepidemiologia.it/epi/freq/stn_mis.htm)
* [epidemiologia2](http://www.quadernodiepidemiologia.it/epi/assoc/ass_nc.htm)
* [confounding and interaction](https://www.ctspedia.org/do/view/CTSpedia/InterConfound)
* [stratified analysis - il più importante](http://www.sjsu.edu/faculty/gerstman/StatPrimer/stratified.PDF)

L'ultimo link, un pdf, è semplicemente illuminante. Così come il paragrafo che ho copiato sopra.

#Confounding and interaction: crude vs stratified analysis.
Confounding (from the Latin confundere: to mix together) is a *distortion of an association* between an exposure (E) and disease (D) brought about by extraneous factors (C1, C2, etc). Since confounding is a systematic (not random) error, hypothesis testing cannot be used to detect it. It is a judgement based science. The analyst should start with simple comparisons of means and proportions.

Interaction, as distinct from confounding, is the interdependent operation of two or more factors to produce an unanticipated effect. Interactions is usually addressed by reporting data by subgroups.

Measures of association in the aggregate are called crude measures of association.

Stratification might reveal otherwise hidden confounding and interaction. Example with RR; se il RR crudo è 4.00, e stratificando per i tre livelli di C abbiamo sempre RRC=4.00, allora la stratificazione è superflua. Se RRC = 1.00 sempre, allora c'è confounding. Se RRC = 1.00, 3.00, 25.00, c'è interazione.

Spesso c'è in parte confounding e in parte interaction. The best estimate of association is both valid and precise. If interaction is present, strata-specific measures of association are reported. If interaction is absent but confounding is present, summary (adjusted) measures of association are reported. If neither interaction nor confounding are present, crude (unadjusted) measures of association are reported. In general, the most parsimoniously unconfounded presentation of the data is preferred. If the association between the exposure and disease is not found by scrutinizing the data in the 2-by-2 table, it's hard to support. Simple is better. 
Qui si parla di RR e di quale va riportato se c'è confounding e/o se c'è interaction.

##previous e poutcome

In questo caso sia il numero di contatti della precedente campagna che l'esito della precedente campagna sono predittive. Solo che osservando che al crescere dei contatti della precedente campagna cresce la conversion dell'attuale, mi domando se in realtà non sia stato la predisposizione a convertire della precedente campagna a generare sia tanti contatti (mi faccio chiamare e risponso perché interessato) che l'attuale conversion (ero e sono interessato a sottoscrivere prodotti aggiuntivi).


```{r previos_poutcome_y table}
t_previous_y <- bank0 %>%
        group_by(previous_class) %>%
        summarise(n = n(), y_rate = mean(y == "yes")) %>%
        mutate(freq_rel = n / sum(n)) %>%
        select(previous_class, y_rate)

t_previous_poutcome_y <- bank0 %>%
        group_by(previous_class, poutcome) %>%
        summarise(n = n(), y_rate = mean(y == "yes")) %>%
        mutate(freq_rel = n / sum(n)) %>%
        select(previous_class, poutcome, y_rate) %>%
        spread(previous_class, y_rate)

g_previous_class_poutcome_f <- g_previous_class + facet_wrap(~poutcome)
g_previous_class_poutcome <- ggplot(bank0, aes(x = factor(previous_class), fill = poutcome)) +
        geom_bar(position = "fill")
g_previous_poutcome_y <- g_previous_class_y + facet_wrap(~poutcome)
g_previous_class_y
```

Ora, per ogni esito della precedente campagna, il numero dei contatti discrimina molto meno che nella crude analysis (tranne che per esito sconosciuto, che però coincide con contati zero, cioè nessuna partecipazione alla precedente campagna). Perciò la mia ipotesi è abbastanza confermata, poutcome ci permette di interpretare abbastanza la relazione tra contatti e conversion.
Come controprova, faccio il condizionamento al contrario:

```{r}
g_poutcome_previos_y <- g_poutcome_y + facet_wrap(~previous_class)
g_poutcome_previos_y
```

Per ogni contatto c'è una bella discriminazione della conversion, perciò la mia ipotesi era esatta. è la predispozione a convertire nella vecchia campagna che contribuisce a determinare il numero di contatti e la nuova conversion.

*La conclusione è che se includeremo nel modello previous andrebbe incluso anche poutcome, come variabile di controllo? Oppure basta poutcome? Mah, alla fine soprattutto per il livello failure, il numero di contatti discrimina, quindi includerei entrambe.*.

##Age e job

```{r age job graph}
g_age_class <- ggplot(bank0, aes(x = age_class)) + 
        geom_bar()
g_age_class_y <- ggplot(bank0, aes(x = age_class, fill = y)) + 
        geom_bar(position = "fill") + 
        geom_hline(yintercept = mean(bank0$y!="yes"), width = 2, col = "black", linetype = 2)
g_age_class_y
g_job
g_job_y

g_job_age_class <- ggplot(bank0, aes(x = job, fill = age_class)) + 
        geom_bar(position = "fill") + 
        geom_hline(yintercept = mean(bank0$y!="yes"), width = 2, col = "black", linetype = 2)
g_job_age_class
#distribuzione molto sbilanciata della variabile di controllo per i due livelli studenee pensionato, probabile che age aiuti a capire la relazione tra job e conversion.

g_job_age_class_y <- ggplot(bank0, aes(x = job, fill = y)) + 
        geom_bar(position = "fill") + 
        geom_hline(yintercept = mean(bank0$y!="yes"), width = 2, col = "black", linetype = 2) +
        facet_wrap(~age_class) +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_job_age_class_y
```

La proporzione delle fasce di età nei job mostra squilibri; ci sono molte professioni dove quasi tutti sono adulti, gli studenti poi sono quasi tutti giovani e i pensionati sono metà adulti e metà anziani. Mentre la relazione tra job e conversion ci dice che i pensionati convertono di più, controllando per l'età vediamo che convertono non se pensionati, ma se pensionati vecchi. Se vai in pensione adulto non converti. 

Se ci limitiamo agli anziani, tutti i job convertono molto, ma comunque i pensionati di più. Quindi è chiaro che i pensionati crudamente convertono di più perché in essi la metà è anziana, ma comunque tra gli anziani i pensionati convertono più degli altri. Essere vecchio ti fa convertire, essere vecchio e in pensione ancora di più. Vi è una qualche interazione.

Invece gli studenti convertono anche se adulti; se si osserva la conversion per fasce di età, gli adulti convertono nella media; se invece sei adulto ma studente converti più della media, perciò essere studente è legato al convertire a prescindere (in parte) dall'età.

Il problema andrebbe complicato ragionando sui volumi bassi di alcuni sottogruppi.

##Age e marital

```{r age and marital univariate graph}
g_age
g_age_y
g_age_class
g_age_class_y
g_marital
g_marital_y
```

Voglio capire se i single convertono in quanto giovani, con l'età a fare da confounder o effect modifier.

```{r age and marital bivariate graph}
g_marital_age_class <- ggplot(bank0, aes(x = marital, fill = age_class)) + 
        geom_bar(position = "fill") 
g_marital_age_class
#infatti la proporzione di giovani nei single è altissima, negli altri due casi lo stato maritale e l'età sono quasi indipendenti
g_marital_age_class_y <- ggplot(bank0, aes(x = marital, fill = y)) + 
        geom_bar(position = "fill") + 
        geom_hline(yintercept = mean(bank0$y!="yes"), width = 2, col = "black", linetype = 2) +
        facet_wrap(~age_class)
g_marital_age_class_y
```


```{r age and marital bivariate table}
t_marital_age_class <- bank0 %>%
        group_by(marital, age_class) %>%
        summarise(n = n(), y_rate = mean(y == "yes")) %>%
        mutate(freq_rel = n / sum(n))

t_marital_age_class_y <- bank0 %>%
        group_by(marital, age_class) %>%
        summarise(y_rate = mean(y == "yes")) %>%
        select(marital, age_class, y_rate) %>%
        spread(marital, y_rate)
t_marital_y
```

Gli anziani single sono 61, quindi la predittività è poco significativa.

La mia ipotesi di partenza è che i single convertissero in quanto giovani. L'ipotesi sembra confermata; innanzitutto la proporzione di giovani tra i single è molto più alta che negli altri due stati maritali, dove la proporzione è quasi identica (e ci può stare, e dove non è identica è perché in divorced ci sono anche i vedovi). Analizzando poi il comportamento dei tre stati per ogni fascia di età, si vede che se sei giovane converti solo se sei anche single, se sei giovane ma sposato (2060 casi) non converti. Quindi l'età non fa da confounder, ma da effect modifier, perché nella fascia giovanile la conversion dei single è potenziata rispetto a quella complessiva, per quanto il trend sia identico (minor conversion gli sposati, maggiore i single). Ma in realtà abbiamo scoperto che i giovani convertono solo se single. Gli anziani convertono assai, come è ovvio, ma il comportamento dei tre stati maritali (per quanto i numeri siano bassi) si invertono; anche qui c'è interazione! E di sicuro è dovuta allo specifico comportamento degli anziani vedovi.

Nella fascia adulti i tre stati maritali convertono come per tutto il portafoglio, invece.

Ma non sarà che è lo stato maritale a fare da confounding?

```{r}
g_age_class_marital_y <- ggplot(bank0, aes(x = age_class, fill = y)) + 
        geom_bar(position = "fill") + 
        geom_hline(yintercept = mean(bank0$y!="yes"), width = 2, col = "black", linetype = 2) +
        facet_wrap(~marital)
g_age_class_marital_y
```

Non abbiamo trovato confounding, ma una relazione di interazione, che ci fa dire soprattutto che i giovani che convertono sono i single. *Si potrebbe pensare di includere un effetto di interazione nel modello*.

##Education and job

Convertono di più i laureti. Magari non è questione di job che fai ma di educazione che hai.

```{r education and job graph}
g_education
g_job
g_job_y
g_education_y
g_education_job <- ggplot(bank0, aes(x = job, fill = education)) + 
        geom_bar(position = "fill") 
g_education_job

g_education_job_y <- ggplot(bank0, aes(x = job, fill = y)) + 
        geom_bar(position = "fill") + 
        geom_hline(yintercept = mean(bank0$y!="yes"), width = 2, col = "black", linetype = 2) +
        facet_wrap(~education) +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_education_job_y
```

Vedo una interazione solo nel management, che essendo pieno di laureati marginalmente coverte di più, ma se non laureato non converte. Bisogna capire i volumi, potrebbero essere bassi. Per il resto vedo comportamenti simili alla analisi cruda, con un main effect dell'education. Tuttavia anche imprenditori e liberi professionisti hanno una buona quota di laureati, e tuttavia non convertono marginalmente e gli imprenditori nemmeno solo se laureati. Il lavoro vince sulla job, diciamo, nel senso che non gli fa esercitare nemmeno il main effect (e non so se questa è una interazione, probabilmente sì).

```{r education and job table}
t_education_job <- bank0 %>%
        group_by(job, education) %>%
        summarise(n = n(), y_rate = mean(y == "yes"))
t_education_job

t_education_job_y <- bank0 %>%
        group_by(job, education) %>%
        summarise(y_rate = mean(y == "yes")) %>%
        select(job, education, y_rate) %>%
        spread(job, y_rate)
t_education_job_y
```

Non vedo grande aiuto dell'education a interpretare la relazione tra job e conversion, non includerei un effetto di interazione.

##Housing and loan

```{r loan and housing graph}
g_loan
g_housing
g_loan_y
g_housing_y
g_loan_housing <- ggplot(bank0, aes(x = loan, fill = housing)) + 
        geom_bar(position = "fill") 
g_loan_housing

g_loan_housing_y <- ggplot(bank0, aes(x = loan, fill = y)) + 
        geom_bar(position = "fill") + 
        geom_hline(yintercept = mean(bank0$y!="yes"), width = 2, col = "black", linetype = 2) +
        facet_wrap(~housing) +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_loan_housing_y
```

Vedo solo un main effect. Se hai il mutuo converti meno; dato che hai un prestito, se hai anche il mutuo converti meno se no converti di più. Magari il noxno accentua la conversion più del semplice main effect, ma non so se vale la pena testare una interazione per questo.


```{r loan and housing table}
t_loan <- bank0 %>%
        group_by(loan) %>%
        summarise(n = n(), y_rate = mean(y == "yes"))
t_loan

t_housing <- bank0 %>%
        group_by(housing) %>%
        summarise(n = n(), y_rate = mean(y == "yes"))
t_housing

t_loan_housing <- bank0 %>%
        group_by(loan, housing) %>%
        summarise(n = n(), y_rate = mean(y == "yes"))
t_loan_housing

t_loan_housing_y <- bank0 %>%
        group_by(loan, housing) %>%
        summarise(y_rate = mean(y == "yes")) %>%
        select(loan, housing, y_rate) %>%
        spread(loan, y_rate)
t_loan_housing_y

ggplot(t_loan_housing, aes(x = loan, y = y_rate, col = housing, group = housing)) + 
        geom_point (size = 4) + 
        geom_line(col= "black", linetype = 2)
```

Graficamente l'interaction effect è evidente e logicamente ha senso.

##Month and day

```{r month duration_class table }
t_month_y
g_duration_class_y
g_month
g_month_y

t_month_duration_class <- bank0 %>%
        group_by(month, duration_class) %>%
        summarise(n = n(), y_rate = mean(y == "yes")) %>%
        mutate(n_rel = n / sum(n)) %>%
        select(duration_class, month, n_rel) %>%
        spread(duration_class, n_rel, fill = 0) %>%
        left_join(t_month_y, by = "month") %>%
        select(-frequenza, -frequenza_relativa) %>%
        arrange(desc(tasso_sottoscrizioni))
```

I mesi di maggior conversion hanno pochissimi volumi. Posto che volumi così bassi non sono significativi, è curioso che la conversion sia sempre altissima e non è mai, che so, bassissima. Noi non sappiamo il numero di chiamate svolte ogni mese dal call center, perché questa variabile conteggia l'ultima chiamata al cliente, che io immagino (per coerenza su come viene definita duration) sia quella di conversion o abbandono.

Si nota tuttavia che nei mesi di maggior conversion / volumi bassi non c'è una particolare concentrazione di chiamate lunghe, come a dire: minori chiamate, maggiore qualità / lunghezza => conversion. Mi rimane solo l'ausilio grafico per smentire l'associazione tra bassi volumi di ultime chiamate e conversion causa qualità.

```{r month duration_class graph}
g_month_duration_class_y <- ggplot(bank0, aes(x = month, fill = y)) + 
        geom_bar(position = "fill") + 
        geom_hline(yintercept = mean(bank0$y!="yes"), width = 2, col = "black", linetype = 2) +
        facet_wrap(~duration_class) +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_month_duration_class_y
```

Mi sembra che a parità di durata delle chiamate l'effetto è che: se la chiamata è breve non si converte in nessun mese (main effect puro), poi il trend tra i mesi è simile per i vari livelli di duration, sempre tenendo conto del main effect.Tendo quindi a pensare che ci sia davvero una stagionalità, e forse il numero basso di chiamate nei mesi in cui la conversion è alta è dovuto al raggiungimento anticipato dei contratti da sottoscrivere. Posso confermare questa ultima tesi facendo un conteggio dei contratti per mese

```{r month table 2}
t_month_y2 <- bank0 %>%
        group_by (month) %>%
        summarise(y_sum = sum(y == "yes"), y_rate = mean(y == "yes")) %>%
        arrange(desc(y_rate))
```

No, la mia ipotesi era errata.
L'ultima cosa che vedo è la distribuzione di duration per mese. Non mi aspetto che sia sbilanciata.

```{r month duration_class graph 2}
g_month_duration_class <- ggplot(bank0, aes(x = month, fill = duration_class)) + 
        geom_bar(position = "fill") 
g_month_duration_class
```

Non è sbilanciata, marzo è uguale a maggio. Non c'è stata una maggiore dedizione alla telefonata nei mesi di bassi volumi. Io la variabile month la inserisco con riserva, deve esserci della stagionalità.


```{r partizione training e test}
#set.seed(19121984)

#training_set <- bank0 %>%
       # add_rownames() %>%
       # sample_frac(0.8, replace = FALSE)

#test_set <- bank0 %>%
      #  add_rownames() %>%
       # sample_frac(1, replace = FALSE) %>%
        #anti_join(training_set, by = "rowname")
#check ok, sono diversi
```

```{r k fold in training}
#set.seed(123)
#flds <- createFolds(training_set$y, k = 10, list = TRUE, returnTrain = FALSE)
#bank_fold1 <- training_set[flds[[1]], ]
#bank_fold2 <- training_set[flds[[2]], ]
#bank_fold3 <- training_set[flds[[3]], ]
#bank_fold4 <- training_set[flds[[4]], ]
#bank_fold5 <- training_set[flds[[5]], ]
#bank_fold6 <- training_set[flds[[6]], ]
#bank_fold7 <- training_set[flds[[7]], ]
#bank_fold8 <- training_set[flds[[8]], ]
#bank_fold9 <- training_set[flds[[9]], ]
#bank_fold10 <- training_set[flds[[10]], ]
```


#Validation set apprach

Creo training_vsa, validation_vsa, test_vsa. Con questa partizione posso attuare il validation approach e modellare e diagnosticare si training, selezionare su validation e testare su test.


```{r partizione training validation e test}
set.seed(456)
training_set_vsa <- bank0 %>%
        add_rownames() %>%
        sample_frac(0.6, replace = FALSE)
nrow(training_set_vsa)

test_and_val_set1 <- bank0 %>%
        add_rownames() %>%
        sample_frac(1, replace = FALSE) %>%
        anti_join(training_set_vsa, by = "rowname")
nrow(test_and_val_set1)
#check ok, sono diversi

test_set_vsa <- test_and_val_set1 %>%
        sample_frac(0.5, replace = FALSE)
nrow(test_set_vsa)

validation_set_vsa <- test_and_val_set1 %>%
        sample_frac(1, replace = FALSE) %>%
        anti_join(test_set_vsa, by = "rowname")
nrow(validation_set_vsa)

validation_set_vsa[validation_set_vsa$rowname == test_set_vsa$rowname,] #check ok, tutte righe diverse
```


Abbiamo quindi training_set_vsa, validation_set_vsa, test_set_vsa.

Da ora userò l'approccio vsa, perché mi permette di modellare molto meglio il modello testando la significatività, escludendo variabili per p.value, diagnosticando multicollinearità e bontà di adattamento.

I paragoni andranno fatti tra i modelli con questo approccio.

Il modello poco propenso all'overfitting e la quantità di osservazioni che non dovrebbe generare bias mi fanno preferire vsa.

#Modello

Selezione solo le variabili con un IV superiore a 0.02, salvo interazioni incluse (http://support.sas.com/resources/papers/proceedings13/095-2013.pdf). Ho comunque sperimentato che escludendo un predittore debole (campaign) l'AUC del validation set passava da 0.746 a 0.740.


```{r formula glm1 vsa}
formula_glm1 <- formula_glm1 <- y~age + job + marital + balance + housing + loan + contact + day + month + campaign + pdays + previous + age*marital + age*job + loan*housing
```

```{r glm1 vsa building}
glm1_vsa <- glm(formula_glm1, family = "binomial", data = training_set_vsa)

summary(glm1_vsa) #AIC molto basso, è normale la sovrastima delle performance, che non vuol dire overfitting.
```

#Diagnostica

##Multicollinearità

```{r coll}
cd <- colldiag(model.matrix(glm1_vsa))
print(cd)
```

Ci sono due indici (il 48 e il 49) maggiori di 30, ma nessuna vdp maggiore di 0.5 (anche se un paio ci vanno vicino, e qualche problema di multicollinearità non mi stupisce).

##Bontà adattamento modello

```{r HL glm1}
hl_glm1 <- hoslem.test(training_set_vsa$y =="yes", fitted(glm1_vsa), g=10)
hl_glm1
```

Il test, se rigettato, rigetta l'ipotesi di buon adattamento. Qui non si può rigettare. è vero che c'è il problema che il numero di gruppi non dovrebbe essere inferiore a p+1 (http://thestatsgeek.com/2014/02/16/the-hosmer-lemeshow-goodness-of-fit-test-for-logistic-regression/), e io con le variabili dummy ho molte p. Ma anche se i gruppi sono 100, il p.value è significativo, quindi il buon adattamento va rigettato.

#Stima performance predittive

```{r glm1 AUC on validation}
glm1_vsa_predictions  <- predict(glm1_vsa, validation_set_vsa, type="response")

AUC_glm1_vsa <- roc(validation_set_vsa$y, glm1_vsa_predictions, levels=c("no", "yes"))
AUC_glm1_vsa$auc
```

AUC del modello sul validation set è 0.746. Con quella competerà con gli altri modelli, se la diagnostica non me lo fa cambiare.

Voglio sperimentare anche la AUCPR, che forse è miglior indicatore per classi molto sbilanciate (http://stats.stackexchange.com/questions/7207/roc-vs-precision-and-recall-curves)


```{r glm1 AUCPR on validation}
AUCPR_glm1_vsa <- pr.curve(glm1_vsa_predictions, weights.class0 = validation_set_vsa$y == "yes", curve=T)
AUCPR_glm1_vsa
plot(AUCPR_glm1_vsa)
```



Prima stepwise selection su tutto il training (la commento per ora)

```{r backward e forward}
#glm2_beforebackstep_training <- glm(y~age + job + marital + education + default + balance + housing + loan + contact + pdays + day + month + campaign + previous, family = "binomial", data = training_set_vsa)

#glm2_backstep_selection <- stepAIC(object = glm2_beforebackstep_training, direction = "backward", scope = c(upper = ~age + job + marital + education + default + balance + housing + loan + contact + day + month + campaign + pdays + previous, lower = ~1))

#glm2_backstep_selection$anova

#glm2_beforeforwardstep_training <- glm(y~1, family = "binomial", data = training_set_vsa)

#glm2_forwardstep_selection <- stepAIC(object = glm2_beforeforwardstep_training, direction = "forward", scope = c(upper = ~age + job + marital + education + default + balance + housing + loan + contact + day + month + campaign + pdays + previous, lower = ~1))

#glm2_forwardstep_selection$anova
```

Allora, la backward come final model presenta y ~ age + job + marital + education + balance + housing + loan + 
    contact + pdays + month + campaign + previous e un AIC di 17048.57.
    
La forward  y ~ month + contact + housing + campaign + loan + job + previous + 
    education + marital + pdays + balance + age con AIC di 17048.57. Identico!


#Diagnostica

```{r glm2 formula }
step_formula <- y ~ age + job + marital + education + balance + housing + loan + contact + pdays + month + campaign + previous

glm2_vsa <- glm(step_formula, family ="binomial", data = training_set_vsa)

```

##Multicollinearità

```{r coll glm2 }
cd <- colldiag(model.matrix(glm2_vsa))
print(cd)
```

Nessun indice, eccetto intercetta, supera 30. Non ci sono problemi di multicollinearità.

##Bontà adattamento modello

```{r HL glm2}
hl_glm2 <- hoslem.test(training_set_vsa$y =="yes", fitted(glm2_vsa), g=100)
hl_glm2
```

Anche qua test rigettato, l'ipotesi nulla di buon adattamento va rigettata. Anche con 100 gruppi il p.value è bassissimo.

#Stima performance predittive

Bene, ora vediamo l'AUC sul validation set

```{r glm2 AUC on validation }
glm2_vsa_predictions  <- predict(glm2_vsa, validation_set_vsa, type="response")

AUC_glm2_vsa <- roc(validation_set_vsa$y, glm2_vsa_predictions, levels=c("no", "yes"))
AUC_glm2_vsa$auc
```

Però. glm2 ha AUC di 0.7463 contro 0.746 di glm1. Per ora vince la step contro di me.

Vediamo la AUCPR

```{r glm2 AUCPR on validation}
AUCPR_glm2_vsa <- pr.curve(glm2_vsa_predictions, weights.class0 = validation_set_vsa$y == "yes", curve=T)
AUCPR_glm2_vsa
plot(AUCPR_glm2_vsa)
```


Modello simile a glm1, ma usando i fattori invece delle variabili quantitative quando possibile

```{r formula glm3 vsa}
formula_glm3 <- y ~ age_class + job + marital + balance_class + housing + loan + contact + day + month + campaign_class + pdays_class + age_class*marital + age_class*job + loan*housing
```

```{r glm3 vsa building}
glm3_vsa <- glm(formula_glm3, family = "binomial", data = training_set_vsa)
summary(glm3_vsa) #AIC molto basso, è normale la sovrastima delle performance, che non vuol dire overfitting.
```

AIC più bassa sinora.

#Diagnostica

##Multicollinearità

```{r glm 3 coll}
matrix_glm3 <- model.matrix(glm3_vsa)
matrix_glm3 <- matrix_glm3[,colSums(matrix_glm3 != 0) != 0]
cd_glm3 <- colldiag(matrix_glm3)
print(cd_glm3)
str(cd_glm3)
cd_glm3$condindx
#cd_glm3$pi[84,]
```

Pdays  e previous_class danno un problema di multicollinearità. Tolgo previous class  eil problema non c'è più.

##Bontà adattamento modello

```{r HL glm3}
hl_glm3 <- hoslem.test(training_set_vsa$y =="yes", fitted(glm3_vsa), g=10)
hl_glm3
```

Il test, se rigettato, rigetta l'ipotesi di buon adattamento. Qui non si può rigettare. è vero che c'è il problema che il numero di gruppi non dovrebbe essere inferiore a p+1 (http://thestatsgeek.com/2014/02/16/the-hosmer-lemeshow-goodness-of-fit-test-for-logistic-regression/), e io con le variabili dummy ho molte p. Ma anche se i gruppi sono 100, il p.value è significativo, quindi il buon adattamento va rigettato.

#Stima performance predittive

```{r glm3 AUC on validation}
glm3_vsa_predictions  <- predict(glm3_vsa, validation_set_vsa, type="response")

AUC_glm3_vsa <- roc(validation_set_vsa$y, glm3_vsa_predictions, levels=c("no", "yes"))
AUC_glm3_vsa$auc
```

AUC del modello sul validation set è 0.755 (stabile anche dopo aver tolo previous per multicollinearità). Con quella competerà con gli altri modelli, se la diagnostica non me lo fa cambiare.


Vediamo la AUCPR

```{r glm3 AUCPR on validation 1}
AUCPR_glm3_vsa <- pr.curve(glm3_vsa_predictions, weights.class0 = validation_set_vsa$y == "yes", curve=T)
AUCPR_glm3_vsa
plot(AUCPR_glm3_vsa)
```


Modello simile a glm3, ma uso i p.value per escludere variabili se possibile

```{r formula glm4 vsa}
formula_glm4_1 <- y ~ age_class + job + marital + balance_class + housing + loan + contact + day + month + campaign_class + pdays_class + age_class*marital + age_class*job + loan*housing
```

```{r glm4 vsa building}
glm4_1_vsa <- glm(formula_glm4_1, family = "binomial", data = training_set_vsa)

summary(glm4_1_vsa) #AIC molto basso, è normale la sovrastima delle performance, che non vuol dire overfitting.
```

Tolgo interazion age*marital age*job e job: Raiggiungo previous_class, magari ora non ci sarà collinearità.

```{r formula glm4 2 vsa}
formula_glm4_2 <- y ~ age_class + marital + balance_class + housing + loan + contact + day + month + campaign_class + pdays_class + loan*housing
```

```{r glm4 second building}
glm4_2_vsa <- glm(formula_glm4_2, family = "binomial", data = training_set_vsa)
summary(glm4_2_vsa)
anova(glm4_1_vsa, glm4_2_vsa)
```


#Multicollinearità

```{r glm 4 coll}
matrix_glm4_2 <- model.matrix(glm4_2_vsa)
matrix_glm4_2 <- matrix_glm4_2[,colSums(matrix_glm4_2 != 0) != 0]

cd_glm4_2 <- colldiag(matrix_glm4_2)
print(cd_glm4_2)
str(cd_glm4_2)
cd_glm4_2$condindx
cd_glm4_2$pi[48,]
```

Previous continua a dare problemi di multicollinearità. Lo ritolgo all'origine.


##Bontà adattamento modello

```{r HL glm4_2}
hl_glm4_2 <- hoslem.test(training_set_vsa$y =="yes", fitted(glm4_2_vsa), g=10)
hl_glm4_2
```

Nada.

##Stima delle performance predittive

```{r glm4 AUC on validation}
glm4_2_vsa_predictions  <- predict(glm4_2_vsa, validation_set_vsa, type="response")

AUC_glm4_2_vsa <- roc(validation_set_vsa$y, glm4_2_vsa_predictions, levels=c("no", "yes"))
AUC_glm4_2_vsa$auc
plot(AUC_glm4_2_vsa, legacy.axes=TRUE)
```

AUC di 0.7556. Senza togliere le variabili con basso p.value eravamo a 0.755, praticamente performance identiche con stessi problemi di multicollinearità Giusto per scrupolo voglio vedere se gli errori standard sono inferiori nel secondo caso (anche se solo il principio della parsimonia basta a giustificare il secondo modello).

```{r}
a <- tidy(glm3_vsa)
b <- tidy(glm4_2_vsa)
glm_comp_3_and_4_2 <- a %>%
        inner_join(b, by = "term") %>%
        select(term, SE_glm3 = std.error.x, SE_glm4_2 =  std.error.y) %>%
        mutate(comp_SE = SE_glm4_2 - SE_glm3) %>%
        arrange(comp_SE)
```

Quasi tutti inferiori, anche se di poco. Mi domando se un tale misero vantaggio di SE e di AUC mi debba indurre a escludere delle variabili. Preferire glm3 o glm4? Mah. Considera però che glm3 ha il problema del rank e che in glm4 ho valutato i p-value senza la correzione di bonferroni.


```{r glm3 AUCPR on validation}
AUCPR_glm4_2_vsa <- pr.curve(glm4_2_vsa_predictions, weights.class0 = validation_set_vsa$y == "yes", curve=T)
AUCPR_glm4_2_vsa
plot(AUCPR_glm4_2_vsa)
```

```{r glm5 poutcome}
formula_glm5_1 <- y ~ poutcome
glm5_1_vsa <- glm(formula_glm5_1, family = "binomial", data = training_set_vsa)
summary(glm5_1_vsa)
```

Alpha = 0.05 / ? Non si sa. Non ha senso fare la forward. Dovresti assumere un numero di variabili che incliderai, ma magari escludi qualcosa che andrebbe messo.


```{r glm5 poutcome month}
formula_glm5_2 <- y~age + job + marital + education + default + balance + housing + loan + contact + pdays + day + month + campaign + previous
glm5_2_vsa <- glm(formula_glm5_2, family = "binomial", data = training_set_vsa)
summary(glm5_2_vsa)
glm5_2_vsa_table <- tidy(glm5_2_vsa)
da_escludere <- glm5_2_vsa_table %>%
        filter(p.value > 0.05/nrow(a))
```

Praticamente tutto. è evidente che il test perde di potenza, oppure che i test statistici per questa analisi tendono a considerare il modello non corretto (vedi anche HL). Bisogna rifarsi perciò alla AUC. La step tramite p.value è abortita.




```{r}
# The train and test set are loaded into your workspace.

# Set random seed. Don't remove this line
set.seed(1)

# Load the rpart, rattle, rpart.plot and RColorBrewer package
library("rpart")
library("rpart.plot")
library("RColorBrewer")
library("rattle")

# Build a tree model: tree
tree <- rpart(y ~ age + job + marital + balance + housing + loan + contact + day + month + campaign + pdays + previous, data = training_set_vsa, method = "class", control=rpart.control(minsplit=5, cp=0.001))

# Draw the decision tree
pred <- predict(tree, validation_set_vsa, type = "class")
conf <- table(validation_set_vsa$y, pred)
conf
```


#Auroc test

```{r AUC test glm3}
test_set_vsa$glm3_vsa_predictions_test  <- predict(glm3_vsa, test_set_vsa, type="response")
AUC_glm3_vsa_test <- roc(test_set_vsa$y, test_set_vsa$glm3_vsa_predictions_test, levels=c("no", "yes"))
AUC_glm3_vsa_test$auc
```

#Aucpr test

```{r AUCPR glm3}
AUCPR_glm3_vsa <- pr.curve(test_set_vsa$glm3_vsa_predictions_test, weights.class0 = test_set_vsa$y == "yes", curve=T)
AUCPR_glm3_vsa
```

#Grafici

```{r plot of ROC AUCPR and prob-cutoff and prob_class }
plot(AUC_glm3_vsa_test, legacy.axes = TRUE)

plot(AUCPR_glm3_vsa)

g_estim_prob_class <- ggplot(data = test_set_vsa, aes(x = glm3_vsa_predictions_test, col = y)) +
        geom_density()
g_estim_prob_class

#construisco un dataframe per il plot sensitivuty probability vs cutoff. vedi https://cran.r-project.org/web/packages/ROCR/ROCR.pdf

prediction_test_obj <- prediction(predictions = test_set_vsa$glm3_vsa_predictions_test, labels = test_set_vsa$y)
tpr_obj <-  performance(prediction_test_obj, measure = "tpr")
fpr_obj <-  performance(prediction_test_obj, measure = "spec")
ppv_obj <-  performance(prediction_test_obj, measure = "prec") 

sens_spec_cutoff_df_wide <- data.frame (cutoff = as.numeric( unlist ( tpr_obj@x.values) ), sensitivity = as.numeric( unlist ( tpr_obj@y.values) ), specificity = as.numeric( unlist ( fpr_obj@y.values) ), ppv = as.numeric( unlist (ppv_obj@y.values) ))

sens_spec_cutoff_df_tidy <- sens_spec_cutoff_df_wide %>%
        gather(key = type_indicator, value_indicator, sensitivity:ppv)

g_sens_spec_cutoff <- ggplot(sens_spec_cutoff_df_tidy, aes(x = cutoff, y = value_indicator, col = type_indicator)) +
        geom_line() + 
        scale_x_continuous(breaks = seq(0.01, 1, 0.02)) +
        scale_y_continuous(breaks = seq(0, 1, 0.05)) +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_sens_spec_cutoff#eccellente!
```

Con questo grafico, `g_sens_spec_cutoff``, posso scegliere la soglia di cutoff che desidero e sapere tpr, fpr, ppv all'istante.

#Decisione sulla soglia

```{r cutoff decision}
sens_spec_cutoff_df_wide %>%
        filter(sensitivity > 0.47, sensitivity < 0.53)

#Quando cutoff = 0.1758297 allora:

sens_spec_cutoff_df_wide %>%
        filter(cutoff > 0.1758, cutoff < 0.1759)
#ho un tpr del 50%, un tnr del 88% e un ppv del 36%
```

La mia soglia è 0.1758

#Confusion matrix
```{r confusion matrix glm3}
#usa prediction_test_obj di rocr, vedi sopra e https://cran.r-project.org/web/packages/ROCR/ROCR.pdf
test_set_vsa$yhat <- factor(as.numeric(test_set_vsa$glm3_vsa_predictions_test > 0.1758))
test_set_vsa$yact <- factor(as.numeric(test_set_vsa$y == "yes"))
conf_matrix <- confusionMatrix(test_set_vsa$yhat, test_set_vsa$yact, positive ="1")
conf_matrix
```


#Diagnostic likelihood ratio

Non so la prevalence se va calcolata su tutto il dataset o solo sul training. Io direi solo sul training, perché nella CV è il campione che ho a disposizione per qualunque stima. peraltro è identica a quella di tutto il dataset.

```{r DLR+ glm3}
ppv_def <-sens_spec_cutoff_df_wide$ppv[sens_spec_cutoff_df_wide$cutoff > 0.1758 & sens_spec_cutoff_df_wide$cutoff < 0.1759]
prevalence <- mean(training_set_vsa$y == "yes")
DLRp <- ( (ppv_def/(1-ppv_def)) / (prevalence/(1-prevalence)) )
DLRp  #sopra 4, buono.
```


#Lift chart cumulato

```{r AULIFT glm3}
lift_df <- data.frame(yact = test_set_vsa$yact, y_pred_prob = test_set_vsa$glm3_vsa_predictions_test)
lift_df_sum <- lift_df %>%
        arrange(y_pred_prob) %>%
        mutate(groups = ntile(y_pred_prob, 10)) %>%
        group_by(groups) %>%
        summarise(n_clienti = n(), n_y = sum(yact == "1")) %>%
        arrange(desc(groups)) %>%
        mutate(perc_clienti = n_clienti / sum(n_clienti), perc_clienti_positivi = n_y / sum(n_y), perc_cum_clienti_pos_mod               = cumsum(perc_clienti_positivi), perc_cum_clienti = cumsum(perc_clienti), perc_cum_clienti_pos_exp = perc_cum_clienti) %>%
        select(groups, perc_cum_clienti, perc_cum_clienti_pos_mod, perc_cum_clienti_pos_exp) %>%
        gather(key = type_indicator, value_indicator, perc_cum_clienti_pos_mod:perc_cum_clienti_pos_exp) %>%
        ggplot(aes(x = perc_cum_clienti, y = value_indicator, col = type_indicator)) + 
        geom_point (size = 3) + 
        geom_line() +
        scale_x_continuous(breaks = seq(0, 1, 0.1)) +
        scale_y_continuous(breaks = seq(0, 1, 0.1)) +
        geom_vline(xintercept = 0.17)
lift_df_sum
```

#Conversion per decili

```{r conversion per decili glm3}
g_conversion_decili <- lift_df %>%
        arrange(y_pred_prob) %>%
        mutate(groups = ntile(y_pred_prob, 10)) %>%
        group_by(groups) %>%
        summarise(n_clienti = n(), n_y = sum(yact == "1")) %>%
        arrange(desc(groups)) %>%
        mutate(perc_clienti = n_clienti / sum(n_clienti), perc_cum_clienti = cumsum(perc_clienti), conversion = n_y / n_clienti) %>%
        ggplot(aes(x = groups, y = conversion)) + 
        geom_bar(stat = "identity", col = "blue", fill = "pink") +
        scale_x_continuous(breaks = seq(1, 10, 1)) +
        scale_y_continuous(breaks = seq(0, 1, 0.05)) +
        geom_hline(yintercept = mean(bank0$y == "yes"), col = "blue", linetype = 2)
g_conversion_decili
```
