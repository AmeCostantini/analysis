---
title: "Untitled"
author: "Americo"
date: "29 aprile 2016"
output: html_document
---

#Introduzione

Questo capitolo tratta lo svolgimento di una analisi dati relativa al **direct marketing** bancario, utilizzando un dataset disponibile sul web a questo indirizzo: http://archive.ics.uci.edu/ml/datasets/Bank+Marketing. Questo dataset contiene le informazioni raccolte da una banca portoghese che dal 2008 al 2013 ha effettuato chiamate in outbound a un campione del suo portafoglio per proporre la sottoscrizione di un ulteriore prodotto, un deposito a termine. Avendo a disposizione alcune informazioni sui clienti e sapendo quali hanno sottoscritto e quali no, l'obiettivo dell'analisi sarà quello di costruire un modello di regressione logistica che sia in grado di discriminare i clienti, tra quelli mai chiamati, che sottoscriveranno il prodotto se contattati da quelli che non lo soottoscriveranno. Una tale analisi predittiva avrebbe enormi benefici in termini di efficacia dell'attività di vendita: senza il supporto di modelli infatti ogni n clienti contattati si avrà una penetrazione del prodotto identica, che sarà molto prossimo a quello del campione analizzato (11,7% circa); con un modello a disposizione invece si potrà individuare un segmento di clienti entro la quale la **penetrazione** sarà maggiore, e si potranno collocare più prodotti a parità di chiamate.

#Metodologia

##Strumenti

Questa analisi viene svolta utilizzando il linguaggio di analisi statistica R, tramite il modulo di literate statical programming **R markdown**, che permette il rispetto dei principi della ricerca riproducibile. Per ogni risultato dell'analisi viene riportato il codice che lo ha generato. Di seguito i package utilizzati per l'analisi:


```{r packages, message=FALSE, warning=FALSE}
require(gains)
require(PRROC)
require(broom)
require(ResourceSelection)
require(MKmisc)
require(perturb)
require(caret)
require(DAAG)
library(pROC)
library(ROCR)
require(MASS)
library(devtools)
require(GGally)
library(woe)
require(ggplot2)
require(dplyr)
require(tidyr)
require(knitr)
require(e1071)
select <- dplyr::select
```

##Approccio statistico

I modelli che verranno testati rientrano tutti nella famiglia della regressione logistica, di cui si è trattato nel capitolo primo. L'approccio si concretizzerà in una prima fase di **exploratory data analysis**, soprattutto in formato grafico, seguita da un confronto tra diverse ipotesi di modello guidate dalla prima fase. Per ogni variabile verrà eseguita una analisi univariata e una della sua relazione con la variabile target `y`, inoltre in alcuni casi verrà approfondita la relazione trivariata tra `y`e due variabili indipendenti.

#Analisi esplorativa

##Caricamento del dataset

```{r directory e dataset, results='hide'}
getwd()
setwd("/Users/Americo/Documents/Education/Unitelma/tesi/data_analysis/dataset")
bank0_df <- read.csv(file = "bank_full.csv", sep = ";")
bank0 <- tbl_df(read.csv(file = "bank_full.csv", sep = ";"))
bank0_sm <- read.csv(file = "bank.csv", sep = ";")
```

`bank0` è il nome dato al dataset che utilizzeremo.

##Informazioni sul dataset

```{r dim dataset}
dim(bank0)
```

Il dataset è composto da circa 45000 osservazioni e da 17 variabili. Vediamo meglio quali sono le variabili:

```{r str dataset}
str(bank0)
```

Al link sopra riportato vi è la descrizione delle 17 variabili presenti nel dataset, che noi approfondiremo singolarmente nella nostra analisi. Per ora basti la seguente sintesi:

**Variabili legate al profilo del cliente**

* age: età del cliente
* job: professione svolta dal cliente
* marital : stato coniugale del cliente
* education: titolo di studio del cliente
* default: presenza di crediti in default
* balance: saldo medio annuale del conto
* housing: presenza di mutuo per la casa
* loan: presenza di prestiti

**Variabili legate all'ultimo contatto dell'attuale campagna di marketing**

* contact: modalità di comunicazione per l'ultimo contatto avvenuto
* day: giorno del mese dell'ultimo contatto avvenuto
* month: mese dell'ultimo contatto avvenuto
* duration: durata (in secondi) dell'ultimo contatto avvenuto

**Variabili legate all'attuale o a precedente campagna di marketing**

* campaign: totale di contatti avvenuti durante l'attuale campagna di marketing per ogni cliente
* pdays: numero di giorni trascorsi prima che il cliente fosse contattato per questa campagna dopo la fine della campagna precedente
* previous: numerodi contatti avvenuti prima di questa campagna
* poutcome: esito della precedente campagna di marketing

**Variabile target: sottoscrizione o meno del deposito**

Verifichiamo che non ci siano valori mancanti

```{r missing vaue detect}
bank0[!complete.cases(bank0),]
```

Nessuna riga contiene valori mancanti.

##Esplorazione variabili univariata e in rapporto alla sottoscrizione

###age

Da indicazioni del dizionario dati, `age` è una variabile numerica che misura l'età del cliente, anche se non sappiamo in quale momento (assumiamo quello attuale di processamento del modello).

```{r age 5 quantities}
class(bank0$age)
summary(bank0$age)
```

Il range è dai 18 ai 95, vediamo in forma grafica la distribuzione delle varie età.

```{r age graph, fig.width=16, fig.height=7}
g_age <- ggplot(bank0, aes(x = factor(age))) + geom_bar(col = "white") +
        ggtitle("distribuzione per età") +
        xlab("età") +
        ylab("frequenza")    
g_age
```

Una distribuzione quasi normale, con maggioritaria presenza di clienti dai 30 ai 60 anni, pochissimi diciotenni e ultra-ottantenni.

Ora vediamo come la penetrazione del prodotto si distribuisce all'interno delle varie età (in questo e in tutti gli altri grafici la linea orizzontale trattegiata rappresenta la percentuale di sottoscrizioni complessiva del campione, `r mean(bank0$y =="yes")`.

```{r age_y table and graph, fig.width=16, fig.height=7}
g_age_y <- ggplot(bank0, aes(x = factor(age), fill = y)) + 
        geom_bar(col = "white", position = "fill") + 
        geom_hline(yintercept = mean(bank0$y!="yes"), col = "black", linetype = 2) +
        ggtitle("penetrazione per età") +
        xlab("età") +
        ylab("tasso sottoscrizioni") +
        scale_y_continuous(breaks = seq(0, 1, 0.1)) +
        scale_fill_discrete(name="Sottoscrizione", labels=c("no", "sì"))
g_age_y

t_age_y <- bank0 %>%
        group_by (age) %>%
        summarise (frequenza = n(), tasso_sottoscrizioni = mean(y == "yes")) %>%
        mutate(frequenza_relativa = frequenza / sum(frequenza)) %>%
        select(age, frequenza, frequenza_relativa, tasso_sottoscrizioni)
kable(t_age_y, digits = 4, format = "markdown")
```

Vediamo che dai 30 ai 59 anni l'incidenza di sottoscrizioni è prossima a quella complessiva, e rappresenta la parte più numerosa del campione. La penetrazione del prodotto comincia a essere superiore a quella complessiva, di portafoglio diciamo, per fasce di età molto giovani o ultra-sessantenni, dove però la numerosità (e quindi la significatività) è inferiore. 

Potrebbe essere interessante raggruppare le età per fasce dal comportamento simile: [18, 30], [31, 59], [60, 95]

```{r age_class_y table and graph}
bank0$age <- as.numeric(bank0$age)
bank0$age_class <- cut(bank0$age, breaks = c(min(bank0$age)-1, 30, 59, max(bank0$age)), labels = c("[18, 30]", "[31, 59]", "[60, 95]"))
summary(bank0$age_class)

t_age_class <- bank0 %>%
        select(age_class, y) %>%
        group_by(age_class) %>%
        summarise(frequenza = n(), tasso_sottoscrizioni = mean(y =="yes")) %>%
        mutate(frequenza_relativa = frequenza / sum(frequenza)) %>%
        select(age_class, frequenza, frequenza_relativa, tasso_sottoscrizioni)
kable(t_age_class, digits = 4, format = "markdown")

g_age_class_y <- ggplot(bank0, aes(x = age_class, fill = y)) + 
        geom_bar(col = "white", position = "fill") + 
        geom_hline(yintercept = mean(bank0$y!="yes"), col = "black", linetype = 2) +
        ggtitle("penetrazione per età") +
        xlab("fasce di età") +
        ylab("tasso sottoscrizioni") +
        scale_x_discrete(labels = c("[18, 30]", "[31, 59]", "[60, 95]")) +
        scale_y_continuous(breaks = seq(0, 1, 0.1)) +
        scale_fill_discrete(name="Sottoscrizione", labels=c("no", "sì"))
g_age_class_y
```

è evidente che giovani e anziani sottoscrivono più del campione nel complesso, che nel comportamento è guidato dalla fascia media, gli adulti. Inoltre l'alta penetrazione della fascia anziana va pesato per la scarsa rilevanza numerica nel campione, il 4% circa, ma comunque di dimensione significativa.

Ha senso questa distribuzione? Beh, ci si può aspettare che un deposito a lungo termine venga sottoscritto di più da giovani che vogliono investire i loro risparmi (magari regali dei loro cari), mentre la fascia adulta avendo già molte spese (mantenimento della famiglia, mutui, presiti - in questi ultimi due casi potremo verificare l'ipotesi di una qualche interazione) abbia meno possibilità di farlo. Quanto agli anziani, per saperlo dovremmo conoscere meglio le caratteristiche del prodotto, magari lo hanno sottoscritto ma per farne beneficiare gli eredi.

Come per ogni variabile che analizzeremo, l'analisi termina con il calcolo dell'**information value**, una misura del potere predittivo della variabile per la cui trattazione teorica rimandiamo al capitolo secondo.

```{r age class IV}
age_class_woe <- bank0 %>%
        select(age_class, y) %>%
        group_by(age_class) %>%
        summarise(n_no = sum(y == "no"), n_y = sum(y == "yes")) %>%
        mutate (perc_no = n_no / sum(n_no), perc_y = n_y / sum(n_y)) %>%
        select (starts_with("perc"))
age_class_woe$woe <- log(age_class_woe$perc_no / age_class_woe$perc_y)
age_class_IV <- sum((age_class_woe$perc_no - age_class_woe$perc_y) * age_class_woe$woe)
age_class_IV
```

`r age_class_IV` , confrontato con la griglia del capitolo secondo, ci fa dire che l'età, raggruppata in tre classi, è una variabile mediamente predittiva della sottoscrizione. 

###Job

La professione svolta dal cliente. Iniziamo con tabella e grafico della distribuzione:

```{r job table and graph }
t_job <- bank0 %>%
        group_by (job) %>%
        summarise (frequenza = n()) %>%
        mutate (frequenza_relativa = frequenza / sum(frequenza)) %>%
        arrange(desc(frequenza_relativa))
kable(t_job, digits = 4, format = "markdown")

g_job  <- ggplot(bank0, aes(x = job)) +
        geom_bar() +
        ggtitle("distribuzione per job") +
        ylab("frequenza") +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_job
```

Vediamo adesso come, all'interno dei vari livelli della professione, si distribuiscono i sottoscrittori:

```{r job_y table and graph}
t_job_y <- bank0 %>%
        group_by (job) %>%
        summarise (frequenza = n(), tasso_sottoscrizioni = mean(y=="yes")) %>%
        mutate(frequenza_relativa = frequenza / sum(frequenza)) %>%
        select(job, frequenza, frequenza_relativa, tasso_sottoscrizioni) %>%
        arrange(desc(tasso_sottoscrizioni))
kable(t_job_y, digits = 4, format = "markdown")

g_job_y  <- ggplot(bank0, aes(x = job, fill = y)) +
        geom_bar(position = "fill") +
        geom_hline(yintercept = mean(bank0$y!="yes"), width = 2, col = "black", linetype = 2) +
        ggtitle("penetrazione per job") +
        ylab("tasso sottoscrizioni") +
        scale_y_continuous(breaks = seq(0, 1, 0.1)) +
        scale_fill_discrete(name="Sottoscrizione", labels=c("no", "sì")) +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_job_y
```

Le professioni con il maggior tasso di sottoscrittori sono le meno frequenti, studenti e pensionati. Sarà interessante vedere - e lo faremo nella sezione delle analisi trivariate - se c'è un legame da età e professione tale per cui una delle due variabili può spiegare parzialmente la relazione con la sottoscrizione. 

Non facile da interpretare invece il dato sui disoccupati: perché mai chi non ha reddito dovrebbe tendere più della media a sottoscrivere depositi a lungo termine? Forse vi rientrano giovani non categorizzati come studenti il cui deposito viene finanziato dai genitori. Anche qui l'analisi trivariata ci potrà svelare se c'è un legame.

Da Ultimo calcoliamo l'information value della variabile `job`:

```{r job IV}
job_woe <- bank0 %>%
        select(job, y) %>%
        group_by(job) %>%
        summarise(n_no = sum(y == "no"), n_y = sum(y == "yes")) %>%
        mutate (perc_no = n_no / sum(n_no), perc_y = n_y / sum(n_y)) %>%
        select (starts_with("perc"))
job_woe$woe <- log(job_woe$perc_no / job_woe$perc_y)
job_IV <- sum((job_woe$perc_no - job_woe$perc_y) * job_woe$woe)
job_IV
```

Anche `job` ha un potere predittivo di media entità.

###Marital

La variabile descrive lo stato coniugale. Dal dizionario dati sappiamo che il valore "divorced" include anche i vedovi.

```{r marital table and graph}
t_marital <- bank0 %>%
        group_by(marital) %>%
        summarise(frequenza = n()) %>%
        mutate(frequenza_relativa = frequenza / sum(frequenza)) %>%
        arrange(desc(frequenza))
kable(t_marital, digits = 4, format = "markdown")

g_marital  <- ggplot(bank0, aes(x = marital)) +
        geom_bar() +
        ggtitle("distribuzione per marital") +
        ylab("frequenza") +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_marital
```


```{r marital_y table and graph}
t_marital_y <- bank0 %>%
        group_by (marital) %>%
        summarise (frequenza = n(), tasso_sottoscrizioni = mean(y=="yes")) %>%
        mutate(frequenza_relativa = frequenza / sum(frequenza)) %>%
        select(marital, frequenza, frequenza_relativa, tasso_sottoscrizioni) %>%
        arrange(desc(tasso_sottoscrizioni))
kable(t_marital_y, digits = 4, format = "markdown")

g_marital_y  <- ggplot(bank0, aes(x = marital, fill = y)) +
        geom_bar(position = "fill") +
        geom_hline(yintercept = mean(bank0$y!="yes"), width = 2, col = "black", linetype = 2) +
        ggtitle("penetrazione per marital") +
        ylab("tasso sottoscrizioni") +
        scale_y_continuous(breaks = seq(0, 1, 0.1)) +
        scale_fill_discrete(name="Sottoscrizione", labels=c("no", "sì")) +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_marital_y
```

I single tendono a sottoscrivere un po' di più. Anche qui andrà indagata la relazione con l'età (la maggior parte dei single sono giovani e quindi per questo i single sottoscrivono di più?) e la professione (specialmente studentesca).

L'information value di `marital`:

```{r marital IV}
marital_woe <- bank0 %>%
        select(marital, y) %>%
        group_by(marital) %>%
        summarise(n_no = sum(y == "no"), n_y = sum(y == "yes")) %>%
        mutate (perc_no = n_no / sum(n_no), perc_y = n_y / sum(n_y)) %>%
        select (starts_with("perc"))
marital_woe$woe <- log(marital_woe$perc_no / marital_woe$perc_y)
marital_IV <- sum((marital_woe$perc_no - marital_woe$perc_y) * marital_woe$woe)
marital_IV
```

Ha una predittività molto debole.

###Education

```{r education graph and table}
t_education  <- bank0 %>%
        group_by(education) %>%
        summarise(frequenza = n()) %>%
        mutate(frequenza_relativa = frequenza / sum(frequenza)) %>%
        arrange(desc(frequenza))
kable(t_education, digits = 4, format = "markdown")

g_education  <- ggplot(bank0, aes(x = education)) +
        geom_bar() +
        ggtitle("distribuzione per education") +
        ylab("frequenza") +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_education
```

Analizziamo come la penetrazione si distribuisce tra i titoli di studio:

```{r education_y graph and table}
t_education_y <- bank0 %>%
        group_by (education) %>%
        summarise (frequenza = n(), tasso_sottoscrizioni = mean(y=="yes")) %>%
        mutate(frequenza_relativa = frequenza / sum(frequenza)) %>%
        select(education, frequenza, frequenza_relativa, tasso_sottoscrizioni) %>%
        arrange(desc(tasso_sottoscrizioni))
kable(t_education_y, digits = 4, format = "markdown")

g_education_y  <- ggplot(bank0, aes(x = education, fill = y)) +
        geom_bar(position = "fill") +
        geom_hline(yintercept = mean(bank0$y!="yes"), width = 2, col = "black", linetype = 2) +
        ggtitle("penetrazione per education") +
        ylab("tasso sottoscrizioni") +
        scale_y_continuous(breaks = seq(0, 1, 0.1)) +
        scale_fill_discrete(name="Sottoscrizione", labels=c("no", "sì")) +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_education_y
```

Sembra che (ignorando il livello "unknown") a maggior livello culturale segua maggiore propensione a sottoscrivere depositi, e questa appare come una informazione aggiuntiva rispetto a quanto abbiamo scoperto sinora. Anche qui dovremo capire se l'educazione terziaria è maggiormente presente negli under 30, che per condizioni socio-economiche mutevoli hanno studiato in proporzione di più degli adulti.

L'information value di `èducation`:

```{r education IV}
education_woe <- bank0 %>%
        select(education, y) %>%
        group_by(education) %>%
        summarise(n_no = sum(y == "no"), n_y = sum(y == "yes")) %>%
        mutate (perc_no = n_no / sum(n_no), perc_y = n_y / sum(n_y)) %>%
        select (starts_with("perc"))
education_woe$woe <- log(education_woe$perc_no / education_woe$perc_y)
education_IV <- sum((education_woe$perc_no - education_woe$perc_y) * education_woe$woe)
education_IV
```

Predittività debole ma non assente.

##Default

Variabile dicotomica che quando assume valore `r 1` indica la presenza di crediti in defualt.

```{r default table and graph}
t_default  <- bank0 %>%
        group_by(default) %>%
        summarise(frequenza = n()) %>%
        mutate(frequenza_relativa = frequenza / sum(frequenza)) %>%
        arrange(desc(frequenza))
kable(t_default, digits = 4, format = "markdown")

g_default  <- ggplot(bank0, aes(x = default)) +
        geom_bar() +
        ggtitle("distribuzione per default") +
        ylab("frequenza") +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_default
```

Pochissimi in default, forse troppo pochi per trovare significatività in questa variabile.

```{r default_y graph and  table}
t_default_y <- bank0 %>%
        group_by (default) %>%
        summarise (frequenza = n(), tasso_sottoscrizioni = mean(y=="yes")) %>%
        mutate(frequenza_relativa = frequenza / sum(frequenza)) %>%
        select(default, frequenza, frequenza_relativa, tasso_sottoscrizioni) %>%
        arrange(desc(tasso_sottoscrizioni))
kable(t_default_y, digits = 4, format = "markdown")

g_default_y  <- ggplot(bank0, aes(x = default, fill = y)) +
        geom_bar(position = "fill") +
        geom_hline(yintercept = mean(bank0$y!="yes"), width = 2, col = "black", linetype = 2) +
        ggtitle("penetrazione per default") +
        ylab("tasso sottoscrizioni") +
        scale_y_continuous(breaks = seq(0, 1, 0.1)) +
        scale_fill_discrete(name="Sottoscrizione", labels=c("no", "sì")) +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_default_y
```

I clienti non in default si comportano, in termini di sottoscrizioni, assolutamente nella media, ma d'altronde rappresentano pressoché tutto il campione. Il `r t_default[2,3]` che è in default sottoscrive (prevedibilmente) molto meno.

Passiamo all'information value

```{r default IV}
default_woe <- bank0 %>%
        select(default, y) %>%
        group_by(default) %>%
        summarise(n_no = sum(y == "no"), n_y = sum(y == "yes")) %>%
        mutate (perc_no = n_no / sum(n_no), perc_y = n_y / sum(n_y)) %>%
        select (starts_with("perc"))
default_woe$woe <- log(default_woe$perc_no / default_woe$perc_y)
default_IV <- sum((default_woe$perc_no - default_woe$perc_y) * default_woe$woe)
default_IV
```

Predittività assente.

###Balance

Il saldo medio sul conto corrente del cliente; in questo caso adottiamo un istogramma, data la natura quantitativa della variabile: 

```{r balance quant graph and table}
balance_quantile <- quantile(bank0$balance, c(seq(0.1, 1, 0.05)))
balance_quantile

g_balance <- ggplot(bank0, aes(x = balance)) + 
        geom_histogram(binwidth = 500) +
        ggtitle("distribuzione di balance") +
        ylab("frequenza")
g_balance
```

Come sia il grafico che la distribuzione dei percentili ci mostrano, `balance` presenta dei valori anomali che rendono l'intervallo dei valori incredibilmente ampio; per così dire, i pochi ricchi clienti della banca, mentre il 79% è tra 0 e 1000.

Vediamo che tipo di distribuzione prende forma se escludiamo il 2% dei valori più alti.

```{r balance quant graph p98}
balance_p_98 <- quantile(bank0$balance, 0.98)
bank0_p98 <- bank0 %>%
        filter(balance <= balance_p_98)
g_balance_p98 <- ggplot(bank0_p98, aes(x = 1, y = balance)) + 
        geom_boxplot() +
        ggtitle("distribuzione di balance - 98-esimo percentile") +
        xlab("") +
        scale_x_continuous(labels = c("", "", "", "", "")) +
        scale_y_continuous(breaks = seq(min(bank0$balance), balance_p_98, 1000))
g_balance_p98
```

Il 50% dei valori è tra 0 e 1000 euro, ora la distribuzione di `balance` è più chiara. Vediamo cosa succede condizionando la distribuzione alla sottoscrizione o meno

```{r balance_y quant graph}
g_balance_y_p98 <- ggplot(bank0_p98, aes(x = y, y = balance)) + 
        geom_boxplot(aes(col = y)) +
        ggtitle("distribuzione di balance - 98-esimo percentile secondo la sottoscrizione") +
        xlab("sottoscrizione") + 
        scale_x_discrete(labels = c("no", "sì")) +
        scale_color_discrete(name="Sottoscrizione", labels=c("no", "sì")) +
        scale_y_continuous(breaks = seq(min(bank0$balance), balance_p_98, 1000))
g_balance_y_p98
```

Ora comincia a essere evidente che chi sottoscrive depositi tende a avere un saldo medio del conto più alto; vale per la mediana del gruppo dei sottoscrittori, ma anche per il terzo quartile. Quindi per saldi che crescono si tende a sottoscrivere più depositi, il che ha senso. Più soldi hai, più ne puoi depositare.

Ora, anche ai fini del calcolo dell'information value, raggruppiamo `balance` in classi e analizziamo la distribuzione dei sottoscrittori all'interno dei vari livelli.

```{r balance_class_y table and graph}
bank0$balance <- as.numeric(bank0$balance)
balance_decile <- quantile(bank0$balance, probs = seq(0.1,1,0.1))
bank0$balance_class <- cut(bank0$balance, breaks = c(min(bank0$balance)-1, -1, balance_decile), right = TRUE, labels = c("negative", "0", "(0, 22]", "(22,131]", "(131,272]", "(272,448]", "(448,701]", "(701,1126]", "(1126,1859]", "(1859,3574]", "(3574,102127]"))
summary(bank0$balance_class)

t_balance_class_y <- bank0 %>%
        group_by (balance_class) %>%
        summarise (frequenza = n(), tasso_sottoscrizioni = mean(y=="yes")) %>%
        mutate(frequenza_relativa = frequenza / sum(frequenza)) %>%
        select(balance_class, frequenza, frequenza_relativa, tasso_sottoscrizioni)
kable(t_balance_class_y, digits = 4, format = "markdown")

g_balance_class_y  <- ggplot(bank0, aes(x = balance_class, fill = y)) +
        geom_bar(position = "fill") +
        geom_hline(yintercept = mean(bank0$y!="yes"), width = 2, col = "black", linetype = 2) +
        ggtitle("penetrazione per balance_class") +
        ylab("tasso sottoscrizioni") +
        scale_y_continuous(breaks = seq(0, 1, 0.1)) +
        scale_fill_discrete(name="Sottoscrizione", labels=c("no", "sì")) +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_balance_class_y
```

Evidente come spostandosi verso gruppi di saldo maggiore (gruppi di numerosità simile, ricordiamolo) cresce la probabilità di sottoscrivere un deposito a medio termine. E l'information value?

```{r balance IV}
balance_class_woe <- bank0 %>%
        select(balance_class, y) %>%
        group_by(balance_class) %>%
        summarise(n_no = sum(y == "no"), n_y = sum(y == "yes")) %>%
        mutate (perc_no = n_no / sum(n_no), perc_y = n_y / sum(n_y)) %>%
        select (starts_with("perc"))
balance_class_woe$woe <- log(balance_class_woe$perc_no / balance_class_woe$perc_y)
balance_class_IV <- sum((balance_class_woe$perc_no - balance_class_woe$perc_y) * balance_class_woe$woe)
balance_class_IV
```

Il valore di `r balance_class_IV` rientra tra i predittori di media rilevanza. 

###Housing

La variabile di dice se il cliente ha o meno sottoscritto un mutuo ipotecario per l'acquisto di un immobile

```{r housing graph and table}
t_housing  <- bank0 %>%
        group_by(housing) %>%
        summarise(frequenza = n()) %>%
        mutate(frequenza_relativa = frequenza / sum(frequenza)) %>%
        arrange(desc(frequenza))
kable(t_housing, digits = 4, format = "markdown")

g_housing  <- ggplot(bank0, aes(x = housing)) +
        geom_bar() +
        ggtitle("distribuzione per housing") +
        ylab("frequenza") +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_housing
```

Vediamo ora il comportamento dei sottoscrittori.

Poco più della metà dei clienti ha il mutuo, l'altra no. Entrambe le classi sono estremanente significative, quindi.

```{r housing_y table and graph}
t_housing_y <- bank0 %>%
        group_by (housing) %>%
        summarise (frequenza = n(), tasso_sottoscrizioni = mean(y=="yes")) %>%
        mutate(frequenza_relativa = frequenza / sum(frequenza)) %>%
        select(housing, frequenza, frequenza_relativa, tasso_sottoscrizioni) %>%
        arrange(desc(tasso_sottoscrizioni))
kable(t_housing_y, digits = 4, format = "markdown")

g_housing_y  <- ggplot(bank0, aes(x = housing, fill = y)) +
        geom_bar(position = "fill") +
        geom_hline(yintercept = mean(bank0$y!="yes"), width = 2, col = "black", linetype = 2) +
        ggtitle("penetrazione per housing") +
        ylab("tasso sottoscrizioni") +
        scale_y_continuous(breaks = seq(0, 1, 0.1)) +
        scale_fill_discrete(name="Sottoscrizione", labels=c("no", "sì")) +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_housing_y
```

La distinzione tra mutuatari o meno sembra abbastanza discriminante sulla sottoscrizione; un gruppo sottoscrive al 16,5%, l'altro al 7,5%. Ha una logica il fatto che chi ha dovuto accolarsi un mutuo non abbia risorse finanziarie da investire per rendimento nel lungo periodo, data l'esigenza pressante di liquidità. Alla luce di ciò l'information value dovrebbe presentarci una variabile con potere predittivo medio.

```{r housing IV}
housing_woe <- bank0 %>%
        select(housing, y) %>%
        group_by(housing) %>%
        summarise(n_no = sum(y == "no"), n_y = sum(y == "yes")) %>%
        mutate (perc_no = n_no / sum(n_no), perc_y = n_y / sum(n_y)) %>%
        select (starts_with("perc"))
housing_woe$woe <- log(housing_woe$perc_no / housing_woe$perc_y)
housing_IV <- sum((housing_woe$perc_no - housing_woe$perc_y) * housing_woe$woe)
housing_IV
```

Esatto.

###Loan

Variabile dicotomica che indica che il cliente ha richiesto e sta pagando un prestito.

```{r loan graph and table}
t_loan  <- bank0 %>%
        group_by(loan) %>%
        summarise(frequenza = n()) %>%
        mutate(frequenza_relativa = frequenza / sum(frequenza)) %>%
        arrange(desc(frequenza))
kable(t_loan, digits = 4, format = "markdown")

g_loan  <- ggplot(bank0, aes(x = loan)) +
        geom_bar() +
        ggtitle("distribuzione per loan") +
        ylab("frequenza") +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_loan
```

La quota di persone con prestiti è intorno al 16%. Vediamo come si distribuiscono i sottoscrittori

```{r loan_y table and graph}
t_loan_y <- bank0 %>%
        group_by (loan) %>%
        summarise (frequenza = n(), tasso_sottoscrizioni = mean(y=="yes")) %>%
        mutate(frequenza_relativa = frequenza / sum(frequenza)) %>%
        select(loan, frequenza, frequenza_relativa, tasso_sottoscrizioni) %>%
        arrange(desc(tasso_sottoscrizioni))
kable(t_loan_y, digits = 4, format = "markdown")

g_loan_y  <- ggplot(bank0, aes(x = loan, fill = y)) +
        geom_bar(position = "fill") +
        geom_hline(yintercept = mean(bank0$y!="yes"), width = 2, col = "black", linetype = 2) +
        ggtitle("penetrazione per loan") +
        ylab("tasso sottoscrizioni") +
        scale_y_continuous(breaks = seq(0, 1, 0.1)) +
        scale_fill_discrete(name="Sottoscrizione", labels=c("no", "sì")) +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_loan_y
```

Il 16% dei richiedenti prestito ha un tasso di sottoscrizione pari alla metà del restante 84%, che sottoscrive poco sopra la media di portafoglio. Ci si aspettava in effetti un comportamento simile a quello di `housing`, e sarà interessante vedere l'effetto di interazione in chi sta pagando sia mutuo che prestito.

```{r loan IV}
loan_woe <- bank0 %>%
        select(loan, y) %>%
        group_by(loan) %>%
        summarise(n_no = sum(y == "no"), n_y = sum(y == "yes")) %>%
        mutate (perc_no = n_no / sum(n_no), perc_y = n_y / sum(n_y)) %>%
        select (starts_with("perc"))
loan_woe$woe <- log(loan_woe$perc_no / loan_woe$perc_y)
loan_IV <- sum((loan_woe$perc_no - loan_woe$perc_y) * loan_woe$woe)
loan_IV
```

In realtà l'information value restituisce una predittività debole.

###Contact

Variabile categoricha che indica la modalità di comunicazione col cliente.

```{r contact graph and table}
t_contact  <- bank0 %>%
        group_by(contact) %>%
        summarise(frequenza = n()) %>%
        mutate(frequenza_relativa = frequenza / sum(frequenza)) %>%
        arrange(desc(frequenza))
kable(t_contact, digits = 4, format = "markdown")

g_contact  <- ggplot(bank0, aes(x = contact)) +
        geom_bar() +
        ggtitle("distribuzione per contact") +
        ylab("frequenza") +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_contact
```

In sostanza abbiamo un 6% tramite fisso e il restante tramite cellullare. Purtroppo Un 29% dei clienti è stato contattato tramite modalità non rilevate.

```{r contact_y graph and table}
t_contact_y <- bank0 %>%
        group_by (contact) %>%
        summarise (frequenza = n(), tasso_sottoscrizioni = mean(y=="yes")) %>%
        mutate(frequenza_relativa = frequenza / sum(frequenza)) %>%
        select(contact, frequenza, frequenza_relativa, tasso_sottoscrizioni) %>%
        arrange(desc(tasso_sottoscrizioni))
kable(t_contact_y, digits = 4, format = "markdown")

g_contact_y  <- ggplot(bank0, aes(x = contact, fill = y)) +
        geom_bar(position = "fill") +
        geom_hline(yintercept = mean(bank0$y!="yes"), width = 2, col = "black", linetype = 2) +
        ggtitle("penetrazione per contact") +
        ylab("tasso sottoscrizioni") +
        scale_y_continuous(breaks = seq(0, 1, 0.1)) +
        scale_fill_discrete(name="Sottoscrizione", labels=c("no", "sì")) +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_contact_y
```

Interessantissimo notare che c'è una variabilità sistematica: se la modalità di contatto è sconosciuta la percentuale di sottoscrittori è bassissima. Questo vorrà dire qualcosa, ma è complicato immaginare il motivo. Il restante 70% di portafoglio sottoscrive al 14% circa, contro l'11,7% complessivo. La variabile sembra discriminante, vediamo se l'information value lo conferma.

```{r contact IV}
contact_woe <- bank0 %>%
        select(contact, y) %>%
        group_by(contact) %>%
        summarise(n_no = sum(y == "no"), n_y = sum(y == "yes")) %>%
        mutate (perc_no = n_no / sum(n_no), perc_y = n_y / sum(n_y)) %>%
        select (starts_with("perc"))
contact_woe$woe <- log(contact_woe$perc_no / contact_woe$perc_y)
contact_IV <- sum((contact_woe$perc_no - contact_woe$perc_y) * contact_woe$woe)
contact_IV
```

Confermato, la predittività è di media / forte entità.

###Day

La variabile rileva il giorno del mese dell'ultimo contatto, che laddove `y = "yes` significa la chiamata di vendita.

```{r day graph}
t_day  <- bank0 %>%
        group_by(day) %>%
        summarise(frequenza = n()) %>%
        mutate(frequenza_relativa = frequenza / sum(frequenza)) %>%
        arrange(day)
kable(t_day, digits = 4, format = "markdown")

g_day  <- ggplot(bank0, aes(x = factor(day))) +
        geom_bar() +
        ggtitle("distribuzione per day") +
        xlab("day") +
        ylab("frequenza") +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_day
```

Il 1, 10, 24 e 31 del mese accade poche volte che ci sia l'ultima chiamata della campagna. Chissà perché.

```{r day_y graph and table}
t_day_y <- bank0 %>%
        group_by (day) %>%
        summarise (frequenza = n(), tasso_sottoscrizioni = mean(y=="yes")) %>%
        mutate(frequenza_relativa = frequenza / sum(frequenza)) %>%
        select(day, frequenza, frequenza_relativa, tasso_sottoscrizioni) %>%
        arrange(day)
kable(t_day_y, digits = 4, format = "markdown")

g_day_y  <- ggplot(bank0, aes(x = factor(day), fill = y)) +
        geom_bar(position = "fill") +
        geom_hline(yintercept = mean(bank0$y!="yes"), width = 2, col = "black", linetype = 2) +
        ggtitle("penetrazione per day") +
        xlab("day") +
        ylab("tasso sottoscrizioni") +
        scale_y_continuous(breaks = seq(0, 1, 0.1)) +
        scale_fill_discrete(name="Sottoscrizione", labels=c("no", "sì")) +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_day_y
```

I due giorni di maggior sottoscrizione sono quelli con il minor numero di contatti. Chissà perché. Sarebbe inoltre utile capire se c'è una interazione tra il giorno dell'ultima chiamata e il numero di contatti già effettuati, così da vedere se ci sono giorni dove basta una chiamata sola per vendere il prodotto. In generale c'è parecchia variabilità all'interno del mese sul tasso di sottoscrizioni.


```{r day IV}
day_woe <- bank0 %>%
        select(day, y) %>%
        group_by(day) %>%
        summarise(n_no = sum(y == "no"), n_y = sum(y == "yes")) %>%
        mutate (perc_no = n_no / sum(n_no), perc_y = n_y / sum(n_y)) %>%
        select (starts_with("perc"))
day_woe$woe <- log(day_woe$perc_no / day_woe$perc_y)
day_IV <- sum((day_woe$perc_no - day_woe$perc_y) * day_woe$woe)
day_IV
```

Media predittività.

###Month

La variabile rileva il mese dell'ultimo contatto, che laddove `y = "yes"` significa la chiamata di vendita. Può essere considerato il mese di chiusura della campagna per il singolo cliente.

```{r month graph and table}
bank0$month <- factor(bank0$month, levels = c("jan","feb","mar", "apr","may","jun", "jul","aug", "sep", "oct", "nov","dec"))
t_month  <- bank0 %>%
        group_by(month) %>%
        summarise(frequenza = n()) %>%
        mutate(frequenza_relativa = frequenza / sum(frequenza))
kable(t_month, digits = 4, format = "markdown")

g_month  <- ggplot(bank0, aes(x = month)) +
        geom_bar() +
        ggtitle("distribuzione per month") +
        ylab("frequenza") +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_month
```

I mesi di ultima chiamata sono prevalentemente quelli estivi. La campagna di marketing è andata avant per due anni, quindi non è chiaro se ci sia stato o meno ogni anno un focus particolare in estate, quando magari l'operatività corrente è inferiore.

```{r month_y graph and table}
t_month_y <- bank0 %>%
        group_by (month) %>%
        summarise (frequenza = n(), tasso_sottoscrizioni = mean(y=="yes"), numero_sottoscrizioni = sum(y=="yes")) %>%
        mutate(frequenza_relativa = frequenza / sum(frequenza)) %>%
        select(month, frequenza, frequenza_relativa, tasso_sottoscrizioni, numero_sottoscrizioni)
kable(t_month_y, digits = 4, format = "markdown")

g_month_y  <- ggplot(bank0, aes(x = month, fill = y)) +
        geom_bar(position = "fill") +
        geom_hline(yintercept = mean(bank0$y!="yes"), width = 2, col = "black", linetype = 2) +
        ggtitle("penetrazione per month") +
        ylab("tasso sottoscrizioni") +
        scale_y_continuous(breaks = seq(0, 1, 0.1)) +
        scale_fill_discrete(name="Sottoscrizione", labels=c("no", "sì")) +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_month_y
```

I  mesi di maggior sottoscrizione, in percentuale, sono quelli con il minor numero di contatti. Si sottoscrive pochissimo d'estate, infatti, e questo dovrebbe indurci a pensare che il management non ponga un focus particolare sul fare gli outbound d'estate. Anche qui l'interazione con il numero di contatti precedenti può essere importante, e idem per la durata dell'ultima chiamata: se ci sono ultime chiamate molto lunghe (magari perché si sta vendendo il prodotto) allora ci può stare che se ne facciano di meno in alcuni mesi.

```{r month IV}
month_woe <- bank0 %>%
        select(month, y) %>%
        group_by(month) %>%
        summarise(n_no = sum(y == "no"), n_y = sum(y == "yes")) %>%
        mutate (perc_no = n_no / sum(n_no), perc_y = n_y / sum(n_y)) %>%
        select (starts_with("perc"))
month_woe$woe <- log(month_woe$perc_no / month_woe$perc_y)
month_IV <- sum((month_woe$perc_no - month_woe$perc_y) * month_woe$woe)
month_IV
```

Predittività molto forte.

###Duration

Durata in secondi dell'ultima chiamata effettuata al cliente. Se il valore è pari a zero significa che all'ultima chiamata il cliente non ha risposto. Analizziamo la distribuzione univariata:

```{r duration quant graph and table}
summary(bank0$duration)
duration_quantile <- quantile(bank0$duration, c(seq(0.1, 1, 0.05)))
duration_quantile

g_duration <- ggplot(bank0, aes(x = duration)) + 
        geom_histogram(binwidth = 20) +
        ggtitle("distribuzione di duration") +
        xlab("duration") +
        ylab("frequenza") +
        scale_x_continuous(breaks = seq(0, 5000, 250))+
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_duration
```

Una distribuzione molto concentrata in un piccolo intervallo, il 70% delle chiamate non supera i 280 secondi. Vediamo se il comportamento della variabile cambia considerando chi sottoscrive e chi non sottoscrive.

```{r duration_y quant graph}
g_duration_y <- ggplot(bank0, aes(x = y, y = duration)) + 
        geom_boxplot(aes(col = y)) +
        ggtitle("distribuzione di duration per sottoscrizione") +
        xlab("sottoscrizione") +
        scale_x_discrete(labels = c("no", "sì")) +
        scale_color_discrete(name="Sottoscrizione", labels=c("no", "sì"))
g_duration_y
```


```{r duration_class_y table and graph}
duration_decile <- quantile(bank0$duration[bank0$duration != 0], probs = seq(0.1,1,0.1))
bank0$duration_class <- cut(bank0$duration, breaks = c(-1, 0, duration_decile), right = TRUE, labels = c("no call", "(0,58]",  "(58,89]", "(89,117]", "(117,147]"," (147,180]", "(180,223]", "(223,280]", "(280,368]", "(368,548]", "(548,4918]"))

t_duration_class_y <- bank0 %>%
        group_by (duration_class) %>%
        summarise (frequenza = n(), tasso_sottoscrizioni = mean(y=="yes")) %>%
        mutate(frequenza_relativa = frequenza / sum(frequenza)) %>%
        select(duration_class, frequenza, frequenza_relativa, tasso_sottoscrizioni)
kable(t_duration_class_y, digits = 4, format = "markdown")

g_duration_class_y  <- ggplot(bank0, aes(x = duration_class, fill = y)) +
        geom_bar(position = "fill") +
        geom_hline(yintercept = mean(bank0$y!="yes"), width = 2, col = "black", linetype = 2) +
        ggtitle("penetrazione per duration_class") +
        ylab("tasso sottoscrizioni") +
        scale_y_continuous(breaks = seq(0, 1, 0.1)) +
        scale_fill_discrete(name="Sottoscrizione", labels=c("no", "sì")) +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_duration_class_y
```

Muovendosi all'interno dei 10 gruppi di dimensioni simili il tasso di sottoscrizione aumenta all'aumentare della durata della chiamata. La cosa ha senso, dato che una chiamata in cui si vende richiede tempo lunghi perché il cliente è molto interessato al prodotto e inoltre dovrà assolvere a dei questionari burocratici. Tuttavia la durata della chiamata non è nota in anticipo, quindi non ha senso includere la variabile in un modello predittivo.

```{r duration IV} 
#devo togliere i tre valori nulli di duration altrimenti la formula va in errore
duration_class_woe <- bank0 %>%
        filter(duration_class != "no call") %>%
        select(duration_class, y) %>%
        group_by(duration_class) %>%
        summarise(n_no = sum(y == "no"), n_y = sum(y == "yes")) %>%
        mutate (perc_no = n_no / sum(n_no), perc_y = n_y / sum(n_y)) %>%
        select (starts_with("perc"))
duration_class_woe$woe <- log(duration_class_woe$perc_no / duration_class_woe$perc_y)
duration_class_IV <- sum((duration_class_woe$perc_no - duration_class_woe$perc_y) * duration_class_woe$woe)
duration_class_IV
```

è infatti un valore di 1.6 è davvero sospetto, troppo alto per essere vero.

###Campaign

Numero di contatti complessivi avuto con il cliente durante la campagna promozionale. Include l'ultimo contatto.

```{r campaign quant table and graph}
summary(bank0$campaign)
campaign_quantile <- quantile(bank0$campaign, c(seq(0.1, 1, 0.05)))
campaign_quantile

g_campaign <- ggplot(bank0, aes(x = factor(campaign))) + 
        geom_histogram(binwidth = 1) +
        ggtitle("distribuzione di duration") +
        xlab("campaign") +
        ylab("frequenza") +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_campaign
```

Il 95% dei valori è tra 1 e 8 contatti. Ha senso raggruppare la variabile in classi 

```{r campaign_class table and graph}
bank0$campaign_class <- cut(bank0$campaign, breaks = c(0, 1, 2, 3, 4, 5, max(bank0$campaign)+1), right = TRUE, labels = c("1", "2", "3", "4", "5", "up 5"))

t_campaign_class  <- bank0 %>%
        group_by(campaign_class) %>%
        summarise(frequenza = n()) %>%
        mutate(frequenza_relativa = frequenza / sum(frequenza))
kable(t_campaign_class, digits = 4, format = "markdown")

g_campaign_class  <- ggplot(bank0, aes(x = campaign_class)) +
        geom_bar() +
        ggtitle("distribuzione per campaign_class") +
        ylab("frequenza") +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_campaign_class
```

Vediamo come si comportano i sottoscrittori attraverso i vari livelli di `campaign`.

```{r campaign_class_ table and graph}
t_campaign_class_y <- bank0 %>%
        group_by (campaign_class) %>%
        summarise (frequenza = n(), tasso_sottoscrizioni = mean(y=="yes")) %>%
        mutate(frequenza_relativa = frequenza / sum(frequenza)) %>%
        select(campaign_class, frequenza, frequenza_relativa, tasso_sottoscrizioni)
kable(t_campaign_class_y, digits = 4, format = "markdown")

g_campaign_class_y  <- ggplot(bank0, aes(x = campaign_class, fill = y)) +
        geom_bar(position = "fill") +
        geom_hline(yintercept = mean(bank0$y!="yes"), width = 2, col = "black", linetype = 2) +
        ggtitle("penetrazione per campaign_class") +
        ylab("tasso sottoscrizioni") +
        scale_y_continuous(breaks = seq(0, 1, 0.1)) +
        scale_fill_discrete(name="Sottoscrizione", labels=c("no", "sì")) +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_campaign_class_y
```

Meno chiamate vengono fatte ai clienti, più si vende (in proporzione). Significa che al cliente davvero interessato basta una chiamata. Solo la fascia "1 contatto" ha un tasso di sottoscrizione superiore a quello complessivo, questa è una informazione rilevante. Vediamo l'information value:

```{r campaign IV}
campaign_class_woe <- bank0 %>%
        select(campaign_class, y) %>%
        group_by(campaign_class) %>%
        summarise(n_no = sum(y == "no"), n_y = sum(y == "yes")) %>%
        mutate (perc_no = n_no / sum(n_no), perc_y = n_y / sum(n_y)) %>%
        select (starts_with("perc"))
campaign_class_woe$woe <- log(campaign_class_woe$perc_no / campaign_class_woe$perc_y)
campaign_class_IV <- sum((campaign_class_woe$perc_no - campaign_class_woe$perc_y) * campaign_class_woe$woe)
campaign_class_IV
```

0.08, predittore debole.

###pdays

Variabile che rileva il numero di giorni trascorsi da quando il cliente è stato contattato per una precedente campagna. Se `pdays = -1` allora il cliente non è stato mai contattato per la precedente campagna.

Vediamo come si distribuisce la variabile se il cliente è stato contattato.

```{r pdays quant graph and table}
summary(bank0$pdays[bank0$pdays != -1])
pdays_decile <- quantile(bank0$pdays[bank0$pdays != -1], c(seq(0.1, 1, 0.1)))

g_pdays_quant <- bank0  %>% 
        filter(pdays != -1) %>% 
        ggplot(aes(x = pdays)) + 
        geom_histogram(binwidth = 10) +
        ggtitle("distribuzione di pdays") +
        xlab("pdays") +
        ylab("frequenza") +
        scale_x_continuous(breaks = seq(0, 871, 50))+
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_pdays_quant
````

Una distribuzione quasi trimodale; immagino che nell'attuale campagna ci siano stati dei periodi con maggiore concentrazione di chiamate, che hanno generato quelle tre mode. Anche la variabile `month` conferma che ci sono stati mesi con molta più concentrazione di chiamate. Vediamo come si dsitribuisce `pdays` condizionando per la sottoscrizione:

```{r pdays_y quant graph}
g_pdays_quant_y <- bank0 %>% 
        filter(pdays != -1) %>% 
        ggplot(aes(x = y, y = pdays)) + 
        geom_boxplot(aes(col = y)) +
        ggtitle("distribuzione di pdays per sottoscrizione") +
        xlab("sottoscrizione") +
        scale_x_discrete(labels = c("no", "sì")) +
        scale_color_discrete(name="Sottoscrizione", labels=c("no", "sì"))
g_pdays_quant_y
```

Chi non sottoscrive è un cliente per cui sono trascorsi più giorni dall'ultimo contatto. Questo ha senso. Dobbiamo tuttavia indagare il comportamento dei sottoscrittori anche tra chi non è mai stato contatatto, e per questo raggruppiamo la variabile in classi, una per i non contattati e poi dieci in base ai decili.

```{r pdays_class table}
bank0$pdays_class <- cut(bank0$pdays, breaks = c(-2, 0, pdays_decile), right = TRUE, labels = c("no campaign", "(0,91]",  "(91,108]", "(108,159]", "(159,181]"," (181,194]", "(194,258]", "(258,300]", "(300,343]", "(343,362]", "(362,871]"))
table(bank0$pdays_class)
```

Circa l'80% dei clienti contattati per questa campagna non è mai stato contattato precedentemente. Ora vediamo come il tasso di sottoscrizione si distribuisce all'interno delle 11 classi:

```{r pdays_class_y table and graph}
t_pdays_class_y <- bank0 %>%
        group_by (pdays_class) %>%
        summarise (frequenza = n(), tasso_sottoscrizioni = mean(y=="yes")) %>%
        mutate(frequenza_relativa = frequenza / sum(frequenza)) %>%
        select(pdays_class, frequenza, frequenza_relativa, tasso_sottoscrizioni)
kable(t_pdays_class_y, digits = 4, format = "markdown")

g_pdays_class_y  <- ggplot(bank0, aes(x = pdays_class, fill = y)) +
        geom_bar(position = "fill") +
        geom_hline(yintercept = mean(bank0$y!="yes"), width = 2, col = "black", linetype = 2) +
        ggtitle("penetrazione per pdays_class") +
        ylab("tasso sottoscrizioni") +
        scale_y_continuous(breaks = seq(0, 1, 0.1)) +
        scale_fill_discrete(name="Sottoscrizione", labels=c("no", "sì")) +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_pdays_class_y
```

In generale se in passato si è stati contattati si sottoscrive di più che se non lo si è mai stati; il tasso non decresce in maniera monotona ma la distribuzione sembra comunque abbastanza informativa.

```{r pdays_class IV}
pdays_class_woe <- bank0 %>%
        select(pdays_class, y) %>%
        group_by(pdays_class) %>%
        summarise(n_no = sum(y == "no"), n_y = sum(y == "yes")) %>%
        mutate (perc_no = n_no / sum(n_no), perc_y = n_y / sum(n_y)) %>%
        select (starts_with("perc"))
pdays_class_woe$woe <- log(pdays_class_woe$perc_no / pdays_class_woe$perc_y)
pdays_class_IV <- sum((pdays_class_woe$perc_no - pdays_class_woe$perc_y) * pdays_class_woe$woe)
pdays_class_IV
```

Infatti 0.34 come information value significa predittore potente.

###Previous

Numero di volte in cui il cliente è stato contattato prima di questa campagna.

```{r previous quant table and graph}
previous_decile <- quantile(bank0$previous, c(seq(0.1, 1, 0.1)))
previous_decile

g_previous_quant <- ggplot(bank0, aes(x = previous)) + 
        geom_histogram(binwidth = 5) +
        ggtitle("distribuzione di previous") +
        xlab("pdays") +
        ylab("frequenza") +
        scale_x_continuous(breaks = seq(0, 275, 5))+
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_previous_quant
````

L'80% dei clienti non è mai stato contattato, è una distribuzione molto strana. Vediamo distinguendo tra sottoscrittori e non in un boxplot:

```{r previous_y quant graph}
g_previous_quant_y <- ggplot(bank0, aes(x = y, y = previous)) + 
        geom_boxplot(aes(col = y)) +
        ggtitle("distribuzione di previous per sottoscrizione") +
        xlab("sottoscrizione") +
        scale_x_discrete(labels = c("no", "sì")) +
        scale_y_continuous(breaks = seq(0, 200, 10)) +
        scale_color_discrete(name="Sottoscrizione", labels=c("no", "sì"))
g_previous_quant_y
```

In questo modo individuare una associazione tra `previous` e sottoscrizione è impossibile. Raggruppiamo in classi, anche se mi aspetto una forte correlazione con `pdays`.
 
```{r previous_class table}
previous_nz_quantile <- quantile(bank0$previous[bank0$previous > 0], probs = seq(0.1,1,0.1))
#Considerando i decili, preferisco fare 7 classi di non pari frequenza: da 0 a 6 e maggiore di 6
bank0$previous_class <- cut(bank0$previous, breaks = c(0, 1, 2, 3, 4, 5, 7, max(bank0$previous)+1), right = FALSE, labels = c("0 contact", "1 contact",  "2 contact", "3 contact", "4 contact","5 or 6 contact", "+ 6 contact"))
table(bank0$previous_class)
summary(bank0$previous_class)
```

```{r previous_class_y graph and table}
t_previous_class_y <- bank0 %>%
        group_by (previous_class) %>%
        summarise (frequenza = n(), tasso_sottoscrizioni = mean(y=="yes")) %>%
        mutate(frequenza_relativa = frequenza / sum(frequenza)) %>%
        select(previous_class, frequenza, frequenza_relativa, tasso_sottoscrizioni)
kable(t_previous_class_y, digits = 4, format = "markdown")

g_previous_class_y  <- ggplot(bank0, aes(x = previous_class, fill = y)) +
        geom_bar(position = "fill") +
        geom_hline(yintercept = mean(bank0$y!="yes"), width = 2, col = "black", linetype = 2) +
        ggtitle("penetrazione per previous_class") +
        ylab("tasso sottoscrizioni") +
        scale_y_continuous(breaks = seq(0, 1, 0.1)) +
        scale_fill_discrete(name="Sottoscrizione", labels=c("no", "sì")) +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_previous_class_y
```

Anche qui c'è un comportamento chiaro: se non si è mai stati contattati si sottoscrive meno (in proporzione) della media, altrimenti sensibilmente di più. Mi aspetto forte predittività:

```{r previous_class IV}
previous_class_woe <- bank0 %>%
        select(previous_class, y) %>%
        group_by(previous_class) %>%
        summarise(n_no = sum(y == "no"), n_y = sum(y == "yes")) %>%
        mutate (perc_no = n_no / sum(n_no), perc_y = n_y / sum(n_y)) %>%
        select (starts_with("perc"))
previous_class_woe$woe <- log(previous_class_woe$perc_no / previous_class_woe$perc_y)
previous_class_IV <- sum((previous_class_woe$perc_no - previous_class_woe$perc_y) * previous_class_woe$woe)
previous_class_IV
```

0.22 è vicina ad essere forte predittività.

###Poutcome

Esito della precedente campagna promozionale per il medesimo cliente. Analizziamo subito la distribuzione univariata:

```{r poutcome table and graph }
t_poutcome <- bank0 %>%
        group_by (poutcome) %>%
        summarise (frequenza = n()) %>%
        mutate (frequenza_relativa = frequenza / sum(frequenza)) %>%
        arrange(desc(frequenza_relativa))
kable(t_poutcome, digits = 4, format = "markdown")

g_poutcome  <- ggplot(bank0, aes(x = poutcome)) +
        geom_bar() +
        ggtitle("distribuzione per poutcome") +
        ylab("frequenza") +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_poutcome
```

Gli "unknown" saranno senz'altro quell'80% di clienti mai contattati. Vediamo nelle quattro fascie come si sottoscrive:

```{r poutcome_y table and graph}
t_poutcome_y <- bank0 %>%
        group_by (poutcome) %>%
        summarise (frequenza = n(), tasso_sottoscrizioni = mean(y=="yes")) %>%
        mutate(frequenza_relativa = frequenza / sum(frequenza)) %>%
        select(poutcome, frequenza, frequenza_relativa, tasso_sottoscrizioni) %>%
        arrange(desc(tasso_sottoscrizioni))
kable(t_poutcome_y, digits = 4, format = "markdown")

g_poutcome_y  <- ggplot(bank0, aes(x = poutcome, fill = y)) +
        geom_bar(position = "fill") +
        geom_hline(yintercept = mean(bank0$y!="yes"), width = 2, col = "black", linetype = 2) +
        ggtitle("penetrazione per poutcome") +
        ylab("tasso sottoscrizioni") +
        scale_y_continuous(breaks = seq(0, 1, 0.1)) +
        scale_fill_discrete(name="Sottoscrizione", labels=c("no", "sì")) +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_poutcome_y
```

Se la precedente campagna ha avuto successo si sottoscrive in percentuali altissime. Persino se è stata fallimentare però si sottoscrive di più che se non si è mai stati contatatti; questo è coerente con l'analisi di `previous`, per cui il gruppo dei contattati sottoscriveva comunque di più dei mai contatatti.

```{r poutcome IV}
poutcome_woe <- bank0 %>%
        select(poutcome, y) %>%
        group_by(poutcome) %>%
        summarise(n_no = sum(y == "no"), n_y = sum(y == "yes")) %>%
        mutate (perc_no = n_no / sum(n_no), perc_y = n_y / sum(n_y)) %>%
        select (starts_with("perc"))
poutcome_woe$woe <- log(poutcome_woe$perc_no / poutcome_woe$perc_y)
poutcome_IV <- sum((poutcome_woe$perc_no - poutcome_woe$perc_y) * poutcome_woe$woe)
poutcome_IV
```

0.51, molto predittiva, ai limiti del sospetto.

###Information values

Creiamo il vettore degli information values e lo rappresentiamo tramite grafico:

```{r all IV table}
names(bank0)
IV <- c(age_class_IV, job_IV, marital_IV, education_IV, default_IV, balance_class_IV, housing_IV, loan_IV, contact_IV, day_IV, month_IV, duration_class_IV, campaign_class_IV, pdays_class_IV, previous_class_IV, poutcome_IV)
Variables <- c("age_class", "job", "marital", "education", "default", "balance_class", "housing", "loan", "contact", "day", "month", "duration_class", "campaign_class", "pdays_class", "previous_class", "poutcome")
t_IV_all <- data.frame(Variables, IV)
t_IV_all <- t_IV_all %>%
        arrange(desc(IV))
t_IV_all
```

```{r all IV graph}
g_IV_all <- ggplot(t_IV_all, aes(x= reorder(Variables, IV), y= IV)) +
        geom_bar(stat='identity') +
        coord_flip() +
        ggtitle ("Information values") +
        ylab("Variabili") +
        xlab("Inromation value") +
        geom_hline(yintercept = c(0.02, 0.1, 0.3, 0.5), linewidth = 2, linetype = 2, col = c("yellow", "blue", "green", "red"))
g_IV_all
```

Le 4 rette trattegiate indicano le soglie per: predittività assente (tra asse e retta gialla), debole (tra retta gialla e blue), media (tra retta blu e verde), forte (tra retta verde e rossa), sospetta (oltre retta rossa).

##Esplorazione dell'associazione tra coppie di variabili e in relazione alla sottoscrizione

###Tre tipologie di relazione tra tre variabili
Forniamo un breve commento ai tre esempi che seguono. 

Al punto 1 presentiamo la situazione detta *spiegazione*. La tab. 3 mostra la tabella a doppia entrata originale che mette in relazione il numero delle pompe antincendio presenti sul luogo di un incendio e l’entità dei danni dello stesso. Come si vede tra le due variabili vi è relazione: solo il 30% degli incidenti è caratterizzato da danni superiori a 10.000$ se le autopompe non sono più di 2, sale al 59% se le autopompe sono più di 2. Naturalmente il numero di autopompe che vengono inviate sul luogo dell’incendio sarà legato alle dimensioni dell’incendio stesso e quindi al presumibile danno prodotto. Quindi occorre *controllare la relazione originale* introducendo la variabile “dimensione dell’incendio”. Si vede così in tab 1 che a parità di dimensioni dell’incendio, non vi è alcuna relazione tra numero di autopompe e ammontare del danno: se le dimensioni sono ridotte solo il 5% degli incendi produce un danno superiore a 10.000$, indipendentemente dal numero di autopompe presenti; questa percentuale sale all’80% quando l’incendio è di ampie dimensioni, anche qui indipendentemente dal numero di autopompe coinvolte. E’ ovvio che il numero di autopompe non può determinare le dimensioni dell’incendio, ma ne è una sua conseguenza. Il numero di autopompe non determina neppure l’ammontare dei danni. In realtà le dimensioni causano sia il numero di autopompe che l’ammontare del danno, così che la relazione tra autopompe e danno è fittizia, dovuta esclusivamente alla terza variabile, perciò *spuria*. => Non so se il confondimento implica che la relazione sia spuria.

Al punto 2 presentiamo la situazione detta *interpretazione*. La tab. 6 mostra la tabella a doppia entrata originale che mette in relazione sesso e coinvolgimento in incidenti. Come si vede le donne hanno meno incidenti dei maschi: 32% e 44% rispettivamente. Bisogna però considerare che, al di là della prudenza e delle capacità di guida, il semplice fatto di percorrere mediamente più chilometri espone ad una probabilità maggiore di incorrere in incidenti. Se introduciamo come terza variabile la percorrenza chilometrica annua (tab. 4) vediamo che la relazione tra sesso e incidenti sparisce: se la percorrenza è bassa il 25% dei conducenti è coinvolto in incidenti qualunque sia il suo sesso; se la percorrenza è alta questa percentuale sale al 52% sia tra i maschi che tra le femmine. *A prima vista, la relazione tra sesso e incidenti potrebbe apparire spuria come nell’esempio precedente. Qui però vi è una differenza fondamentale: la terza variabile non è la causa delle due variabili originali (la percorrenza non causa il sesso del conducente)*. *Siamo invece in presenza di una catena causale: il sesso causa la percorrenza che a sua volta causa il coinvolgimento in incidenti. Insomma la relazione tra sesso e incidenti non è fittizia*, appare a prima vista incomprensibile perché è *mediata* da una variabile intermedia, la percorrenza. E’ in questo senso che si dice che la relazione originale è interpretata. Anche qui forniamo la tab. 5, forma compatta della tab. 4.=> l'interpretazione è quando tra la relazione causale tra2 variabili se ne include una terza intermedia che cambia l'interpretazione della relazione, che comunque ha senso, non è spuria come nobel e cioccolato.

Al punto 3 presentiamo la situazione detta *specificazione*. La tab. 9 mostra la tabella a doppia entrata originale che mette in relazione orientamento politico e interesse per la politica. La tab. 7 mostra cosa accade *quando introduciamo come variabile di controllo*, il titolo di studio. In origine tra coloro che si collocano a sinistra il 28% ha un interesse alto, che scende al 15% tra i soggetti di destra. Questa differenza resta anche quando si introduce la terza variabile. Bisogna però notare che tra coloro che hanno un basso grado di istruzione i valori sono pari a 19% e 7%, cioè valori più bassi di quelli della relazione bivariata e con una differenza tra sinistra e destra equivalente. Tra coloro invece che hanno un elevato titolo di studio l’interesse per la politica aumenta: coloro che sono molto interessati crescono rispettivamente al 36% e al 18%, rispettivamente per sinistra e destra, con una differenza tra i due pari a 18 punti percentuali, contro i 13 della relazione originaria. Qui entrambe le variabili “orientamento” e “titolo” influenzano la dipendente ed è per questo che si parla di “specificazione” della relazione originale.=> a me questo sembra effetto di interazione: l'introduzione di una terza variabile porta a un effetto congiunto delle due indipendenti che è piu (perché cambiano le differenze tra i valori) della loro moltiplicazione.

#Link utili

* [epidemiologia1](http://www.quadernodiepidemiologia.it/epi/freq/stn_mis.htm)
* [epidemiologia2](http://www.quadernodiepidemiologia.it/epi/assoc/ass_nc.htm)
* [confounding and interaction](https://www.ctspedia.org/do/view/CTSpedia/InterConfound)
* [stratified analysis - il più importante](http://www.sjsu.edu/faculty/gerstman/StatPrimer/stratified.PDF)

L'ultimo link, un pdf, è semplicemente illuminante. Così come il paragrafo che ho copiato sopra.

#Confounding and interaction: crude vs stratified analysis.
Confounding (from the Latin confundere: to mix together) is a *distortion of an association* between an exposure (E) and disease (D) brought about by extraneous factors (C1, C2, etc). Since confounding is a systematic (not random) error, hypothesis testing cannot be used to detect it. It is a judgement based science. The analyst should start with simple comparisons of means and proportions.

Interaction, as distinct from confounding, is the interdependent operation of two or more factors to produce an unanticipated effect. Interactions is usually addressed by reporting data by subgroups.

Measures of association in the aggregate are called crude measures of association.

Stratification might reveal otherwise hidden confounding and interaction. Example with RR; se il RR crudo è 4.00, e stratificando per i tre livelli di C abbiamo sempre RRC=4.00, allora la stratificazione è superflua. Se RRC = 1.00 sempre, allora c'è confounding. Se RRC = 1.00, 3.00, 25.00, c'è interazione.

Spesso c'è in parte confounding e in parte interaction. The best estimate of association is both valid and precise. If interaction is present, strata-specific measures of association are reported. If interaction is absent but confounding is present, summary (adjusted) measures of association are reported. If neither interaction nor confounding are present, crude (unadjusted) measures of association are reported. In general, the most parsimoniously unconfounded presentation of the data is preferred. If the association between the exposure and disease is not found by scrutinizing the data in the 2-by-2 table, it's hard to support. Simple is better. 
Qui si parla di RR e di quale va riportato se c'è confounding e/o se c'è interaction.

##Age e job

L'ipotesi è che il maggior tasso di sottoscrizione della fascia giovane possa spiegare o essere spiegato dal maggiore tasso di sottoscrizione degli studenti. Lo stesso vale per fascia anziana e pensionati. Poiché in questo caso la direzione causale non è chiara sin dal principio, dovremo capire come ognuna delle due variabili si distribuisce sui livelli dell'altra. Lo faremo tramite esplorazione grafica:

```{r age job graph and table}
t_job_age <- bank0 %>%
        group_by(job, age_class) %>%
        summarise(frequenza = n()) %>%
        mutate(frequenza_relativa = frequenza / sum(frequenza)) %>%
        select(job, age_class, frequenza_relativa) %>%
        spread(age_class, frequenza_relativa)
kable(t_job_age, digits = 4, format = "markdown")

g_job_age  <- ggplot(bank0, aes(x = job, fill = age_class)) +
        geom_bar(position = "fill") +
        ggtitle("distribuzione di age_class per job") +
        ylab("percentuale di fascie di età") +
        scale_y_continuous(breaks = seq(0, 1, 0.1)) +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_job_age

g_age_job  <- ggplot(bank0, aes(x = age_class, fill = job)) +
        geom_bar(position = "fill") +
        ggtitle("distribuzione di job per age_class") +
        ylab("percentuale di job") +
        scale_y_continuous(breaks = seq(0, 1, 0.1)) +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_age_job
```

Notiamo dal primo grafico che per tutte le professioni tranne due la maggior parte dei clienti sono adulti; tuttavia gli studenti sono tutti giovani e metà pensionati sono anziani. Se però osserviamo il secondo grafico vediamo che non è vero il contrario: i giovani non sono tutti studenti, anzi, fanno i lavori più disparati. Vediamo come si sottoscrive per combinazione di fascia di età e professione:

```{r age job y graph and table}
g_job_age_class_y <- ggplot(bank0, aes(x = job, fill = y)) + 
        geom_bar(position = "fill") + 
        geom_hline(yintercept = mean(bank0$y!="yes"), width = 2, col = "black", linetype = 2) +
        facet_wrap(~age_class) +
        ggtitle("penetrazione per age e job") +
        ylab("percentuale di job") +
        scale_y_continuous(breaks = seq(0, 1, 0.1)) +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_job_age_class_y

t_job_age_y <- bank0 %>%
        group_by(job, age_class) %>%
        summarise(tasso_sottoscrizione = mean(y == "yes")) %>%
        select(job, age_class, tasso_sottoscrizione) %>%
        spread(age_class, tasso_sottoscrizione) %>%
        left_join(t_job_y, by ="job") %>%
        select(-frequenza, -frequenza_relativa)
kable(t_job_age_y, digits = 4, format = "markdown")
```

Se fosse l'età a spiegare la maggior sottoscrizione di pensionati e studenti, in ragione del fatto che quasi tutti gli studenti sono giovani e che il 50% dei pensionati sono anziani, allora confrontando tutti clienti della stessa età dovremmo avere comportamenti simili. Nella fascia 18-30 stiamo prendendo in considerazione tutti clienti giovani, eppure osserviamo differenze di comportamento tra una professione e l'altra, quindi l'età non spiega tutta la differenza di comportamento tra le professioni. Anche tra gli anziani ci sono differenze di comportamento tra una professione e l'altra, i pensionati convertono di più di altre professioni a parità di età, quindi anche qui l'età non spiega la relazione tra professione e sottoscrizione.

Quando non si può spiegare la relazione tra due variabili grazie a una terza l'unica altra verifica da fare è l'eventuale presenza di interazione, vale a dire di comportamenti differenti della relazione tra due variabili quando l'indipendente si combina con un'altra variabile indipendente, in aggiunta al semplice **main effect**. Nel nostro caso, il **main effect** si esprime coil fatto che tutte le professioni, se i clienti sono adulti, sottoscrivono meno, un indizio di interazione invece risiede nella comparazione tra pensionati e altre professioni nella fascia adulta rispetto al campione complessivo: dall'essere, nel complesso, la seconda professione a sottoscrivere (in proporzione), nella fascia adulta è dietro a molte altre professioni. Sembra una interazione debole, la testeremo nel modello per scrupolo, e possiamo provare a rappresentarla in questo modo:


```{r age and job interaction graph}
t_job_age_y_pp <- bank0 %>%
        group_by(job, age_class) %>%
        summarise(tasso_sottoscrizione = mean(y == "yes")) %>%
        select(job, age_class, tasso_sottoscrizione)
g_job_age_y_pp <- ggplot(t_job_age_y_pp, aes(x = age_class, y = tasso_sottoscrizione, col = job, group = job)) +
        geom_point() +
        geom_line() +
        ggtitle("interazione tra age e job") +
        xlab("età")
```

In presenza di solo main effect tutte le rette sono parallele, vale a dire che tra le professione, passando da una fascia di età all'altra, lo scostamento in termini di tasso di sottoscrizione è costante. Nel nostro caso solo con i pensionati che non sia così, cioè che la combinazione età + professione generi un maggior aumento del tasso di sottoscrizione.

##Age e marital

Analizziamo la relazione tra `age` e `marital` per capire se il comportamento dei single, sposati e divorziati è guidato dall'età o viceversa o nessuna delle due.


```{r age marital graph and table}
t_marital_age <- bank0 %>%
        group_by(marital, age_class) %>%
        summarise(frequenza = n()) %>%
        mutate(frequenza_relativa = frequenza / sum(frequenza)) %>%
        select(marital, age_class, frequenza_relativa) %>%
        spread(age_class, frequenza_relativa)
kable(t_marital_age, digits = 4, format = "markdown")

g_marital_age  <- ggplot(bank0, aes(x = marital, fill = age_class)) +
        geom_bar(position = "fill") +
        ggtitle("distribuzione di age_class per marital") +
        ylab("percentuale di fascie di età") +
        scale_y_continuous(breaks = seq(0, 1, 0.1)) +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_marital_age

g_age_marital  <- ggplot(bank0, aes(x = age_class, fill = marital)) +
        geom_bar(position = "fill") +
        ggtitle("distribuzione di marital per age_class") +
        ylab("percentuale di marital") +
        scale_y_continuous(breaks = seq(0, 1, 0.1)) +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_age_marital
```

C'è una forte componente di giovani tra i single e di single tra i giovani.


```{r age and marital bivariate graph}
g_marital_age_class_y <- ggplot(bank0, aes(x = marital, fill = y)) + 
        geom_bar(position = "fill") + 
        geom_hline(yintercept = mean(bank0$y!="yes"), width = 2, col = "black", linetype = 2) +
        facet_wrap(~age_class) +
        ggtitle("penetrazione per age e marital") +
        ylab("percentuale di marital") +
        scale_y_continuous(breaks = seq(0, 1, 0.1)) +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_marital_age_class_y

t_marital_age_y <- bank0 %>%
        group_by(marital, age_class) %>%
        summarise(tasso_sottoscrizione = mean(y == "yes")) %>%
        select(marital, age_class, tasso_sottoscrizione) %>%
        spread(age_class, tasso_sottoscrizione) %>%
        left_join(t_marital_y, by ="marital") %>%
        select(-frequenza, -frequenza_relativa)
kable(t_marital_age_y, digits = 4, format = "markdown")
```

L'ipotesi è che i single sottoscrivono più della media in quanto giovani e gli sposati no in quanto adulti: in realtà se ci limitiamo a guardare i giovani, gli sposati convertono sotto la media, anche se giovani. Quindi non basta l'età a spiegare la discriminazione che fa lo stato maritale, giacché essa persiste pure a parità di fascia di età. E la numerosità di questo sottogruppo non è irrilevante: 2061 casi. Insomma, lo stato maritale discrimina anche a parità di età. Lo stesso vale, ma con una evidente interazione, per gli anziani, e per la fascia adulta, dove si vede principalmente il **main effect** dell'età.

```{r age and marital interaction graph}
t_marital_age_y_pp <- bank0 %>%
        group_by(marital, age_class) %>%
        summarise(tasso_sottoscrizione = mean(y == "yes")) %>%
        select(marital, age_class, tasso_sottoscrizione)
g_marital_age_y_pp <- ggplot(t_marital_age_y_pp, aes(x = age_class, y = tasso_sottoscrizione, col = marital, group = marital)) +
        geom_point() +
        geom_line() +
        ggtitle("interazione tra age e marital") +
        xlab("età")
g_marital_age_y_pp
```

La linea verde e quella rossa sono abbastanza parallele; questo vuol dire che sposati e divorziati/vedovi, muovendosi tra le varie fascie di età, mantengono una differenza nel tasso di sottoscrizione simile, e quindi l'età eserciza un semplice main effect sullo stato maritale. Invece c'è una interazione tra età e stato maritale single, in quanto la combinazione 18-30 anni e stato single genera un tasso di sottoscrizione molto superiore a quanto è superiore quello dei single tout court, mentre per i single adulti questo effetto non c'è. Gli anziani single sono 61, quindi la numerosità è poco significativa.

La mia ipotesi di partenza è che i single convertissero in quanto giovani. L'ipotesi non sembra confermata: analizzando  il comportamento dei tre stati maritali per ogni fascia di età, si vede che i giovani sottoscrivono tanto solo se anche single, i giovani sposati non sottoscrivono più della media. Quindi l'età non fa da *confounder*, ma da *effect modifier*, perché nella fascia giovanile la conversion dei single è potenziata rispetto a quella complessiva, per quanto il trend sia identico (minor tasso di sottoscrizione gli sposati, maggiore i single). Ma in realtà abbiamo scoperto che i giovani sottoscrivono più della media solo se single. Gli anziani sottoscrivono assai, come è ovvio, ma il comportamento dei tre stati maritali (per quanto i numeri siano bassi) si invertono; anche qui c'è interazione! E di sicuro è dovuta allo specifico comportamento degli anziani vedovi.

Nella fascia adulti invece si nota solo il **main effect** dell'età.

Abbiamo trovato una relazione di interazione, non forte ma presente. **Si potrebbe pensare di includere un effetto di interazione nel modello**.

##Education and job

L'ipotesi è che il maggior tasso di sottoscrizione dei laureati sia dovuto al fatto che i laureati sono giovani mentre gli adulti hanno educazione inferiore.

```{r age education graph and table}
t_education_age <- bank0 %>%
        group_by(education, age_class) %>%
        summarise(frequenza = n()) %>%
        mutate(frequenza_relativa = frequenza / sum(frequenza)) %>%
        select(education, age_class, frequenza_relativa) %>%
        spread(age_class, frequenza_relativa)
kable(t_education_age, digits = 4, format = "markdown")

g_education_age  <- ggplot(bank0, aes(x = education, fill = age_class)) +
        geom_bar(position = "fill") +
        ggtitle("distribuzione di age_class per education") +
        ylab("percentuale di fascie di età") +
        scale_y_continuous(breaks = seq(0, 1, 0.1)) +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_education_age

g_age_education  <- ggplot(bank0, aes(x = age_class, fill = education)) +
        geom_bar(position = "fill") +
        ggtitle("distribuzione di education per age_class") +
        ylab("percentuale di education") +
        scale_y_continuous(breaks = seq(0, 1, 0.1)) +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_age_education
```

La proporzione delle fascie di età all'interno dei titolo di studio è abbastanza simile, già da qui risulta molto improbabile confermare l'ipotesi di partenza.


```{r age and education bivariate graph}
g_education_age_class_y <- ggplot(bank0, aes(x = education, fill = y)) + 
        geom_bar(position = "fill") + 
        geom_hline(yintercept = mean(bank0$y!="yes"), width = 2, col = "black", linetype = 2) +
        facet_wrap(~age_class) +
        ggtitle("penetrazione per age e education") +
        ylab("percentuale di education") +
        scale_y_continuous(breaks = seq(0, 1, 0.1)) +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_education_age_class_y

t_education_age_y <- bank0 %>%
        group_by(education, age_class) %>%
        summarise(tasso_sottoscrizione = mean(y == "yes")) %>%
        select(education, age_class, tasso_sottoscrizione) %>%
        spread(age_class, tasso_sottoscrizione) %>%
        left_join(t_education_y, by ="education") %>%
        select(-frequenza, -frequenza_relativa)
kable(t_education_age_y, digits = 4, format = "markdown")
```

Trascurando il valore "Unknown", risulta evidente che a parità di età la discriminazione che esercita l'educazione sul tasso di sottoscrizione è simile a quella complessiva, al netto dell'effetto principale dell'età. L'età non spiega nulla sulla discriminazione dell'educazione e probabilmente non c'è nemmeno alcuna interazione.

```{r age and education interaction graph}
t_education_age_y_pp <- bank0 %>%
        group_by(education, age_class) %>%
        summarise(tasso_sottoscrizione = mean(y == "yes")) %>%
        select(education, age_class, tasso_sottoscrizione)
g_education_age_y_pp <- ggplot(t_education_age_y_pp, aes(x = age_class, y = tasso_sottoscrizione, col = education, group = education)) +
        geom_point() +
        geom_line() +
        ggtitle("interazione tra age e education") +
        xlab("età")
g_education_age_y_pp
```

Anche il grafico dell'interazione ci mostra che, trascurando "unknown" (sarebbe interessante capire che clienti indica), le rette sono parallele. 

##Housing and loan

Vogliamo verificare se ci sia una qualche interazione tra avere il mutuo e avere un prestito sul tasso di sottoscrizione

```{r housing and loan interaction graph}
t_loan_housing_y_pp <- bank0 %>%
        group_by(loan, housing) %>%
        summarise(frequenza = n(), tasso_sottoscrizione = mean(y == "yes")) %>%
        select(loan, housing, tasso_sottoscrizione, frequenza)
g_loan_housing_y_pp <- ggplot(t_loan_housing_y_pp, aes(x = housing, y = tasso_sottoscrizione, col = loan, group = loan)) +
        geom_point() +
        geom_line() +
        ggtitle("interazione tra housing e loan") +
        xlab("housing")
g_loan_housing_y_pp
```

La differenza nella propensione a sottoscrivere tra chi ha un mutuo e chi non ce l'ha è molto molto diversa se si ha anche un prestito o no; Se hai un prestito, avere anche un mutuo fa diminuire il tasso di sottoscrizione molto più che se il prestito non c'è. L'effetto di interazione è evidente e andrà incluso nel modello.

##Campaign e month

`Campaign` misura il numero di contatti di questa campagna. Più un cliente ne riceve, meno tende a sottoscrivere. Poiché è anche evidente che i mesi in cui si sottoscrive di più sono quelli in cui si fanno meno ultime chiamate, vorrei verificare se c'è una associazione tra le due variabili: magari si hanno più unici contatti nei mesi in cui si chiama meno, e quindi si chiama meno proprio per quel motivo. Vediamo quindi se i contatti unici si concentrano nei mesi con minor numero di chiamate oppure no.


```{r campaign_class graph and table}
grand_margin_month1 <- bank0 %>%
        group_by(campaign_class) %>%
        summarise(frequenza = n()) %>%
        mutate(frequenza_relativa = frequenza / sum(frequenza)) %>%
        select(frequenza_relativa)
grand_margin_month2 <- as.data.frame(t(grand_margin_month1))
t_campaign_class_month <- bank0 %>%
        group_by(month, campaign_class) %>%
        summarise(frequenza = n()) %>%
        mutate(frequenza_relativa = frequenza / sum(frequenza)) %>%
        select(campaign_class, month, frequenza_relativa) %>%
        spread(campaign_class, frequenza_relativa)
kable(t_campaign_class_month, digits = 4, format = "markdown")
kable(grand_margin_month2, digits = 4, format = "markdown")

g_campaign_class_month  <- ggplot(bank0, aes(x = month, fill = campaign_class)) +
        geom_bar(position = "fill") +
        ggtitle("distribuzione di campaign_class per month ") +
        ylab("frequenza relativa") +
        scale_y_continuous(breaks = seq(0, 1, 0.1)) +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_campaign_class_month
```

In effetti i mesi a minor numero di chiamate (marzo, settembre, ottobre, dicembre) tendono ad avere una concentrazione di contatti unici molto maggiore dei mesi estivi, ad alto numero di chiamate finali. A questo punti bisogna verificare se, a parità di numero di contatti, il mese discrimina ancora, e di quanto:

```{r month and campaign_class_class bivariate graph}
g_campaign_class_month_y <- ggplot(bank0, aes(x = month, fill = y)) + 
        geom_bar(position = "fill") + 
        geom_hline(yintercept = mean(bank0$y!="yes"), width = 2, col = "black", linetype = 2) +
        facet_wrap(~campaign_class) +
        ggtitle("penetrazione per month e campaign_class") +
        ylab("tasso di sottoscrizione") +
        scale_y_continuous(breaks = seq(0, 1, 0.1)) +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_campaign_class_month_y

t_campaign_class_month_y <- bank0 %>%
        group_by(campaign_class, month) %>%
        summarise(tasso_sottoscrizione = mean(y == "yes")) %>%
        select(campaign_class, month, tasso_sottoscrizione) %>%
        spread(month, tasso_sottoscrizione) %>%
        left_join(t_campaign_class_y, by ="campaign_class") %>%
        select(-frequenza, -frequenza_relativa)
kable(t_campaign_class_month_y, digits = 4, format = "markdown")
```

Sembra che il mese discrimini, per ogni livello di `campaign class`, come fa marginalmente. Mi sembra ci sia solo il main effect del numero di contatti, verifichiamolo con il grafico dell'interazione:

```{r month and campaign_class interaction graph}
t_campaign_class_month_y_pp <- bank0 %>%
        group_by(month, campaign_class) %>%
        summarise(frequenza = n(), tasso_sottoscrizione = mean(y == "yes")) %>%
        select(campaign_class, month, tasso_sottoscrizione, frequenza)

g_campaign_class_month_y_pp <- ggplot(t_campaign_class_month_y_pp, aes(x = campaign_class, y = tasso_sottoscrizione, col = month, group = month)) +
        geom_point() +
        geom_line() +
        ggtitle("interazione tra month e campaign_class") +
        xlab("campaign_class") +
        scale_y_continuous(breaks = seq(0,0.6, 0.05))
g_campaign_class_month_y_pp
```

L'interazione sembra debole, rimangono nettamente separati i mesi ad alti volumi da quelli a bassi volumi. Non c'è né interazione né spiegazione tra le due variabili.

#La creazione del modello

A questo punto siamo pronti per testare vari modelli di regressione logistica. Il primo step sarà, come da prassi, la suddivisione del dataset in tre parti: training, validation e test. Questo approccio, tipico della *cross validation*, permetterà di addestrare vari modelli sul dataset di training, scegliere il più performante sul dataset di validazione e poi stimare definitivamente le performance del modello selezionato sul dataset di test.

##Partizione del dataset

```{r partizione training validation e test}
set.seed(456)
training_set_vsa <- bank0 %>%
        add_rownames() %>%
        sample_frac(0.6, replace = FALSE)
nrow(training_set_vsa)

test_and_val_set1 <- bank0 %>%
        add_rownames() %>%
        sample_frac(1, replace = FALSE) %>%
        anti_join(training_set_vsa, by = "rowname")
nrow(test_and_val_set1)
#check ok, sono mutuamente esclusivi

test_set_vsa <- test_and_val_set1 %>%
        sample_frac(0.5, replace = FALSE)
nrow(test_set_vsa)

validation_set_vsa <- test_and_val_set1 %>%
        sample_frac(1, replace = FALSE) %>%
        anti_join(test_set_vsa, by = "rowname")
nrow(validation_set_vsa)

validation_set_vsa[validation_set_vsa$rowname == test_set_vsa$rowname,] #check ok, sono mutuamente esclusivi
```

Il 60% del dataset è stato destinato al training, un 20% alla validazione e un 20% al test.

#Selezione del modello

Ora verranno addestrati e validati diversi modelli di regressione logistica, con una logica di selezione delle variabili sempre diversa. Ogni modello verrà addestrato sul dataset di training, dove verranno calcolati i coefficienti e fatta una diagnostica sul modello stesso (significatività del modello, multicollinearità). Verrà poi applicato al dataset di validazione e le sue performance predittive calcolcate mediante l'AUROC.

##Modello 1

###Formula
In questo modello verranno incluse le variabili con u information value maggiore di 0.02, esclusa `duration` che non verrà utilizzata. Verranno inoltre incluse alcune interazioni che nell'analisi esplorativa sono parse di interesse (si riconoscono dall'asterisco che separa le due variabili che interagiscono). Ecco la formula:

```{r formula glm1 vsa}
formula_glm1 <- formula_glm1 <- y~age + job + marital + balance + housing + loan + contact + day + month + campaign + pdays + previous + age*marital + age*job + loan*housing
```

###Coefficienti
```{r glm1 vsa building}
glm1_vsa <- glm(formula_glm1, family = "binomial", data = training_set_vsa)
summary(glm1_vsa)
```

Guardando ai valori dei coefficienti, i loro p.value sono spesso significativi (wald test). Laddove non lo sono non ha senso escludere la variabile, perché si tratta di un livello di una variabile categorica trasformata in tante variabili dummy.

###Verifica di multicollinearità

Con il codice sottostante creiamo la matrice con la *variance decomposition proportion* e il *condition index*. Verifichiamo se ci son indici maggiori di 30 con una proporzione della scomposizione della varianza maggiore di 0.5

```{r coll}
cd1 <- colldiag(model.matrix(glm1_vsa))
cd1_pi_df <- as.data.frame(cd1$pi)
cd1_indx_df <- as.data.frame(cd1$condindx)
cd1_df <- data.frame(cd1_indx_df, cd1_pi_df, row.names = NULL)
cd1_mc<- gather(cd1_df, variable, vdp, -cond.index) %>%
        arrange(cond.index) %>%
        filter(cond.index > 30 & vdp > 0.5)
kable(cd1_mc, digits = 4, format = "markdown")
```

`age` genera problemi di multicollinearità, probabilmente in ragione degli effetti di interazione inseriti nel modello ma di cui non c'era fortissima evidenza nell'analisi esplorativa. Proviamo a rimuovere gli effetti di interazione in cui è presente la variabile dell'età. 

```{r glm1 mc}
formula_glm1 <- formula_glm1 <- y ~ age + job + marital + balance + housing + loan + contact + day + month + campaign + pdays + previous + loan*housing
glm1_vsa <- glm(formula_glm1, family = "binomial", data = training_set_vsa)
cd1 <- colldiag(model.matrix(glm1_vsa))
cd1_pi_df <- as.data.frame(cd1$pi)
cd1_indx_df <- as.data.frame(cd1$condindx)
cd1_df <- data.frame(cd1_indx_df, cd1_pi_df, row.names = NULL)
cd1_mc<- gather(cd1_df, variable, vdp, -cond.index) %>%
        arrange(cond.index) %>%
        filter(cond.index > 30 & vdp > 0.5)
kable(cd1_mc, digits = 4, format = "markdown")
```

Difatti ora solo l'intercetta - ciò non fa problema - è rilevata dalla verifica di multicollinearità.

```{r glm1 mc1 coefficienti}
summary(glm1_vsa)
```

###Test di bontà adattamento modello

Usiamo il test di Hosmer e Lemshow in ragione del numero eccessivo di combinazione di variabili  che ci impedirebbero di utilizzare il test di rapporto di verosimiglianza.

```{r HL glm1}
hl_glm1 <- hoslem.test(training_set_vsa$y =="yes", fitted(glm1_vsa), g=10)
hl_glm1
```

Il test, se rigettato, rigetta l'ipotesi di buon adattamento. Qui non si può rigettare, in ragione di un p-value molto besso, quindi il modello non si adatta ai dati. Come già spiegato nel capitolo secondo, questo non vuol dire che le performance predittive saranno necessariamente scarse.

###Stima delle performance predittive

```{r glm1 AUC on validation}
glm1_vsa_predictions  <- predict(glm1_vsa, validation_set_vsa, type="response")

AUC_glm1_vsa <- roc(validation_set_vsa$y, glm1_vsa_predictions, levels=c("no", "yes"))
AUC_glm1_vsa$auc
```

L'AUROC del modello sul validation set è 0.746. Un modello con un AUROC del genere è un buon modello, né scarso né ottimo o eccellente. Con questo valore competerà con gli altri modelli.

##Modello 2

In questo tentativo la selezione delle variabili da includere nel modello si farà ramite procedure step, sia backward che forward. Tra le variabili selezionabili escludiamo `duration`.

###Formula

```{r backward e forward}
#glm2_beforebackstep_training <- glm(y~age + job + marital + education + default + balance + housing + loan + contact + pdays + day + month + campaign + previous, family = "binomial", data = training_set_vsa)
#glm2_backstep_selection <- stepAIC(object = glm2_beforebackstep_training, direction = "backward", scope = c(upper = ~age + job + marital + education + default + balance + housing + loan + contact + day + month + campaign + pdays + previous, lower = ~1))
#glm2_backstep_selection$anova

#glm2_beforeforwardstep_training <- glm(y~1, family = "binomial", data = training_set_vsa)
#glm2_forwardstep_selection <- stepAIC(object = glm2_beforeforwardstep_training, direction = "forward", scope = c(upper = ~age + job + marital + education + default + balance + housing + loan + contact + day + month + campaign + pdays + previous, lower = ~1))
#glm2_forwardstep_selection$anova
```

Sia la procedura backward che quella forward presentano lo stesso modello finale: y ~ age + job + marital + education + balance + housing + loan + contact + pdays + month + campaign + previous
    
###Coefficienti

```{r glm2 formula }
step_formula <- y ~ age + job + marital + education + balance + housing + loan + contact + pdays + month + campaign + previous
glm2_vsa <- glm(step_formula, family ="binomial", data = training_set_vsa)
summary(glm2_vsa)
```

###Verifica di multicollinearità

```{r coll glm2 }
cd2 <- colldiag(model.matrix(glm2_vsa))
cd2_pi_df <- as.data.frame(cd2$pi)
cd2_indx_df <- as.data.frame(cd2$condindx)
cd2_df <- data.frame(cd2_indx_df, cd2_pi_df, row.names = NULL)
cd2_mc<- gather(cd2_df, variable, vdp, -cond.index) %>%
        arrange(cond.index) %>%
        filter(cond.index > 30 & vdp > 0.5)
kable(cd2_mc, digits = 4, format = "markdown")
```

Nessun problema di multicollinearità rilevato.

###Test di bontà adattamento modello

```{r HL glm2}
hl_glm2 <- hoslem.test(training_set_vsa$y =="yes", fitted(glm2_vsa), g=100)
hl_glm2
```

Anche qui l'ipotesi nulla di buon adattamento del modello va rigettata.

###Stima delle performance predittive

Calcoliamo l'AUROC di questo modello utilizzato sul validation set:

```{r glm2 AUC on validation }
glm2_vsa_predictions  <- predict(glm2_vsa, validation_set_vsa, type="response")

AUC_glm2_vsa <- roc(validation_set_vsa$y, glm2_vsa_predictions, levels=c("no", "yes"))
AUC_glm2_vsa$auc
```

Il modello 2 ha una AUROC di 0.7463 contro lo 0.746 del modello 1. Seppur di valori millesimali, il modello con selezione automatica delle variabili performa meglio di una selezione tramite analisi esplorativa.

##Modello 3

Il modello 3 utilizza le stesse variabili del modello 1, ma laddove ne esista una versione con raggruppamento in classi utilizza questa seconda versione.

###Formula

```{r formula glm3 vsa}
formula_glm3 <- y ~ age_class + job + marital + balance_class + housing + loan + contact + day + month + campaign_class + pdays_class + previous_class + age_class*marital + age_class*job + loan*housing
```

###Coefficienti

```{r glm3 vsa building}
glm3_vsa <- glm(formula_glm3, family = "binomial", data = training_set_vsa)
summary(glm3_vsa)
```

In questo modello sia la variabile `job` che l'interazione tra `job` e `age_class` non è significativa a nessun livello. Tuttavia per ora non esludiamo nulla, utilizzeremo il wald test nella selezione delle variabili un un successivo tentativo. Vediamo se però ci sono problemi di multicollinearità

###Verifica di multicollinearità

```{r glm 3 coll}
matrix_glm3 <- model.matrix(glm3_vsa)
matrix_glm3 <- matrix_glm3[,colSums(matrix_glm3 != 0) != 0]
cd3 <- colldiag(matrix_glm3)
cd3_pi_df <- as.data.frame(cd3$pi)
cd3_indx_df <- as.data.frame(cd3$condindx)
cd3_df <- data.frame(cd3_indx_df, cd3_pi_df, row.names = NULL)
cd3_mc<- gather(cd3_df, variable, vdp, -cond.index) %>%
        arrange(cond.index) %>%
        filter(cond.index > 30 & vdp > 0.5)
kable(cd3_mc, digits = 4, format = "markdown")
```

Molti problemi di multicollinearità, relativi alle variabili `job`, `age_class`, `marital`, `pdays`, `previous` e `contact`.

Provo a togliere le interazioni e la variabile di contatto con l'information value più basso, `previous`.

```{r glm3 mc1}
formula_glm3 <- y ~ age_class + job + marital + balance_class + housing + loan + contact + day + month + campaign_class + pdays_class + loan*housing
glm3_vsa <- glm(formula_glm3, family = "binomial", data = training_set_vsa)
matrix_glm3 <- model.matrix(glm3_vsa)
matrix_glm3 <- matrix_glm3[,colSums(matrix_glm3 != 0) != 0]
cd3 <- colldiag(matrix_glm3)
cd3_pi_df <- as.data.frame(cd3$pi)
cd3_indx_df <- as.data.frame(cd3$condindx)
cd3_df <- data.frame(cd3_indx_df, cd3_pi_df, row.names = NULL)
cd3_mc<- gather(cd3_df, variable, vdp, -cond.index) %>%
        arrange(cond.index) %>%
        filter(cond.index > 30 & vdp > 0.5)
kable(cd3_mc, digits = 4, format = "markdown")
```

Nessuna multicollinearità. Ecco i coefficienti dopo la rimozione delle variabili "problematiche"

```{r glm3 mc1 coefficienti}
summary(glm3_vsa)
```

###Bontà adattamento modello

```{r HL glm3}
hl_glm3 <- hoslem.test(training_set_vsa$y =="yes", fitted(glm3_vsa), g=10)
hl_glm3
```

Il test, se rigettato, rigetta l'ipotesi di buon adattamento. Qui non si può rigettare. è vero che c'è il problema che il numero di gruppi non dovrebbe essere inferiore a p+1 (http://thestatsgeek.com/2014/02/16/the-hosmer-lemeshow-goodness-of-fit-test-for-logistic-regression/), e io con le variabili dummy ho molte p. Ma anche se i gruppi sono 100, il p.value è significativo, quindi il buon adattamento va rigettato.

###Stima performance predittive

```{r glm3 AUC on validation}
glm3_vsa_predictions  <- predict(glm3_vsa, validation_set_vsa, type="response")

AUC_glm3_vsa <- roc(validation_set_vsa$y, glm3_vsa_predictions, levels=c("no", "yes"))
AUC_glm3_vsa$auc
```

Il modello 3 ha una AUROC di `r AUC_glm3_vsa$auc`, calcolata sul dataset di validazione non utilizzato per addestrare il modello. Miglior performance sinora.

##Modello 4
**ripartire da qui**

Modello simile a glm3, ma uso i p.value per escludere variabili se possibile

```{r formula glm4 vsa}
formula_glm4_1 <- y ~ age_class + job + marital + balance_class + housing + loan + contact + day + month + campaign_class + pdays_class + age_class*marital + age_class*job + loan*housing
```

```{r glm4 vsa building}
glm4_1_vsa <- glm(formula_glm4_1, family = "binomial", data = training_set_vsa)

summary(glm4_1_vsa) #AIC molto basso, è normale la sovrastima delle performance, che non vuol dire overfitting.
```

Tolgo interazion age*marital age*job e job: Raiggiungo previous_class, magari ora non ci sarà collinearità.

```{r formula glm4 2 vsa}
formula_glm4_2 <- y ~ age_class + marital + balance_class + housing + loan + contact + day + month + campaign_class + pdays_class + loan*housing
```

```{r glm4 second building}
glm4_2_vsa <- glm(formula_glm4_2, family = "binomial", data = training_set_vsa)
summary(glm4_2_vsa)
anova(glm4_1_vsa, glm4_2_vsa)
```


#Multicollinearità

```{r glm 4 coll}
matrix_glm4_2 <- model.matrix(glm4_2_vsa)
matrix_glm4_2 <- matrix_glm4_2[,colSums(matrix_glm4_2 != 0) != 0]

cd_glm4_2 <- colldiag(matrix_glm4_2)
print(cd_glm4_2)
str(cd_glm4_2)
cd_glm4_2$condindx
cd_glm4_2$pi[48,]
```

Previous continua a dare problemi di multicollinearità. Lo ritolgo all'origine.


##Bontà adattamento modello

```{r HL glm4_2}
hl_glm4_2 <- hoslem.test(training_set_vsa$y =="yes", fitted(glm4_2_vsa), g=10)
hl_glm4_2
```

Nada.

##Stima delle performance predittive

```{r glm4 AUC on validation}
glm4_2_vsa_predictions  <- predict(glm4_2_vsa, validation_set_vsa, type="response")

AUC_glm4_2_vsa <- roc(validation_set_vsa$y, glm4_2_vsa_predictions, levels=c("no", "yes"))
AUC_glm4_2_vsa$auc
plot(AUC_glm4_2_vsa, legacy.axes=TRUE)
```

AUC di 0.7556. Senza togliere le variabili con basso p.value eravamo a 0.755, praticamente performance identiche con stessi problemi di multicollinearità Giusto per scrupolo voglio vedere se gli errori standard sono inferiori nel secondo caso (anche se solo il principio della parsimonia basta a giustificare il secondo modello).

```{r}
a <- tidy(glm3_vsa)
b <- tidy(glm4_2_vsa)
glm_comp_3_and_4_2 <- a %>%
        inner_join(b, by = "term") %>%
        select(term, SE_glm3 = std.error.x, SE_glm4_2 =  std.error.y) %>%
        mutate(comp_SE = SE_glm4_2 - SE_glm3) %>%
        arrange(comp_SE)
```

Quasi tutti inferiori, anche se di poco. Mi domando se un tale misero vantaggio di SE e di AUC mi debba indurre a escludere delle variabili. Preferire glm3 o glm4? Mah. Considera però che glm3 ha il problema del rank e che in glm4 ho valutato i p-value senza la correzione di bonferroni.


```{r glm3 AUCPR on validation}
AUCPR_glm4_2_vsa <- pr.curve(glm4_2_vsa_predictions, weights.class0 = validation_set_vsa$y == "yes", curve=T)
AUCPR_glm4_2_vsa
plot(AUCPR_glm4_2_vsa)
```

```{r glm5 poutcome}
formula_glm5_1 <- y ~ poutcome
glm5_1_vsa <- glm(formula_glm5_1, family = "binomial", data = training_set_vsa)
summary(glm5_1_vsa)
```

Alpha = 0.05 / ? Non si sa. Non ha senso fare la forward. Dovresti assumere un numero di variabili che incliderai, ma magari escludi qualcosa che andrebbe messo.


```{r glm5 poutcome month}
formula_glm5_2 <- y~age + job + marital + education + default + balance + housing + loan + contact + pdays + day + month + campaign + previous
glm5_2_vsa <- glm(formula_glm5_2, family = "binomial", data = training_set_vsa)
summary(glm5_2_vsa)
glm5_2_vsa_table <- tidy(glm5_2_vsa)
da_escludere <- glm5_2_vsa_table %>%
        filter(p.value > 0.05/nrow(a))
```

Praticamente tutto. è evidente che il test perde di potenza, oppure che i test statistici per questa analisi tendono a considerare il modello non corretto (vedi anche HL). Bisogna rifarsi perciò alla AUC. La step tramite p.value è abortita.




```{r}
# The train and test set are loaded into your workspace.

# Set random seed. Don't remove this line
set.seed(1)

# Load the rpart, rattle, rpart.plot and RColorBrewer package
library("rpart")
library("rpart.plot")
library("RColorBrewer")
library("rattle")

# Build a tree model: tree
tree <- rpart(y ~ age + job + marital + balance + housing + loan + contact + day + month + campaign + pdays + previous, data = training_set_vsa, method = "class", control=rpart.control(minsplit=5, cp=0.001))

# Draw the decision tree
pred <- predict(tree, validation_set_vsa, type = "class")
conf <- table(validation_set_vsa$y, pred)
conf
```


#Auroc test

```{r AUC test glm3}
test_set_vsa$glm3_vsa_predictions_test  <- predict(glm3_vsa, test_set_vsa, type="response")
AUC_glm3_vsa_test <- roc(test_set_vsa$y, test_set_vsa$glm3_vsa_predictions_test, levels=c("no", "yes"))
AUC_glm3_vsa_test$auc
```

#Aucpr test

```{r AUCPR glm3}
AUCPR_glm3_vsa <- pr.curve(test_set_vsa$glm3_vsa_predictions_test, weights.class0 = test_set_vsa$y == "yes", curve=T)
AUCPR_glm3_vsa
```

#Grafici

```{r plot of ROC AUCPR and prob-cutoff and prob_class }
plot(AUC_glm3_vsa_test, legacy.axes = TRUE)

plot(AUCPR_glm3_vsa)

g_estim_prob_class <- ggplot(data = test_set_vsa, aes(x = glm3_vsa_predictions_test, col = y)) +
        geom_density()
g_estim_prob_class

#construisco un dataframe per il plot sensitivuty probability vs cutoff. vedi https://cran.r-project.org/web/packages/ROCR/ROCR.pdf

prediction_test_obj <- prediction(predictions = test_set_vsa$glm3_vsa_predictions_test, labels = test_set_vsa$y)
tpr_obj <-  performance(prediction_test_obj, measure = "tpr")
fpr_obj <-  performance(prediction_test_obj, measure = "spec")
ppv_obj <-  performance(prediction_test_obj, measure = "prec") 

sens_spec_cutoff_df_wide <- data.frame (cutoff = as.numeric( unlist ( tpr_obj@x.values) ), sensitivity = as.numeric( unlist ( tpr_obj@y.values) ), specificity = as.numeric( unlist ( fpr_obj@y.values) ), ppv = as.numeric( unlist (ppv_obj@y.values) ))

sens_spec_cutoff_df_tidy <- sens_spec_cutoff_df_wide %>%
        gather(key = type_indicator, value_indicator, sensitivity:ppv)

g_sens_spec_cutoff <- ggplot(sens_spec_cutoff_df_tidy, aes(x = cutoff, y = value_indicator, col = type_indicator)) +
        geom_line() + 
        scale_x_continuous(breaks = seq(0.01, 1, 0.02)) +
        scale_y_continuous(breaks = seq(0, 1, 0.05)) +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
g_sens_spec_cutoff#eccellente!
```

Con questo grafico, `g_sens_spec_cutoff``, posso scegliere la soglia di cutoff che desidero e sapere tpr, fpr, ppv all'istante.

#Decisione sulla soglia

```{r cutoff decision}
sens_spec_cutoff_df_wide %>%
        filter(sensitivity > 0.47, sensitivity < 0.53)

#Quando cutoff = 0.1758297 allora:

sens_spec_cutoff_df_wide %>%
        filter(cutoff > 0.1758, cutoff < 0.1759)
#ho un tpr del 50%, un tnr del 88% e un ppv del 36%
```

La mia soglia è 0.1758

#Confusion matrix
```{r confusion matrix glm3}
#usa prediction_test_obj di rocr, vedi sopra e https://cran.r-project.org/web/packages/ROCR/ROCR.pdf
test_set_vsa$yhat <- factor(as.numeric(test_set_vsa$glm3_vsa_predictions_test > 0.1758))
test_set_vsa$yact <- factor(as.numeric(test_set_vsa$y == "yes"))
conf_matrix <- confusionMatrix(test_set_vsa$yhat, test_set_vsa$yact, positive ="1")
conf_matrix
```


#Diagnostic likelihood ratio

Non so la prevalence se va calcolata su tutto il dataset o solo sul training. Io direi solo sul training, perché nella CV è il campione che ho a disposizione per qualunque stima. peraltro è identica a quella di tutto il dataset.

```{r DLR+ glm3}
ppv_def <-sens_spec_cutoff_df_wide$ppv[sens_spec_cutoff_df_wide$cutoff > 0.1758 & sens_spec_cutoff_df_wide$cutoff < 0.1759]
prevalence <- mean(training_set_vsa$y == "yes")
DLRp <- ( (ppv_def/(1-ppv_def)) / (prevalence/(1-prevalence)) )
DLRp  #sopra 4, buono.
```


#Lift chart cumulato

```{r AULIFT glm3}
lift_df <- data.frame(yact = test_set_vsa$yact, y_pred_prob = test_set_vsa$glm3_vsa_predictions_test)
lift_df_sum <- lift_df %>%
        arrange(y_pred_prob) %>%
        mutate(groups = ntile(y_pred_prob, 10)) %>%
        group_by(groups) %>%
        summarise(n_clienti = n(), n_y = sum(yact == "1")) %>%
        arrange(desc(groups)) %>%
        mutate(perc_clienti = n_clienti / sum(n_clienti), perc_clienti_positivi = n_y / sum(n_y), perc_cum_clienti_pos_mod               = cumsum(perc_clienti_positivi), perc_cum_clienti = cumsum(perc_clienti), perc_cum_clienti_pos_exp = perc_cum_clienti) %>%
        select(groups, perc_cum_clienti, perc_cum_clienti_pos_mod, perc_cum_clienti_pos_exp) %>%
        gather(key = type_indicator, value_indicator, perc_cum_clienti_pos_mod:perc_cum_clienti_pos_exp) %>%
        ggplot(aes(x = perc_cum_clienti, y = value_indicator, col = type_indicator)) + 
        geom_point (size = 3) + 
        geom_line() +
        scale_x_continuous(breaks = seq(0, 1, 0.1)) +
        scale_y_continuous(breaks = seq(0, 1, 0.1)) +
        geom_vline(xintercept = 0.17)
lift_df_sum
```

#Conversion per decili

```{r conversion per decili glm3}
g_conversion_decili <- lift_df %>%
        arrange(y_pred_prob) %>%
        mutate(groups = ntile(y_pred_prob, 10)) %>%
        group_by(groups) %>%
        summarise(n_clienti = n(), n_y = sum(yact == "1")) %>%
        arrange(desc(groups)) %>%
        mutate(perc_clienti = n_clienti / sum(n_clienti), perc_cum_clienti = cumsum(perc_clienti), conversion = n_y / n_clienti) %>%
        ggplot(aes(x = groups, y = conversion)) + 
        geom_bar(stat = "identity", col = "blue", fill = "pink") +
        scale_x_continuous(breaks = seq(1, 10, 1)) +
        scale_y_continuous(breaks = seq(0, 1, 0.05)) +
        geom_hline(yintercept = mean(bank0$y == "yes"), col = "blue", linetype = 2)
g_conversion_decili
```
